question_id,answer_id,is_accepted,body,user_id,reputation,score
67234961,67236964,True,"<p>If there are multiple records for given key, you were overriding it everytime. Update your inner loop with following code.</p>
<pre><code>for (const [reportKey, reportValue] of Object.entries(value)) {
        //  console.log(reportKey, reportValue);
        // this[&quot;reportKey&quot;] = reportKey;
        if (
          reportKey.toUpperCase() != horizontal &amp;&amp;
          reportKey.toUpperCase() != vertical
        ) {
          // this[&quot;reportKey&quot;] = this.getMetricsName(this[&quot;reportKey&quot;]);
          let rK = this.getMetricsName(reportKey);
          // let dataSet = [];

          // dataSet.push(
          let dataset = {
            x: xAxis,
            y: yAxis,
            value: reportValue,
            &quot;x-axis&quot;: horizontal,
            &quot;y-axis&quot;: vertical,
            &quot;x-name&quot;: value.PROCESSING_DAY,
            &quot;y-name&quot;: value.PROCESSING_TIME
          };
          // );
          if (!(rK[0] in reportKeyData)) {
            reportKeyData[rK[0]] = [];
          }
          reportKeyData[rK[0]].push(dataset);
          // reportKeyData[this[&quot;reportKey&quot;][0]] = dataSet;
        }
      }
</code></pre>
<p>Note: I've kept your code as commented, so you can see what has been changed.</p>
",11641029.0,5078.0,0
35793622,67239365,False,"<p>If you end up here because you Googled &quot;error LNK2001: unresolved external symbol __CrtDbgReport&quot; here is a simple thing to check...</p>
<p>If you are comparing working DEBUG to non-working RELEASE project settings and copy/paste between them, it is easy to copy a preprocessor definition, &quot;_DEBUG&quot; into a RELEASE project by mistake.  I just chased my tail for two frustrating hours after a quick and sloppy cut-n-paste... see how long it takes to find it below:</p>
<pre><code>WIN32_LEAN_AND_MEAN;WIN32;_CRT_NON_CONFORMING_SWPRINTFS;_CRT_SECURE_NO_WARNINGS;_CRT_SECURE_NO_DEPRECATE;_DEBUG;_CONSOLE;%(PreprocessorDefinitions)
</code></pre>
",1740065.0,125.0,0
35793622,35794243,True,"<p>It seems to be an SDL issue. <a href=""http://forums.libsdl.org/viewtopic.php?t=11533&amp;sid=8b83c67cb812b515738af3f945687c33"" rel=""nofollow"">Here</a> is a discussion on it in the SDL forum and basically there are following solutions - adding the libraries you mentioned , taking a proper VS2015 release build (there is a link in the thread) or building SDL from sources (the thread mentions that that should work too).</p>
",1458617.0,10998.0,2
56035960,67239339,False,"<p>This could be an installation and setup problem.</p>
<p>Check to make sure you have both &quot;C:\Program Files\Java\jdk1.8.0_291&quot; and &quot;C:\Program Files\Java\jre1.8.0_291&quot; folders. If not, try uninstalling Java and reinstalling Java SE Development Kit from <a href=""https://www.oracle.com/java/technologies/javase/javase-jdk8-downloads.html"" rel=""nofollow noreferrer"">here</a>, and rechecking after installation. Next, make sure that you set Java and Javac to Windows Path and download &quot;selenium-server-standalone-3.9.1.jar&quot; from <a href=""https://selenium-release.storage.googleapis.com/index.html"" rel=""nofollow noreferrer"">here</a>.</p>
<p>After that, go into the command prompt, change the directory to where the &quot;selenium-server-standalone-3.9.1.jar&quot; folder is and run the command below.</p>
<pre><code>java -jar selenium-server-standalone-3.9.1.jar
</code></pre>
<p>After that, run the following in your favorite Python IDE.</p>
<pre><code>from selenium import webdriver

browser = webdriver.Remote( desired_capabilities = webdriver.DesiredCapabilities.HTMLUNITWITHJS )
browser.quit()
</code></pre>
<p>That should be all you need to do to get HtmlUnit up and running in Python.</p>
",10665896.0,11.0,0
56035960,56042011,True,"<p>As per <a href=""https://docs.oracle.com/javase/8/docs/technotes/tools/windows/java.html#jar"" rel=""nofollow noreferrer""><code>java</code> command line documentation:</a></p>

<blockquote>
  <p>When you use the <code>-jar</code> option, the specified JAR file is the source of all user classes, and <strong>other class path settings are ignored</strong>.</p>
</blockquote>

<p>So you need to amend the command you're using to launch <a href=""https://docs.experitest.com/display/TE/Grid+Execution+with+Selenium"" rel=""nofollow noreferrer"">Selenium Grid</a> to look like:</p>

<pre><code>java -cp ""htmlunit-driver-2.35.1-jar-with-dependencies.jar;selenium-server-standalone-3.141.59.jar"" org.openqa.grid.selenium.GridLauncherV3
</code></pre>

<p>I would also recommend changing this line:</p>

<pre><code>driver = webdriver.Remote(command_executor='http://127.0.0.1:4444/wd/hub',desired_capabilities={'browserName': 'htmlunit', 'version': '2','javascriptEnabled': True})
</code></pre>

<p>to this one:</p>

<pre><code>driver = webdriver.Remote(command_executor='http://127.0.0.1:4444/wd/hub',desired_capabilities=webdriver.DesiredCapabilities.HTMLUNITWITHJS)
</code></pre>

<p>this way your script has a better chance to survive future libraries upgrade</p>
",2897748.0,116880.0,1
67144974,67239352,True,"<p>For simplicity, I think it is better to split the logic from the decorator to somewhere else. So, I created a function named <strong><code>_my_custom_decorator(...)</code></strong></p>
<pre><code><b>def _my_custom_decorator(func, view, request):
    # do most of the decorator logic here!!!
    if request.method.lower():
        raise ValueError(""Just for testing"")
    return func(view, request)</b>


def my_custom_decorator(func):
    def wrap(view, request):
        <b>return _my_custom_decorator(func, view, request) # calling the newly created function</b>
    return wrap


class SomeAPIView(APIView):
    <b>@my_custom_decorator # this decorator remain unchanged!!!</b>
    def post(self, request):
        return Response({""message"": ""Success""})</code></pre>
<p>and now, mock the <strong><code>_my_custom_decorator(...)</code></strong> function in the tests,</p>
<pre><code><b>def mock_my_custom_decorator(func, view, request):
    return func(view, request)</b>


class TestSomeAPIView(APITestCase):

    <b>@patch(""sample.views._my_custom_decorator"", mock_my_custom_decorator</b>)
    def test_decorator(self):
        url = reverse(""some-api-view"")
        response = self.client.post(url)
        self.assertEqual(response.status_code, 200)
        self.assertEqual(response.json(), {""message"": ""Success""})</code></pre>
",8283848.0,54462.0,0
67144974,67235190,False,"<p>This isn't a guaranteed solution but depending on your needs it may work to rewrite your decorator with a helper function that contains the logic that needs to be mocked.</p>
<p>For example:</p>
<pre class=""lang-py prettyprint-override""><code>from rest_framework.views import APIView
from rest_framework.response import Response

def some_check_or_other_response(view, request):
    if request.method.lower():
        raise ValueError(&quot;Just for testing&quot;)
    if some_other_condition:
        return Response({})
    

def my_custom_decorator(func):
    def wrap(view, request):
        short_circuit_response = some_check_or_other_response(view, request)
        if short_circuit_response:
            return short_circuit_response
        return func(view, request)

    return wrap


class SomeAPIView(APIView):

    @my_custom_decorator
    def post(self, request):
        return Response({&quot;message&quot;: &quot;Success&quot;})
</code></pre>
<p>and then</p>
<pre class=""lang-py prettyprint-override""><code>class TestSomeAPIView(APITestCase):

    @patch(&quot;sample.views.some_check_or_other_response&quot;)
    def test_decorator(self, mock_some_check):
        mock_some_check.return_value = ... # short-circuit with a return value
        mock_some_check.side_effect = ValueError(...) # simulate an exception
        ... # etc
</code></pre>
",11847125.0,4819.0,1
67144974,67181315,False,"<p>First, you will need to move <strong><code>my_custom_decorator</code></strong> into another module, preferably within the same package as your <strong><code>views.py</code></strong>.</p>
<p>Then you need to:</p>
<ul>
<li><p>Clear the module import cache for <strong><code>sample.decorators</code></strong>, all modules within your app that import it, and your <strong><code>settings.ROOT_URLCONF</code></strong></p>
</li>
<li><p>Clear the url cache that django uses internally</p>
</li>
<li><p>Monkey patch the decorator</p>
</li>
</ul>
<p><strong>tests.py</strong>:</p>
<pre><code>import sys
from django.conf import settings
from django.urls import clear_url_caches

def clear_app_import_cache(app_name):
    modules = [key for key in sys.modules if key.startswith(app_name)]

    for module_name in modules:
        del sys.modules[module_name]
    
    try:
        del sys.modules[settings.ROOT_URLCONF]
    except KeyError:
        pass
    clear_url_caches()

class TestSomeAPIView(APITestCase):
    @classmethod
    def setUpClass(cls):
        clear_app_import_cache('sample')

        from sample import decorators
        decorators.my_custom_decorator = lambda method: method

        super().setUpClass()

    @classmethod
    def tearDownClass(cls):
        # Make sure the monkey patch doesn't affect tests outside of this class.  
        # Might not be necessary
        super().tearDownClass()
        clear_app_import_cache('sample')

    def test_decorator(self):
        url = reverse(&quot;some-api-view&quot;)
        response = self.client.post(url)
        self.assertEqual(response.status_code, 200)
        self.assertEqual(response.json(), {&quot;message&quot;: &quot;Success&quot;})
</code></pre>
",10746224.0,8696.0,1
67144974,67145715,False,"<p>First you need to move the decorator to a different module to get a change to mock it.</p>
<p><strong>decorators.py</strong></p>
<pre><code>def my_custom_decorator(func):
    def wrap(view, request):
        if request.method.lower():
            raise ValueError(&quot;Just for testing&quot;)
        return func(view, request)
    return wrap

</code></pre>
<p><strong>views.py</strong></p>
<pre><code>from decorators import my_custom_decorator

class SomeAPIView(APIView):

    @my_custom_decorator
    def post(self, request):
        return Response({&quot;message&quot;: &quot;Success&quot;})
</code></pre>
<p>In your tests patch the decorator before it get applied,
like this</p>
<p><strong>tests.py</strong></p>
<pre><code>from unittest.mock import patch
patch(&quot;decorators.my_custom_decorator&quot;, lambda x: x).start()

from rest_framework.test import APITestCase

from django.urls import reverse


class TestSomeAPIView(APITestCase):

    def test_decorator(self):
        url = reverse(&quot;some-api-view&quot;)
        response = self.client.post(url)
        self.assertEqual(response.status_code, 200)
        self.assertEqual(response.json(), {&quot;message&quot;: &quot;Success&quot;})

</code></pre>
",6091847.0,615.0,0
65411291,67239350,False,"<p>Thanks <a href=""https://stackoverflow.com/users/11258538/felixfebrian"">FelixFebrian</a>, I'm able to resolve this issue with numpy 1.16.0 version.</p>
",5779486.0,11.0,0
65411291,65417387,True,"<ol>
<li>start apache at command line with 'httpd' and look for error messages. If Apache has a problem at startup there is no message in the log files.</li>
<li>check error.log
You can place 'print('xyz') even in the settings.py and elsewhere and this way by checking error.log see how your app is setup and how far a request is processed. If your app get stuck somewhere like this you find the code where it is stuck</li>
</ol>
",13510123.0,551.0,2
67236923,67237336,False,"<p>Or using <code>isin()</code>:</p>
<pre><code>df[df['colB'].apply(lambda x: pd.Series(x).isin(test_lst).sum()&gt;0)]

   colA              colB
0     1  [20, 40, 50, 60]
1     2      [20, 70, 80]
</code></pre>
",3968761.0,368.0,0
67236923,67236978,True,"<p>You can use <code>set.intersection</code>:</p>
<pre><code>test_lst = [20, 45, 35]
print(df[df.colB.apply(lambda x: set(x).intersection(test_lst)).astype(bool)])
</code></pre>
<p>Prints:</p>
<pre class=""lang-none prettyprint-override""><code>   colA              colB
0     1  [20, 40, 50, 60]
1     2      [20, 70, 80]
</code></pre>
",10035985.0,71901.0,5
55942672,67231762,False,"<p>Inside your animation function use <code>plt.close()</code><br />
For example if your last frame plotted was <code>iFrame = 9</code><br />
then:</p>
<pre class=""lang-py prettyprint-override""><code>if iFrame == 9:
    plt.close()
</code></pre>
",15748662.0,1.0,0
55942672,55942895,True,"<p>Maybe you want to use the animating function to decide when to close the figure.</p>

<pre><code>import numpy as np
import matplotlib.pyplot as plt
import matplotlib.animation as animation

fig = plt.figure()
ax = fig.add_subplot(1, 1, 1)

grid_size = [10, 10]
grid = np.random.randint(low=0, high=256, size=grid_size, dtype=np.uint8)
im = ax.imshow(grid, cmap='gray', vmin=0, vmax=255)

# Animation settings
def animate(frame):
    if frame == FRAMES_NUM:
        print(f'{frame} == {FRAMES_NUM}; closing!')
        plt.close(fig)
    else:
        print(f'frame: {frame}') # Debug: May be useful to stop
        grid = np.random.randint(low=0, high=256, size=grid_size, dtype=np.uint8)
        im.set_array(grid)

INTERVAL = 100
FRAMES_NUM = 10

anim = animation.FuncAnimation(fig, animate, interval=INTERVAL, 
                               frames=FRAMES_NUM+1, repeat=False)

plt.show()
</code></pre>
",4124317.0,246732.0,3
33852508,67239319,False,"<p>Just to add to this, to actually use a composite key, it's not that clear either.</p>
<p>Adding an object isn't too bad:</p>
<pre><code>myStore.add({
    id1: 'a',  // first part of key
    id2: 'b',  // second part of key
    etc: 'c',  // other data to store
});
</code></pre>
<p>However getting the object again using the composite key isn't all that obvious.  You need to pass an array as the key, with the values in the same order as the <code>keyPath</code> array originally passed to <code>createObjectStore()</code>.</p>
<pre><code>myStore.get(['a', 'b'])   // look for id1=a + id2=b
</code></pre>
<p>Here, the first value in the array (<code>a</code>) matches up with <code>keyPath[0]</code> which in the above answer is set to <code>id1</code>.</p>
",308237.0,19905.0,0
33852508,33852509,True,"<p><strong>A:</strong></p>

<p>As it turns out, the answer is very simple, but not documented well anywhere I have looked, and not obvious at first glance. Use an array of strings...</p>

<pre><code>var store = db.createObjectStore('myStore', 
    {keyPath: ['id1', 'id2']}
);
</code></pre>

<p>Composite indexes can also be created in the same fashion.</p>
",1905476.0,12083.0,36
67239221,67239259,True,"<h2>New answer</h2>
<p>You are getting the size of the string before the user has entered the string.</p>
<p>Change</p>
<pre><code>int size = input.size();

cin &gt;&gt; input;
</code></pre>
<p>to</p>
<pre><code>cin &gt;&gt; input:

int size = input.size();
</code></pre>
<h2>Previous answer</h2>
<p>You are using a single = rather than two in the if statement.</p>
<p>Change</p>
<pre><code>if (flag = true)
</code></pre>
<p>to</p>
<pre><code>if (flag == true)
</code></pre>
",15751739.0,53.0,1
19083100,19083130,True,"<p>Use Javascript/jQuery:</p>
<pre><code>$(document).on(&quot;click&quot;, &quot;#hi&quot;, function(){
    if ($(this).is(':checked')) {
        $('form').submit();
    }
});
</code></pre>
<p>All you need is to bind a function on the click event, and in that function, call submit() manually.</p>
",863637.0,17948.0,7
17796043,67239314,False,"<p>With go1.16, you can start using <code>embed</code>, this is standard package which helps you embed static non-go files into your binary</p>
<p>Documentation: <a href=""https://pkg.go.dev/embed"" rel=""nofollow noreferrer"">https://pkg.go.dev/embed</a> <br>
Example: <a href=""https://blog.carlmjohnson.net/post/2021/how-to-use-go-embed/"" rel=""nofollow noreferrer"">https://blog.carlmjohnson.net/post/2021/how-to-use-go-embed/</a></p>
<p>for go &lt; 1.16, you can use packr. It's an awesome tool, you can check out more about this at <a href=""https://github.com/gobuffalo/packr"" rel=""nofollow noreferrer"">https://github.com/gobuffalo/packr</a></p>
",8819631.0,170.0,0
17796043,29500100,False,"<h2>===== Edit Jan 2021 =====</h2>
<p>Starting with Go 1.16, released in Feb 2021, you can use the <a href=""https://tip.golang.org/pkg/embed/"" rel=""noreferrer""><code>go:embed</code></a> directive:</p>
<pre><code>import &quot;embed&quot;

//go:embed hello.txt
var s string
print(s)

//go:embed hello.txt
var b []byte
print(string(b))

//go:embed hello.txt
var f embed.FS
data, _ := f.ReadFile(&quot;hello.txt&quot;)
print(string(data))
</code></pre>
<h2>===== Original answer ======</h2>
<p>Since Go 1.4, you can use <a href=""https://blog.golang.org/generate"" rel=""noreferrer"">go generate</a> if you need more flexibility.</p>
<p>If you have more than one text file or the text file may change you might not want to hardcode the text file but include it at compile time.</p>
<p>If you have the following files:</p>
<pre><code>main.go
scripts/includetxt.go
a.txt
b.txt
</code></pre>
<p>And want to have access to the contents of all .txt files in main.go, you can include a special comment containing a go generate command.</p>
<h3>main.go</h3>
<pre><code>package main

import &quot;fmt&quot;

//go:generate go run scripts/includetxt.go

func main() {
    fmt.Println(a)
    fmt.Println(b)
}
</code></pre>
<p>The go generate command will run the script after <code>go:generate</code>. In this case it runs a go script which reads all text files and outputs them as string literals into a new file. I skipped the error handling for shorter code.</p>
<h3>script/includetxt.go</h3>
<pre><code>package main

import (
    &quot;io&quot;
    &quot;io/ioutil&quot;
    &quot;os&quot;
    &quot;strings&quot;
)

// Reads all .txt files in the current folder
// and encodes them as strings literals in textfiles.go
func main() {
    fs, _ := ioutil.ReadDir(&quot;.&quot;)
    out, _ := os.Create(&quot;textfiles.go&quot;)
    out.Write([]byte(&quot;package main \n\nconst (\n&quot;))
    for _, f := range fs {
        if strings.HasSuffix(f.Name(), &quot;.txt&quot;) {
            out.Write([]byte(strings.TrimSuffix(f.Name(), &quot;.txt&quot;) + &quot; = `&quot;))
            f, _ := os.Open(f.Name())
            io.Copy(out, f)
            out.Write([]byte(&quot;`\n&quot;))
        }
    }
    out.Write([]byte(&quot;)\n&quot;))
}
</code></pre>
<p>To compile all .txt files into your exectutable:</p>
<pre><code>$ go generate
$ go build -o main
</code></pre>
<p>Now your directory structure will look like:</p>
<pre><code>main.go
main
scripts/includetxt.go
textfiles.go
a.txt
b.txt
</code></pre>
<p>Where textfiles.go was generated by go generate and script/includetxt.go</p>
<h3>textfiles.go</h3>
<pre><code>package main 

const (
a = `hello`
b = `world`
)
</code></pre>
<p>And running main gives</p>
<pre><code>$ ./main
hello
world
</code></pre>
<p>This will work fine as long as you're encoding UTF8 encoded files. If you want to encode other files you have the full power of the go language (or any other tool) to do so. I used this technique to <a href=""http://golang.org/pkg/encoding/hex/"" rel=""noreferrer"">hex encode</a> png:s into a single executable. That requires a minor change to includetxt.go.</p>
",702065.0,2911.0,77
17796043,57829269,False,"<p>Was looking for the same thing and came across <a href=""https://mattjibson.com/esc/"" rel=""nofollow noreferrer"">esc: Embedding Static Assets in Go</a> (by 19 Nov 2014) where author, <a href=""https://github.com/mjibson"" rel=""nofollow noreferrer"">Matt Jibson</a>, is evaluating 3 other popular packages that claims to do file embedding:</p>
<ol>
<li><a href=""http://github.com/rakyll/statik"" rel=""nofollow noreferrer"">rakyll/statik</a></li>
<li><a href=""http://github.com/jteeuwen/go-bindata"" rel=""nofollow noreferrer"">jteeuwen/go-bindata</a> (and the new official <a href=""https://github.com/go-bindata/go-bindata"" rel=""nofollow noreferrer"">go-bindata/go-bindata</a> and another improved one <a href=""https://github.com/kevinburke/go-bindata"" rel=""nofollow noreferrer"">kevinburke/go-bindata</a>)</li>
<li><a href=""http://github.com/GeertJohan/go.rice"" rel=""nofollow noreferrer"">GeertJohan/go.rice</a></li>
</ol>
<p>and explain why he eventually come up with his own package:</p>
<ol start=""4"">
<li><strong><a href=""https://github.com/mjibson/esc/"" rel=""nofollow noreferrer"">mjibson/esc</a></strong></li>
</ol>
<p>So after briefly trying them all (in that order) I've naturally settled on Matt's <a href=""https://github.com/mjibson/esc/"" rel=""nofollow noreferrer"">esc</a> as it was the only one that was working out of the box <em>with necessary for me</em> functionality (HTTPS service in a single executable), namely:</p>
<ol>
<li>Can take some directories and recursively embed all files in them in a way that was compatible with <a href=""https://golang.org/src/net/http/fs.go?s=2511:2573#L77"" rel=""nofollow noreferrer"">http.FileSystem</a></li>
<li><strong>Can optionally be disabled</strong> for use with the local file system for local development without changing the client's code</li>
<li>Will not change the output file on subsequent runs has reasonable-sized diffs when files changed</li>
<li>Capable of doing the work via <code>//go:generate</code> instead of forcing you to manually write additional Go code</li>
</ol>
<p>The point <strong>#2</strong> was important for me and the rest of the packages for one reason or another didn't work out that well.</p>
<p>From esc's README:</p>
<blockquote>
<p>esc embeds files into go programs and provides http.FileSystem interfaces to them.</p>
<p>It adds all named files or files recursively under named directories at the path specified. The output file provides an http.FileSystem interface with zero dependencies on packages outside the standard library.</p>
</blockquote>
",1032261.0,5629.0,12
17796043,52919246,False,"<p>Based on @CoreyOgburn comment and this <a href=""https://github.com/rakyll/statik/issues/18#issuecomment-258438040"" rel=""nofollow noreferrer"">Github comment</a>, the following snippet was created:</p>

<pre><code>//go:generate statik -src=./html

package main

import (
    _ ""./statik""
    ""github.com/rakyll/statik/fs""
)

func statikFile() {
    s, _ := fs.New()
    f, _ := s.Open(""/tmpl/login.html"")
    b, _ := ioutil.ReadAll(f)
    t, _ := template.New(""login"").Parse(string(b))
    t.Execute(w, nil)
}
</code></pre>

<p>and run</p>

<pre><code>go generate
</code></pre>

<p>and subsequently</p>

<pre><code>go build
</code></pre>

<p>should create a binary that contains the files</p>
",2777965.0,7876.0,2
17796043,58256664,False,"<p>check <a href=""https://github.com/gobuffalo/packr"" rel=""noreferrer"">packr</a>, its quite friendly to use</p>

<pre class=""lang-golang prettyprint-override""><code>package main

import (
  ""net/http""

  ""github.com/gobuffalo/packr""
)

func main() {
  box := packr.NewBox(""./templates"")

  http.Handle(""/"", http.FileServer(box))
  http.ListenAndServe("":3000"", nil)
}
</code></pre>
",790330.0,1471.0,5
17796043,17797641,True,"<p>Use <a href=""https://github.com/go-bindata/go-bindata"" rel=""nofollow noreferrer"">go-bindata</a>. From the README:</p>

<blockquote>
  <p>This tool converts any file into managable Go source code. Useful for
  embedding binary data into a go program. The file data is optionally
  gzip compressed before being converted to a raw byte slice.</p>
</blockquote>
",836390.0,16539.0,31
17796043,37494288,False,"<p>I used a simple function to read an external template in a <code>go generate</code> run and to generate Go code from it. A function returning the template as a string will be generated. One can then parse the returned template string using <code>tpl, err := template.New(""myname"").Parse(mynameTemplate())</code></p>

<p>I did put that code to github. You might want to try <a href=""https://github.com/wlbr/templify"" rel=""nofollow"">https://github.com/wlbr/templify</a></p>

<p>Very simple, but works for me quite well.</p>
",1183146.0,105.0,2
17796043,17802019,False,"<p>You can use a <a href=""http://golang.org/ref/spec#String_literals"" rel=""noreferrer""><code>string literal</code></a> to define the text as a constant or variable. String literals are defined by enclosing the string with back-quotes. e.g. `string`.</p>

<p>For example:</p>

<pre><code>package main

import ""fmt""

func main() {
    const text = `
Lorem ipsum dolor sit amet, consectetur adipiscing elit. Donec a diam lectus. Sed sit  
amet ipsum mauris. Maecenas congue ligula ac quam viverra nec consectetur ante 
hendrerit. Donec et mollis dolor. Praesent et diam eget libero egestas mattis sit amet 
vitae augue. Nam tincidunt congue enim, ut porta lorem lacinia consectetur. Donec ut 
libero sed arcu vehicula ultricies a non tortor. Lorem ipsum dolor sit amet, 
consectetur adipiscing elit. Aenean ut gravida lorem. Ut turpis felis, pulvinar a 
semper sed, adipiscing id dolor. Pellentesque auctor nisi id magna consequat sagittis. 
Curabitur dapibus enim sit amet elit pharetra tincidunt feugiat nisl imperdiet. Ut 
convallis libero in urna ultrices accumsan. Donec sed odio eros. Donec viverra mi quis 
quam pulvinar at malesuada arcu rhoncus. Cum sociis natoque penatibus et magnis dis 
parturient montes, nascetur ridiculus mus. In rutrum accumsan ultricies. Mauris vitae 
nisi at sem facilisis semper ac in est.
`

    fmt.Println(text)
}
</code></pre>
",1567738.0,15631.0,5
67232463,67232872,False,"<p>Overall, the difference for those 2 methods are not huge and you will get the same result, except:</p>
<ul>
<li><code>$person-&gt;furnitures</code> uses relationships, quite similar to <a href=""https://laravel.com/docs/8.x/eloquent-relationships#eager-loading"" rel=""nofollow noreferrer"">eager loading</a> that it retrieves data based on the One to Many relationship.</li>
<li><code>$person-&gt;furnitures()-&gt;get()</code> is implemented from the perspective of collection, which is why it has the syntax of querying a collection.</li>
</ul>
",8947552.0,220.0,1
67232463,67233411,True,"<p>The given answers are vague and incomplete, so here's a better explanation hopefully:</p>
<p><strong>Situation 1 <code>$person-&gt;furnitures()</code>:</strong> When you call any of a model's relations as a <em>function</em>, you get an (incomplete) query object for that particular relation. That means whenever you call <code>$person-&gt;furnitures()</code>, any additional functions you chain on this result like <code>-&gt;where()</code> are actual SQL operators and directly modify the query. In order to complete the query, you <em>should</em> call <code>-&gt;get()</code> (or a function like <code>-&gt;pluck()</code>) at the end to retrieve the actual data.</p>
<p><strong>Situation 2 <code>$person-&gt;furnitures</code>:</strong> When you call any of a model's relations as a <em>property</em>, you retrieve the complete relation collection for that model. This means that <code>$person-&gt;furnitures</code> lazy-loads the collection if it is not available on the model yet. Any additional functions you chain on this result like <code>-&gt;where()</code> will act on the PHP collection.</p>
<hr />
<p>By using <code>Person::with('furnitures')...</code> you make sure that the relation is already loaded (<a href=""https://laravel.com/docs/8.x/eloquent-relationships#eager-loading"" rel=""nofollow noreferrer"">Eager Loaded</a>) after the <code>findOrFail()</code> call. You might note that this is not particularly useful with respect to loading 1 model (since you might just as well call <code>$person-&gt;furnitures</code> whenever you need it), but the important thing to remember here is that this <a href=""https://laravel.com/docs/8.x/eloquent-relationships#eager-loading"" rel=""nofollow noreferrer""><code>with()</code></a> method is extremely useful when you are retrieving collections of a model, like <code>$persons = Person::where('activated', 1)-&gt;with('furnitures')-&gt;get()</code>. This last query only executes 2 queries: 1 for retrieving persons, and 1 for retrieving all furniture related to these persons.</p>
",1346367.0,3151.0,2
67232463,67233190,False,"<p>They are same, but <code>$person-&gt;furnitures</code> requires extra steps to understand tha this is relation, and finally call <code>$person-&gt;furnitures()-&gt;get()</code></p>
",12760472.0,304.0,0
810,818,False,"<p>I'm partway to my solution with this entry on MSDN (don't know how I couldn't find it before).</p>

<p>User/Machine Hive<br>
Subkeys and values entered under this hive will be installed under the HKEY_CURRENT_USER hive when a user chooses ""Just Me"" or the HKEY_USERS hive or when a user chooses ""Everyone"" during installation.</p>

<p><s><a href=""http://msdn.microsoft.com/en-us/library/x6kd89c5(VS.80).aspx"" rel=""nofollow noreferrer"">Registry Editor</a></s> <a href=""http://web.archive.org/web/20100112132447/http://msdn.microsoft.com/en-us/library/x6kd89c5(VS.80).aspx"" rel=""nofollow noreferrer"">Archive of MSDN Article</a></p>
",233.0,43255.0,1
810,870,False,"<p>Despite what the <s><a href=""http://msdn.microsoft.com/en-us/library/x6kd89c5(VS.80).aspx"" rel=""nofollow noreferrer"">MSDN article</a></s> <a href=""http://web.archive.org/web/20100112132447/http://msdn.microsoft.com/en-us/library/x6kd89c5(VS.80).aspx"" rel=""nofollow noreferrer"">Archive of MSDN Article</a>  says about User/Machine Hive, it doesn't write to HKEY_USERS. Rather it writes to HKCU if you select Just Me and HKLM if you select everyone.</p>

<p>So my solution is going to be to use the User/Machine Hive, and then in the application it checks if the registry entries are in HKCU and if not, copies them from HKLM. I know this probably isn't the most ideal way of doing it, but it has the least amount of changes.</p>
",233.0,43255.0,1
810,829,False,"<p>I'm guessing that because you want to set it for all users, that you're on some kind of shared computer, which is probably running under a domain?</p>

<p><strong>HERE BE DRAGONS</strong></p>

<p>Let's say Joe and Jane regularly log onto the computer, then they will each have 'registries'.</p>

<p>You'll then install your app, and the installer will employ giant hacks and disgusting things to set items under HKCU for them.</p>

<p>THEN, bob will come along and log on (he, and 500 other people have accounts in the domain and so can do this). He's never used this computer before, so he has no registry. The first time he logs in, windows creates him one, but he won't have your setting. </p>

<p>Your app then falls over or behaves incorrectly, and bob complains loudly about those crappy products from raynixon incorporated.</p>

<p>The correct answer is to just have some default settings in your app, which can write them to the registry if it doesn't find them. It's general good practice that your app should never depend on the registry, and should create things as needed, for any registry entry, not just HKCU, anyway</p>
",234.0,113281.0,5
810,820,True,"<p>First: Yes, this is something that belongs in the Application for the exact reson you specified: What happens after new user profiles are created? Sure, if you're using a domain it's possible to have some stuff put in the registry on creation, but this is not really a use case. The Application should check if there are seetings and use the default settings if not.</p>

<p>That being said, it IS possible to change other users Keys through the HKEY_USERS Hive.</p>

<p>I have no experience with the Visual Studio 2003 Setup Project, so here is a bit of (totally unrelated) VBScript code that might just give you an idea where to look:</p>

<pre><code>const HKEY_USERS = &amp;H80000003
strComputer = "".""
Set objReg=GetObject(""winmgmts:{impersonationLevel=impersonate}!\\"" &amp; strComputer &amp; ""\root\default:StdRegProv"")
strKeyPath = """"
objReg.EnumKey HKEY_USERS, strKeyPath, arrSubKeys
strKeyPath = ""\Software\Microsoft\Windows\CurrentVersion\WinTrust\Trust Providers\Software Publishing""
For Each subkey In arrSubKeys
    objReg.SetDWORDValue HKEY_USERS, subkey &amp; strKeyPath, ""State"", 146944
Next
</code></pre>

<p>(Code Courtesy of <a href=""http://jritmeijer.spaces.live.com/blog/cns!8A48A27460FB898A!965.entry"" rel=""noreferrer"">Jeroen Ritmeijer</a>)</p>
",91.0,166977.0,5
826,7842,False,"<p>You can do this in two lines in python with</p>
<pre><code>allSums = set(a+b for a in X for b in X)
allSums = sorted(allSums)
</code></pre>
<p>The cost of this is <code>n^2</code> (maybe an extra log factor for the set?) for the iteration and s * log(s) for the sorting where s is the size of the set.</p>
<p>The size of the set could be as big as <code>n*(n-1)/2</code> for example if <code>X = [1,2,4,...,2^n]</code>. So if you want to generate this list it will take at least <code>n^2/2</code> in the worst case since this is the size of the output.</p>
<p>However if you want to select the first k elements of the result you can do this in O(kn) using a selection algorithm for sorted <code>X+Y</code> matrices by Frederickson and Johnson (<a href=""http://arxiv.org/abs/0804.0936"" rel=""nofollow noreferrer"">see here for gory details)</a>. Although this can probably be modified to generate them online by reusing computation and get an efficient generator for this set.</p>
<p>@deuseldorf, Peter
There is some confusion about <code>(n!)</code> I seriously doubt deuseldorf meant &quot;n factorial&quot; but simply &quot;n, (very excited)!&quot;</p>
",,,2
826,97294,True,"<p>Edit as of 2018: You should probably stop reading this. (But I can't delete it as it is accepted.)</p>

<p>If you write out the sums like this:</p>

<pre><code>1 4  5  6  8  9
---------------
2 5  6  7  9 10
  8  9 10 12 13
    10 11 13 14
       12 14 15
          16 17
             18
</code></pre>

<p>You'll notice that since M[i,j] &lt;= M[i,j+1] and M[i,j] &lt;= M[i+1,j], then you only need to examine the top left ""corners"" and choose the lowest one.</p>

<p>e.g.</p>

<ul>
<li>only 1 top left corner, pick 2</li>
<li>only 1, pick 5</li>
<li>6 or 8, pick 6</li>
<li>7 or 8, pick 7</li>
<li>9 or 8, pick 8</li>
<li>9 or 9, pick both :)</li>
<li>10 or 10 or 10, pick all</li>
<li>12 or 11, pick 11</li>
<li>12 or 12, pick both</li>
<li>13 or 13, pick both</li>
<li>14 or 14, pick both</li>
<li>15 or 16, pick 15</li>
<li>only 1, pick 16</li>
<li>only 1, pick 17</li>
<li>only 1, pick 18</li>
</ul>

<p>Of course, when you have <em>lots</em> of top left corners then this solution devolves.</p>

<p>I'm pretty sure this problem is Ω(n²), because you have to calculate the sums for each M[i,j] -- unless someone has a better algorithm for the summation :)</p>
",10311.0,28662.0,12
826,884,False,"<p>Rather than coding this out, I figure I'll pseudo-code it in steps and explain my logic, so that better programmers can poke holes in my logic if necessary. </p>

<p>On the first step we start out with a list of numbers length n. For each number we need to create a list of length n-1 becuase we aren't adding a number to itself. By the end we have a list of about n sorted lists that was generated in O(n^2) time.</p>

<pre><code>step 1 (startinglist) 
for each number num1 in startinglist
   for each number num2 in startinglist
      add num1 plus num2 into templist
   add templist to sumlist
return sumlist 
</code></pre>

<p>In step 2 because the lists were sorted by design (add a number to each element in a sorted list and the list will still be sorted) we can simply do a mergesort by merging each list together rather than mergesorting the whole lot.  In the end this should take O(n^2) time.</p>

<pre><code>step 2 (sumlist) 
create an empty list mergedlist
for each list templist in sumlist
   set mergelist equal to: merge(mergedlist,templist)
return mergedlist
</code></pre>

<p>The merge method would be then the normal merge step with a check to make sure that there are no duplicate sums.  I won't write this out because anyone can look up mergesort.</p>

<p>So there's my solution.  The entire algorithm is O(n^2) time.  Feel free to point out any mistakes or improvements.</p>
",159.0,1561.0,4
826,20701,False,"<p>This question has been wracking my brain for about a day now. Awesome.</p>

<p>Anyways, you can't get away from the n^2 nature of it easily, but you can do slightly better with the merge since you can bound the range to insert each element in.</p>

<p>If you look at all the lists you generate, they have the following form:</p>

<p><code>(a[i], a[j]) | j&gt;=i</code></p>

<p>If you flip it 90 degrees, you get:</p>

<p><code>(a[i], a[j]) | i&lt;=j</code></p>

<p>Now, the merge process should be taking two lists <code>i</code> and <code>i+1</code> (which correspond to lists where the first member is always <code>a[i]</code> and <code>a[i+1]</code>), you can bound the range to insert element <code>(a[i + 1], a[j])</code> into list <code>i</code> by the location of <code>(a[i], a[j])</code> and the location of <code>(a[i + 1], a[j + 1])</code>.</p>

<p>This means that you should merge in reverse in terms of <code>j</code>. I don't know (yet) if you can leverage this across <code>j</code> as well, but it seems possible.</p>
",1799.0,1058.0,1
826,97567,False,"<p>No matter what you do, without additional constraints on the input values, you cannot do better than O(n^2), simply because you have to iterate through all pairs of numbers.  The iteration will dominate sorting (which you can do in O(n log n) or faster).</p>
",18308.0,13110.0,1
826,6458,False,"<p>In SQL:</p>

<pre><code>create table numbers(n int not null)
insert into numbers(n) values(1),(1), (2), (2), (3), (4)


select distinct num1.n+num2.n sum2n
from numbers num1
inner join numbers num2 
    on num1.n&lt;&gt;num2.n
order by sum2n
</code></pre>

<p>C# LINQ:</p>

<pre><code>List&lt;int&gt; num = new List&lt;int&gt;{ 1, 1, 2, 2, 3, 4};
var uNum = num.Distinct().ToList();
var sums=(from num1 in uNum
        from num2 in uNum 
        where num1!=num2
        select num1+num2).Distinct();
foreach (var s in sums)
{
    Console.WriteLine(s);
}
</code></pre>
",224.0,8502.0,1
826,840,False,"<p>The best I could come up with is to produce a matrix of sums of each pair, and then merge the rows together, a-la merge sort.  I feel like I'm missing some simple insight that will reveal a much more efficient solution.</p>

<p>My algorithm, in Haskell:</p>

<pre><code>matrixOfSums list = [[a+b | b &lt;- list, b &gt;= a] | a &lt;- list]

sortedSums = foldl merge [] matrixOfSums

--A normal merge, save that we remove duplicates
merge xs [] = xs
merge [] ys = ys
merge (x:xs) (y:ys) = case compare x y of
    LT -&gt; x:(merge xs (y:ys))
    EQ -&gt; x:(merge xs (dropWhile (==x) ys))
    GT -&gt; y:(merge (x:xs) ys)
</code></pre>

<p>I found a minor improvement, one that's more amenable to lazy stream-based coding.  Instead of merging the columns pair-wise, merge all of them at once.  The advantage being that you start getting elements of the list immediately.</p>

<pre><code>-- wide-merge does a standard merge (ala merge-sort) across an arbitrary number of lists
-- wideNubMerge does this while eliminating duplicates
wideNubMerge :: Ord a =&gt; [[a]] -&gt; [a]
wideNubMerge ls = wideNubMerge1 $ filter (/= []) ls
wideNubMerge1 [] = []
wideNubMerge1 ls = mini:(wideNubMerge rest)
    where mini = minimum $ map head ls
          rest = map (dropWhile (== mini)) ls

betterSortedSums = wideNubMerge matrixOfSums
</code></pre>

<p>However, if you know you're going to use all of the sums, and there's no advantage to getting some of them earlier, go with '<code>foldl merge []</code>', as it's faster.</p>
",101.0,42113.0,1
826,834,False,"<p>If you are looking for a truly language agnostic solution then you will be sorely disappointed in my opinion because you'll be stuck with a for loop and some conditionals. However if you opened it up to functional languages or functional language features (I'm looking at you LINQ) then my colleagues here can fill this page with elegant examples in Ruby, Lisp, Erlang, and others.</p>
",200.0,12856.0,-4
832,33140,False,"<p>This isn't a full answer for you, but on the left join piece you can use the DefaultIfEmpty operator like so:</p>

<pre><code>var collection = 
from u in db.Universe
join history in db.History on u.id = history.id into temp
from h in temp.DefaultIfEmpty()
where h.dateCol &lt; DateTime.Now.Date.AddDays(-1)
select u.id, u.name, h.dateCol ?? '1900-01-01'
</code></pre>

<p>I haven't had the need to do any <code>groupby</code> commands yet, so I left that out as to not send you down the wrong path.  Two other quick things to note.  I have been unable to actually join on two parameters although as above there are ways to get around it.  Also, the ?? operator works really well in place of the <code>isnull</code> in SQL.  </p>
",2176.0,7710.0,0
832,36693733,False,"<pre><code>var collection=
    from u in db.Universe
    select new
    {
        u.id,
        u.name,
        MaxDate =(DateTime?)
       (
           from h in db.History
           where u.Id == h.Id
           &amp;&amp; h.dateCol &lt; yesterday
           select h.dateCol 
       ).Max()
    };
</code></pre>

<p>Just youse the above code and this should work fine!</p>
",,,1
832,837,True,"<p>A solution, albeit one that defers handling of the null value to the code, could be:</p>

<blockquote>
  <p>DateTime yesterday = DateTime.Now.Date.AddDays(-1);</p>
</blockquote>

<pre><code>var collection=
    from u in db.Universe
    select new
    {
        u.id,
        u.name,
        MaxDate =(DateTime?)
       (
           from h in db.History
           where u.Id == h.Id
           &amp;&amp; h.dateCol &lt; yesterday
           select h.dateCol 
       ).Max()
    };
</code></pre>

<p>This does not produce exactly the same SQL, but does provide the same logical result. Translating ""complex"" SQL queries to LINQ is not always straightforward.</p>
",224.0,8502.0,9
832,80296,False,"<p>You're going to want to use the <code>join into</code> construct to create a group query.</p>

<pre><code>TestContext db = new TestContext(CreateSparqlTripleStore());
var q = from a in db.Album
        join t in db.Track on a.Name equals t.AlbumName into tracks
        select new Album{Name = a.Name, Tracks = tracks};
foreach(var album in q){
    Console.WriteLine(album.Name);
    foreach (Track track in album.Tracks)
    {
        Console.WriteLine(track.Title);
    }
}
</code></pre>
",7756.0,17933.0,0
833,10437,False,"<p>Another option is to test that the values in the record that you are changing are the still the same as they were when you started: </p>

<pre><code>SELECT 
    customer_nm,
    customer_nm AS customer_nm_orig
FROM demo_customer
WHERE customer_id = @p_customer_id
</code></pre>

<p>(display the customer_nm field and the user changes it)</p>

<pre><code>UPDATE demo_customer
SET customer_nm = @p_customer_name_new
WHERE customer_id = @p_customer_id
AND customer_name = @p_customer_nm_old

IF @@ROWCOUNT = 0
    RAISERROR( 'Update failed: Data changed' );
</code></pre>

<p>You don't have to add a new column to your table (and keep it up to date), but you do have to create more verbose SQL statements and pass <em>new</em> and <em>old</em> fields to the stored procedure.</p>

<p>It also has the advantage that you are not locking the records - because we all know that records will end up staying locked when they should not be...</p>
",993.0,9115.0,1
833,38372873,False,"<p>-first create filed (update time) to store last update record
-when any user select record save select time,
compare between select time and update time field if( update time) > (select time) that mean another user update this record after select record</p>
",6589135.0,21.0,2
833,1620,False,"<p>@ Mark Harrison : SQL Server does not support that syntax (<code>SELECT ... FOR UPDATE</code>).</p>

<p>The SQL Server equivalent is the <code>SELECT</code> statement hint <code>UPDLOCK</code>.</p>

<p>See <a href=""http://msdn.microsoft.com/en-us/library/ms187373.aspx"" rel=""nofollow noreferrer"">SQL Server Books Online</a> for more information.</p>
",318.0,13365.0,1
833,838,True,"<p>If you expect infrequent collisions, <a href=""http://msdn.microsoft.com/en-us/library/aa0416cz.aspx"" rel=""noreferrer"">Optimistic Concurrency</a> is probably your best bet.</p>

<p>Scott Mitchell wrote a comprehensive tutorial on implementing that pattern:<br>
<a href=""http://www.asp.net/Learn/data-access/tutorial-21-cs.aspx"" rel=""noreferrer"">Implementing Optimistic Concurrency</a></p>
",60.0,56986.0,15
833,6464596,False,"<p>With me, the best way i have a column lastupdate (timetamp datatype).
when select and update just compare this value
another advance of this solution is that you can use this column to track down the time data has change.
I think it is not good if you just create a colum like isLock for check update.</p>
",573668.0,11.0,0
833,156759,False,"<p>A classic approach is as follows: </p>

<ul>
<li>add a boolean field , ""locked"" to each table.  </li>
<li>set this to false by default. </li>
<li><p>when a user starts editing, you do this: </p>

<ul>
<li>lock the row (or the whole table if you can't lock the row) </li>
<li>check the flag on the row you want to edit</li>
<li>if the flag is true then 

<ul>
<li>inform the user that they cannot edit that row at the moment</li>
</ul></li>
<li>else

<ul>
<li>set the flag to true</li>
</ul></li>
<li><p>release the lock</p></li>
<li><p>when saving the record, set the flag back to false</p></li>
</ul></li>
</ul>
",7211.0,12593.0,3
833,156358,False,"<p>SELECT FOR UPDATE and equivalents are good providing you hold the lock for a microscopic amount of time, but for a macroscopic amount (e.g. the user has the data loaded and hasn't pressed 'save' you should use optimistic concurrency as above.  (Which I always think is misnamed - it's more pessimistic than 'last writer wins', which is usually the only other alternative considered.)</p>
",,,1
833,981,False,"<p>The database will do this for you.  Look at ""select ... for update"", which is designed just for this kind of thing.  It will give you a write lock on the selected rows, which you can then commit or roll back.</p>
",116.0,265948.0,0
835,1281,False,"<p>You can use the artifact directory variable inside the MSBuild script itself.  Here's an example of how I'm running FxCop right now from my CC.Net MSBuild script (this script is what CC.Net points to - there is also a ""Build"" target in the script that includes an MSBuild task against the SLN to do the actual compilation):</p>

<pre><code>&lt;Exec
  Command='FxCopCmd.exe /project:""$(MSBuildProjectDirectory)\FXCopRules.FxCop"" /out:""$(CCNetArtifactDirectory)\ProjectName.FxCop.xml""'
  WorkingDirectory=""C:\Program Files\Microsoft FxCop 1.35""
  ContinueOnError=""true""
  IgnoreExitCode=""true""
/&gt;
</code></pre>
",35.0,17207.0,5
835,2343524,False,"<p>Parameters like <code>CCNetArtifactDirectory</code> are passed to external programs using environment variables. They are available in the external program but they aren't inside <code>CCNET</code> configuration. This often leads to confusion.</p>

<p>You can use a preprocessor constant instead: </p>

<pre><code>&lt;cb:define project.artifactDirectory=""C:\foo""&gt;
&lt;project&gt;
  &lt;!-- [...] --&gt;
  &lt;artifactDirectory&gt;$(project.artifactDirectory)&lt;/artifactDirectory&gt;
  &lt;!-- [...] --&gt;
  &lt;tasks&gt;
    &lt;!-- [...] --&gt;
    &lt;msbuild&gt;
      &lt;!-- [...] --&gt;
      &lt;buildArgs&gt;/noconsolelogger /p:OutputPath=$(project.artifactDirectory)\test&lt;/buildArgs&gt;
      &lt;!-- [...] --&gt;
    &lt;/msbuild&gt;
    &lt;!-- [...] --&gt;
  &lt;/tasks&gt;
  &lt;!-- [...] --&gt;
&lt;/project&gt;
</code></pre>
",38029.0,6851.0,2
835,1023,True,"<p>The CCNetArtifactDirectory is passed to the MSBuild by default, so you dont need to worry about it. MSBuild will place the build output in the ""bin location"" relevant to the working directory that you have specified.</p>

<pre><code>&lt;executable&gt;c:\WINDOWS\Microsoft.NET\Framework\v3.5\MSBuild.exe&lt;/executable&gt;
&lt;workingDirectory&gt;C:\data\projects\FooSolution\&lt;/workingDirectory&gt;
&lt;projectFile&gt;FooSolution.sln&lt;/projectFile&gt;
&lt;buildArgs&gt;/noconsolelogger /p:Configuration=Debug &lt;/buildArgs&gt;
</code></pre>

<p>So in the above example your build output will be put in C:\data\projects\FooSolution[ProjectName]\bin\Debug. Should you want to output to a different location you may want to look at of the  tag in CCNET.</p>

<pre><code>&lt;publishers&gt;
  &lt;xmllogger /&gt;
  &lt;buildpublisher&gt;
    &lt;sourceDir&gt;C:\data\projects\FooSolution\FooProject\bin\Debug&lt;/sourceDir&gt;
    &lt;publishDir&gt;C:\published\FooSolution\&lt;/publishDir&gt;
    &lt;useLabelSubDirectory&gt;false&lt;/useLabelSubDirectory&gt;
  &lt;/buildpublisher&gt;
&lt;/publishers&gt;
</code></pre>

<p>This will allow you to publish your output to a different location.</p>
",231.0,9610.0,6
845,8741592,False,"<p>Another solution would be to install the font automatically via <code>@font-face</code> which might negate the need for detection.</p>
<pre class=""lang-css prettyprint-override""><code>@font-face {
  font-family: &quot;Calibri&quot;;
  src: url(&quot;http://www.yourwebsite.com/fonts/Calibri.eot&quot;);
  src: local(&quot;Calibri&quot;), url(&quot;http://www.yourwebsite.com/fonts/Calibri.ttf&quot;) format(&quot;truetype&quot;);
}
</code></pre>
<p>Of course it wouldn't solve any copyright issues, however you could always use a freeware font or even make your own font. You will need both <code>.eot</code> &amp; <code>.ttf</code> files to work best.</p>
",1131991.0,87.0,7
845,8307897,False,"<p>There is a simple solution - just use <code>element.style.font</code>:</p>

<pre><code>function getUserBrowsersFont() {
    var browserHeader = document.getElementById('header');
    return browserHeader.style.font;
}
</code></pre>

<p>This function will  exactly do what you want. On execution It will return the font type of the user/browser. Hope this will help.</p>
",1067051.0,2269.0,10
845,887291,False,"<p>@pat Actually, Safari does not give the font used, Safari instead always returns the first font in the stack regardless of whether it is installed, at least in my experience.</p>

<pre><code>font-family: ""my fake font"", helvetica, san-serif;
</code></pre>

<p>Assuming Helvetica is the one installed/used, you'll get:</p>

<ul>
<li>""my fake font"" in Safari (and I believe other webkit browsers).</li>
<li>""my fake font, helvetica, san-serif"" in Gecko browsers and IE. </li>
<li>""helvetica"" in Opera 9, though I read that they are changing this in Opera 10 to match
Gecko.</li>
</ul>

<p>I took a pass at this problem and created <a href=""http://github.com/philoye/fontunstack/tree/master"" rel=""nofollow noreferrer"">Font Unstack</a>, which tests each font in a stack and returns the first installed one only. It uses the trick that @MojoFilter mentions, but only returns the first one if multiple are installed. Though it does suffer from the weakness that @tlrobinson mentions (Windows will substitute Arial for Helvetica silently and report that Helvetica is installed), it otherwise works well.</p>
",109864.0,2400.0,11
845,849,True,"<p>I've seen it done in a kind of iffy, but pretty reliable way. Basically, an element is set to use a specific font and a string is set to that element.  If the font set for the element does not exist, it takes the font of the parent element.  So, what they do is measure the width of the rendered string.  If it matches what they expected for the desired font as opposed to the derived font, it's present. This won't work for monospaced fonts.</p>

<p>Here's where it came from:
<a href=""http://ajaxian.com/archives/javascriptcss-font-detector"" rel=""noreferrer"">Javascript/CSS Font Detector (ajaxian.com; 12 Mar 2007)</a></p>
",93.0,11651.0,77
845,47571799,False,"<p>You can put <a href=""https://technet.microsoft.com/en-us/library/cc939627.aspx"" rel=""nofollow noreferrer"">Adobe Blank</a> in the font-family after the font you want to see, and then any glyphs not in that font won't be rendered.</p>

<p>e.g.:</p>

<pre><code>font-family: Arial, 'Adobe Blank';
</code></pre>

<p>As far as I'm aware there is no JS method to tell which glyphs in an element are being rendered by which font in the font stack for that element.</p>

<p>This is complicated by the fact that browsers have user settings for serif/sans-serif/monospace fonts and they also have their own hard-coded fall-back fonts that they will use if a glyph is not found in any of the fonts in a font stack. <strong>So browser may render some glyphs in a font that is not in the font stack or the user's browser font setting.</strong> <a href=""https://developers.google.com/web/updates/2013/09/DevTools-answers-What-font-is-that"" rel=""nofollow noreferrer"">Chrome Dev Tools will show you each rendered font for the glyphs in the selected element</a>. So on your machine you can see what it's doing, but there's no way to tell what's happening on a user's machine.</p>

<p>It's also possible the user's system may play a part in this as e.g. <a href=""https://docs.microsoft.com/en-us/globalization/input/font-technology#font-linking"" rel=""nofollow noreferrer"">Window does Font Substitution</a> at the glyph level.</p>

<p>so...</p>

<p>For the glyphs you are interested in, you have no way of knowing whether they will be rendered by the user's browser/system fallback, even if they don't have the font you specify.</p>

<p>If you want to test it in JS you could render individual glyphs with a font-family including Adobe Blank and measure their width to see if it is zero, <strong>BUT</strong> you'd have to iterate thorough each glyph and <strong>each font you wanted to test</strong>, but although you can know the fonts in an elements font stack there is no way of knowing what fonts the user's browser is configured to use so for at least some of your users the list of fonts you iterate through will be incomplete. (It is also not future proof if new fonts come out and start getting used.)</p>
",2541.0,13260.0,1
845,29582806,False,"<p>You can use this website :</p>

<p><a href=""http://website-font-analyzer.com/"" rel=""nofollow noreferrer"">http://website-font-analyzer.com/</a></p>

<p>It does exactly what you want...</p>
",2267379.0,749.0,1
845,42756664,False,"<p>I am using Fount. You just have to drag the Fount button to your bookmarks bar, click on it and then click on a specific text on the website. It will then show the font of that text. </p>

<p><a href=""https://fount.artequalswork.com/"" rel=""nofollow noreferrer"">https://fount.artequalswork.com/</a></p>
",2098493.0,4468.0,2
845,6083463,False,"<p>I wrote a simple JavaScript tool that you can use it to check if a font is installed or not.<br>
It uses simple technique and should be correct most of the time.
<br></p>

<p><strong><a href=""https://github.com/derek1906/jFont-Checker/"" rel=""noreferrer"">jFont Checker</a></strong> on github</p>
",283863.0,84240.0,35
845,13385418,False,"<p>Calibri is a font owned by Microsoft, and shouldn't be distributed for free. Also, requiring a user to download a specific font isn't very user-friendly. </p>

<p>I would suggest purchasing a license for the font and embedding it into your application.</p>
",1090092.0,197.0,4
845,27035,False,"<p>A technique that works is to look at the computed style of the element. This is supported in Opera and Firefox (and I recon in safari, but haven't tested). IE (7 at least), provides a method to get a style, but it seems to be whatever was in the stylesheet, not the computed style. More details on quirksmode: <a href=""http://www.quirksmode.org/dom/getstyles.html"" rel=""noreferrer"">Get Styles</a></p>

<p>Here's a simple function to grab the font used in an element:</p>

<pre><code>/**
 * Get the font used for a given element
 * @argument {HTMLElement} the element to check font for
 * @returns {string} The name of the used font or null if font could not be detected
 */
function getFontForElement(ele) {
    if (ele.currentStyle) { // sort of, but not really, works in IE
        return ele.currentStyle[""fontFamily""];
    } else if (document.defaultView) { // works in Opera and FF
        return document.defaultView.getComputedStyle(ele,null).getPropertyValue(""font-family"");
    } else {
        return null;
    }
}
</code></pre>

<p>If the CSS rule for this was:</p>

<pre><code>#fonttester {
    font-family: sans-serif, arial, helvetica;
}
</code></pre>

<p>Then it should return helvetica if that is installed, if not, arial, and lastly, the name of the system default sans-serif font. Note that the ordering of fonts in your CSS declaration is significant.</p>

<p>An interesting hack you could also try is to create lots of hidden elements with lots of different fonts to try to detect which fonts are installed on a machine. I'm sure someone could make a nifty font statistics gathering page with this technique.</p>
",2906.0,3291.0,10
845,7866425,False,"<p>A simplified form is:</p>

<pre><code>function getFont() {
    return document.getElementById('header').style.font;
}
</code></pre>

<p>If you need something more complete, check <a href=""http://www.lalit.org/lab/javascript-css-font-detect/#comment-43"" rel=""noreferrer"">this</a> out.</p>
",1009517.0,109.0,9
855,1120,False,"<p>I've just set up Sandcastle again. Try installing it (the May 2008 release) and search for SandcastleGui.exe or something similar (it's in the examples folder or so).</p>

<p>Click Add Assembly and add your Assembly or Assemblies, add any .xml Documentation files (the ones generated by the compiler if you enabled that option) and then Build.</p>

<p>It will take some time, but the result <strong>will</strong> be worth the effort. It will actually look up stuff from MSDN, so your resulting documentation will also have the Class Inheritance all the way down to System.Object with links to MSDN and stuff.</p>

<p>Sandcastle seems a bit complicated at first, especially when you want to use it in an automated build, but I am absolutely sure it will be worth the effort.</p>

<p>Also have a look at <a href=""http://www.codeplex.com/SHFB"" rel=""nofollow noreferrer"">Sandcastle Help File Builder</a>, this is a somewhat more advanced GUI for it.</p>
",91.0,166977.0,4
855,858,True,"<p>You're looking for Sandcastle</p>

<p>Project Page: <a href=""http://www.codeplex.com/Sandcastle/Release/ProjectReleases.aspx"" rel=""nofollow noreferrer"">Sandcastle Releases</a></p>

<p>Blog: <a href=""http://blogs.msdn.com/sandcastle/default.aspx"" rel=""nofollow noreferrer"">Sandcastle Blog</a></p>

<p><a href=""http://ndoc.sourceforge.net"" rel=""nofollow noreferrer"">NDoc Code Documentation Generator for .NET</a> used to be the tool of choice, but support has all but stopped.</p>
",34.0,20440.0,10
855,102768,False,"<p>You should also use the Sandcastle Help File Builder. It provides you with a ndoc like GUI for generating help files so you don't have to do anything from a command prompt.</p>

<p><a href=""http://www.codeplex.com/SHFB"" rel=""nofollow noreferrer"">Welcome to the Sandcastle Help File Builder Project</a></p>
",26932.0,7149.0,5
855,2307656,False,"<p>I use <a href=""http://sourceforge.net/projects/ndoc3/"" rel=""nofollow noreferrer"">NDoc3</a></p>
",10793.0,5453.0,2
855,1123,False,"<p>Follow <a href=""http://saftsack.fs.uni-bayreuth.de/~dun3/archives/integrate-xml-code-comments-into-visual-studio-20052008-using-sandcastle-and-html-help-20/150.html"" rel=""nofollow noreferrer"">this simple 5 step article</a> and you are pretty much done. As a bonus you can use <a href=""http://www.helpware.net/mshelp2/h2viewer.htm"" rel=""nofollow noreferrer"">H2Viewer</a> to view Html Help 2.x files.</p>
",39.0,14412.0,4
855,859,False,"<p>Have a look at <a href=""http://blogs.msdn.com/sandcastle/"" rel=""noreferrer"">Sandcastle</a>, which does exactly that. It's also one of the more simpler solutions out there, and it's more or less the tool of choice, so in the long run, maybe we could help you to set up Sandcastle if you specify what issues you encountered during setup?</p>
",91.0,166977.0,5
871,531042,False,"<p>""<a href=""http://whygitisbetterthanx.com/#svn"" rel=""nofollow noreferrer"">Why Git is Better than X</a>"" outlines the various pros and cons of Git vs other SCMs.</p>

<p>Briefly:</p>

<ul>
<li>Git tracks <strong>content rather than files</strong></li>
<li><strong>Branches are lightweight</strong> and merging is <em>easy</em>, and I mean <em>really easy</em>.</li>
<li>It's distributed, basically every repository is a branch. It's much easier to develop concurrently and collaboratively than with Subversion, in my opinion. It also makes <strong>offline</strong> development possible.</li>
<li>It <strong>doesn't impose any workflow</strong>, as seen on <a href=""http://whygitisbetterthanx.com/#svn"" rel=""nofollow noreferrer"">the above linked website</a>, there are many workflows possible with Git. A Subversion-style workflow is easily mimicked.</li>
<li>Git repositories are much <strong>smaller in file size</strong> than Subversion repositories. There's only one "".git"" directory, as opposed to dozens of "".svn"" repositories (note Subversion 1.7 and higher <a href=""http://subversion.apache.org/docs/release-notes/1.7.html#wc-ng"" rel=""nofollow noreferrer"">now uses a single directory</a> like Git.)</li>
<li>The <strong>staging</strong> area is awesome, it allows you to see the changes you will commit, commit partial changes and do various other stuff.</li>
<li><strong>Stashing</strong> is invaluable when you do ""chaotic"" development, or simply want to fix a bug while you're still working on something else (on a different branch).</li>
<li>You can <strong>rewrite history</strong>, which is great for preparing patch sets and fixing your mistakes (<em>before</em> you publish the commits)</li>
<li>… and a <em>lot</em> more.</li>
</ul>

<p>There are some disadvantages:</p>

<ul>
<li>There aren't many good GUIs for it yet. It's new and Subversion has been around for a lot longer, so this is natural as there are a few interfaces in development. Some good ones include <a href=""http://code.google.com/p/tortoisegit/"" rel=""nofollow noreferrer"">TortoiseGit</a> and <a href=""http://mac.github.com/"" rel=""nofollow noreferrer"">GitHub for Mac</a>.</li>
<li><del>Partial checkouts/clones of repositories are not possible at the moment (I read that it's in development). However, there is submodule support.</del> <a href=""http://www.kernel.org/pub/software/scm/git/docs/RelNotes-1.7.0.txt"" rel=""nofollow noreferrer"">Git 1.7+ supports sparse checkouts</a>.</li>
<li>It might be harder to learn, even though I did not find this to be the case (about a year ago). Git has recently improved its interface and is quite user friendly.</li>
</ul>

<p>In the most simplistic usage, Subversion and Git are pretty much the same. There isn't much difference between:</p>

<pre><code>svn checkout svn://foo.com/bar bar
cd bar
# edit
svn commit -m ""foo""
</code></pre>

<p>and</p>

<pre><code>git clone git@github.com:foo/bar.git
cd bar
# edit
git commit -a -m ""foo""
git push
</code></pre>

<p>Where Git really shines is branching and working with other people.</p>
",64423.0,1310.0,56
871,6169247,False,"<p>This is the wrong question to be asking.  It's all too easy to focus on git's warts and formulate an argument about why subversion is ostensibly better, at least for some use cases.  The fact that git was originally designed as a low-level version control construction set and has a baroque linux-developer-oriented interface makes it easier for the holy wars to gain traction and perceived legitimacy.  Git proponents bang the drum with millions of workflow advantages, which svn guys proclaim unnecessary.  Pretty soon the whole debate is framed as centralized vs distributed, which serves the interests of the enterprise svn tool community.  These companies, which typically put out the most convincing articles about subversion's superiority in the enterprise, are dependent on the perceived insecurity of git and the enterprise-readiness of svn for the long-term success of their products.</p>

<p>But here's the problem: <strong>Subversion is an architectural dead-end</strong>.  </p>

<p>Whereas you can take git and build a centralized subversion replacement quite easily, despite being around for more than twice as long svn has never been able to get even basic merge-tracking working anywhere near as well as it does in git.  One basic reason for this is the design decision to make branches the same as directories.  I don't know why they went this way originally, it certainly makes partial checkouts very simple.  Unfortunately it also makes it impossible to track history properly.  Now obviously you are supposed to use subversion repository layout conventions to separate branches from regular directories, and svn uses some heuristics to make things work for the daily use cases.  But all this is just papering over a very poor and limiting low-level design decision.  Being able to a do a repository-wise diff (rather than directory-wise diff) is basic and critical functionality for a version control system, and greatly simplifies the internals, making it possible to build smarter and useful features on top of it.  You can see in the amount of effort that has been put into extending subversion, and yet how far behind it is from the current crop of modern VCSes in terms of fundamental operations like merge resolution.</p>

<p>Now here's my heart-felt and agnostic advice for anyone who still believes Subversion is good enough for the foreseeable future:</p>

<p>Subversion will never catch up to the newer breeds of VCSes that have learned from the mistakes of RCS and CVS; it is a technical impossibility unless they retool the repository model from the ground up, but then it wouldn't really be svn would it?  Regardless of how much you think you don't the capabilities of a modern VCS, your ignorance will not protect you from the Subversion's pitfalls, many of which are situations that are impossible or easily resolved in other systems.</p>

<p>It is extremely rare that the technical inferiority of a solution is so clear-cut as it is with svn, certainly I would never state such an opinion about win-vs-linux or emacs-vs-vi, but in this case it is so clearcut, and source control is such a fundamental tool in the developer's arsenal, that I feel it must be stated unequivocally.  Regardless of the requirement to use svn for organizational reasons, I implore all svn users not to let their logical mind construct a false belief that more modern VCSes are only useful for large open-source projects.  Regardless of the nature of your development work, if you are a programmer, you will be a more effective programmer if you learn how to use better-designed VCSes, whether it be Git, Mercurial, Darcs, or many others.</p>
",8376.0,15901.0,3
871,5246905,False,"<p>For people looking for a good Git GUI, <a href=""http://www.syntevo.com/smartgit/"" rel=""nofollow"">Syntevo SmartGit</a> might be a good solution. Its proprietary, but free for non-commercial use, runs on Windows/Mac/Linux and even supports SVN using some kind of git-svn bridge, I think.</p>
",651657.0,1.0,2
871,43491,False,"<p>The main points I like about DVCS are those :</p>

<ol>
<li>You can commit broken things. It doesn't matter because other peoples won't see them until you publish. Publish time is different of commit time.</li>
<li>Because of this you can commit more often.</li>
<li>You can merge complete functionnality. This functionnality will have its own branch. All commits of this branch will be related to this functionnality. You can do it with a CVCS however with DVCS its the default.</li>
<li>You can search your history (find when a function changed )</li>
<li>You can undo a pull if someone screw up the main repository, you don't need to fix the errors. Just clear the merge.</li>
<li>When you need a source control in any directory do : git init . and you can commit, undoing changes, etc...</li>
<li>It's fast (even on Windows )</li>
</ol>

<p>The main reason for a relatively big project is the improved communication created by the point 3. Others are nice bonuses.</p>
",4508.0,2224.0,22
871,3998872,False,"<p>Why I think Subversion is better than Git (at least for the projects I work on), mainly due to its usability, and simpler workflow:</p>

<p><a href=""http://www.databasesandlife.com/why-subversion-is-better-than-git/"" rel=""nofollow"">http://www.databasesandlife.com/why-subversion-is-better-than-git/</a></p>
",220627.0,15846.0,1
871,3737909,False,"<p><a href=""http://blogs.wandisco.com/2010/09/08/why-we-got-so-heavily-involved-in-the-subversion-project/"" rel=""nofollow noreferrer"">David Richards WANdisco Blog on Subversion / GIT</a></p>

<blockquote>
  <p>The emergence of GIT  has brought with it a breed of DVCS fundamentalists – the ‘Gitterons’ – that think anything other than GIT is crap. The Gitterons seem to think software engineering happens on their own island and often forget that most organizations don’t employ senior software engineers exclusively. That’s ok but it’s not how the rest of the market thinks, and I am happy to prove it: GIT, at the last look had less than three per cent of the market while Subversion has in the region of five million users and about half of the overall market.</p>
  
  <p>The problem we saw was that the Gitterons were firing (cheap) shots at Subversion. Tweets like “Subversion is so [slow/crappy/restrictive/doesn't smell good/looks at me in a funny way] and now I have GIT and [everything works in my life/my wife got pregnant/I got a girlfriend after 30 years of trying/I won six times running on the blackjack table]. You get the picture.</p>
</blockquote>
",450904.0,1.0,8
871,1560307,False,"<p><a href=""http://www.ericsink.com/"" rel=""nofollow noreferrer"">Eric Sink</a> from SourceGear wrote series of articles on differences between distributed and nondistributed version controls systems. He compares pros and cons of most popular version control systems. Very interesting reading. <br>
Articles can be found on his blog, <a href=""http://www.ericsink.com"" rel=""nofollow noreferrer"">www.ericsink.com</a>:</p>

<ul>
<li><p><a href=""http://www.ericsink.com/entries/Read_the_Diffs.html"" rel=""nofollow noreferrer"">Read the Diffs</a></p></li>
<li><p><a href=""http://www.ericsink.com/entries/git_index.html"" rel=""nofollow noreferrer"">Git is the C of Version Control Tools</a></p></li>
<li><p><a href=""http://www.ericsink.com/entries/git_immutability.html"" rel=""nofollow noreferrer"">On Git's lack of respect for immutability and the Best Practices for a DVCS</a></p></li>
<li><p><a href=""http://www.ericsink.com/entries/dvcs_dag_1.html"" rel=""nofollow noreferrer"">DVCS and DAGs, Part 1</a></p></li>
<li><p><a href=""http://www.ericsink.com/entries/dvcs_dag_2.html"" rel=""nofollow noreferrer"">DVCS and DAGs, Part 2</a></p></li>
<li><p><a href=""http://www.ericsink.com/entries/dbts_fossil.html"" rel=""nofollow noreferrer"">DVCS and Bug Tracking</a></p></li>
<li><p><a href=""http://www.ericsink.com/entries/merge_history.html"" rel=""nofollow noreferrer"">Merge History, DAGs and Darcs</a></p></li>
<li><p><a href=""http://www.ericsink.com/entries/why_is_git_fast.html"" rel=""nofollow noreferrer"">Why is Git so Fast?</a></p></li>
<li><p><a href=""http://www.ericsink.com/entries/hg_denzel.html"" rel=""nofollow noreferrer"">Mercurial, Subversion, and Wesley Snipes</a></p></li>
</ul>
",25732.0,12716.0,2
871,6582,False,"<p>Git also makes branching and merging really easy. Subversion 1.5 just added merge tracking, but Git is still better. With Git branching is very fast and cheap. It makes creating a branch for each new feature more feasible. Oh and Git repositories are very efficient with storage space as compared to Subversion.</p>
",796.0,10376.0,7
871,3345344,False,"<p>I think Subversion is fine.. until you start merging.. or doing anything complicated.. or doing anything Subversion thinks is complicated (like doing queries to find out which branches messed with a particular file, where a change <em>actually</em> comes from, detecting copy&amp;pastes, etc)...</p>

<p>I disagree with the winning answer, saying the <em>main benefit</em> of GIT is offline work - it's certainly useful, but it's more like an extra for my use case. SVK can work offline too, still there is no question for me which one to invest my learning time in).</p>

<p>It's just that it's incredibly powerful and fast and, well -after getting used to the concepts - very useful (yes, in that sense: user friendly).</p>

<p>For more details on a merging story, see this :
<a href=""https://stackoverflow.com/questions/2945842/using-git-svn-or-similar-just-to-help-out-with-svn-merge/2981745#2981745"">Using git-svn (or similar) *just* to help out with an svn merge?</a></p>
",174284.0,17294.0,4
871,910,False,"<p>With Git, you can do practically anything offline, because everybody has their own repository.</p>

<p>Making branches and merging between branches is really easy.</p>

<p>Even if you don't have commit rights for a project, you can still have your own repository online, and publish ""push requests"" for your patches. Everybody who likes your patches can pull them into their project, including the official maintainers.</p>

<p>It's trivial to fork a project, modify it, and still keep merging in the bugfixes from the HEAD branch. </p>

<p>Git works for the Linux kernel developers. That means it is really fast (it has to be), and scales to thousands of contributors. Git also uses less space (up to 30 times less space for the Mozilla repository).</p>

<p>Git is very flexible, very TIMTOWTDI (There is more than one way to do it). You can use whatever workflow you want, and Git will support it.</p>

<p>Finally, there's <a href=""http://en.wikipedia.org/wiki/GitHub"" rel=""nofollow noreferrer"">GitHub</a>, a great site for hosting your Git repositories.</p>

<p>Drawbacks of Git: </p>

<ul>
<li>it's much harder to learn, because Git has more concepts and more commands.</li>
<li>revisions don't have version numbers like in subversion</li>
<li>many Git commands are cryptic, and error messages are very user-unfriendly</li>
<li>it lacks a good GUI (such as the great <a href=""http://en.wikipedia.org/wiki/TortoiseSVN"" rel=""nofollow noreferrer"">TortoiseSVN</a>)</li>
</ul>
",136.0,40451.0,145
871,172269,False,"<p>I like Git because it actually helps communication developer to developer on a medium to large team. As a distributed version control system, through its push/pull system, it helps developers to create a source code eco-system which helps to manage a large pool of developers working on a single project.</p>

<p>For example say you trust 5 developers and only pull codes from their repository. Each of those developers has their own trust network from where they pull codes. Thus the development is based on that trust fabric of developers where code responsibility is shared among the development community.</p>

<p>Of course there are other benefits which are mentioned in other answers here.</p>
",20165.0,951.0,5
871,1245254,False,"<p>A few answers have alluded to these, but I want to make 2 points explicit:</p>

<p>1) The ability to do selective commits (for example, <code>git add --patch</code>).  If your working directory contains multiple changes that are not part of the same logical change, Git makes it very easy to make a commit that includes only a portion of the changes.  With Subversion, it is difficult.</p>

<p>2) The ability to commit without making the change public.  In Subversion, any commit is immediately public, and thus irrevocable.  This greatly limits the ability of the developer to ""commit early, commit often"".</p>

<p>Git is more than just a VCS; it's also a tool for developing patches. Subversion is merely a VCS.</p>
",140750.0,172509.0,4
871,2240942,False,"<p>I absolutely love being able to manage local branches of my source code in Git without muddying up the water of the central repository.  In many cases I'll checkout code from the Subversion server and run a local Git repository just to be able to do this.  It's also great that initializing a Git repository doesn't pollute the filesystem with a bunch of annoying .svn folders everywhere.</p>

<p>And as far as Windows tool support, TortoiseGit handles the basics very well, but I still prefer the command line unless I want to view the log.  I really like the way Tortoise{Git|SVN} helps when reading commit logs.</p>
",149212.0,4560.0,3
871,1994861,False,"<p>First, concurrent version control seems like an easy problem to solve. It's not at all. Anyway...</p>

<p>SVN is quite non-intuitive. Git is even worse. [sarcastic-speculation] This might be because developers, that like hard problems like concurrent version control, don't have much interest in making a good UI. [/sarcastic-speculation]</p>

<p>SVN supporters think they don't need a distributed version-control system. <strong>I thought that too.</strong> But now that we use Git exclusively, I'm a believer. Now version control works for me AND the team/project instead of just working for the project. When I need a branch, I branch. Sometimes it's a branch that has a corresponding branch on the server, and sometimes it does not. Not to mention all the other advantages that I'll have to go study up on (thanks in part to the arcane and absurd lack of UI that is a modern version control system).</p>
",8047.0,64326.0,1
871,2710068,False,"<p>I have been dwelling in Git land lately, and I like it for personal projects, but I wouldn't be able to switch work projects to it yet from Subversion given the change in thinking of required from staff, without no pressing benefits. Moreover the biggest project we run in-house is extremely dependent on <a href=""http://svnbook.red-bean.com/en/1.0/ch07s03.html"" rel=""nofollow noreferrer"">svn:externals</a> which, from what I've seen so far, does not work so nicely and seamlessly in Git.</p>
",325458.0,1862.0,1
871,1558578,False,"<p>All the answers here are as expected, programmer centric, however what happens if your company uses revision control outside of source code? There are plenty of documents which aren't source code which benefit from version control, and should live close to code and not in another CMS. Most programmers don't work in isolation - we work for companies as part of a team.</p>

<p>With that in mind, compare ease of use, in both client tooling and training, between Subversion and git. I can't see a scenario where <em>any</em> distributed revision control system is going to be easier to use or explain to a non-programmer. I'd love to be proven wrong, because then I'd be able to evaluate git and actually have a hope of it being accepted by people who need version control who aren't programmers.</p>

<p>Even then, if asked by management why we should move from a centralised to distributed  revision control system, I'd be hard pressed to give an honest answer, because we don't need it.</p>

<p>Disclaimer: I became interested in Subversion early on (around v0.29) so obviously I'm biased, but the companies I've worked for since that time are benefiting from my enthusiasm because I've encouraged and supported its use. I suspect this is how it happens with most software companies.  With so many programmers jumping on the git bandwagon, I wonder how many companies are going to miss out on the benefits of using version control outside of source code? Even if you have separate systems for different teams, you're missing out on some of the benefits, such as (unified) issue tracking integration, whilst increasing maintenance, hardware and training requirements.</p>
",44540.0,15940.0,11
871,2238465,False,"<p>Git in Windows is quite well supported now.</p>

<p>Check out GitExtensions = <a href=""http://code.google.com/p/gitextensions/"" rel=""nofollow noreferrer"">http://code.google.com/p/gitextensions/</a></p>

<p>and the manual for a better Windows Git experience.</p>
",,,1
871,2239475,False,"<p><a href=""http://subversion.wandisco.com/component/content/article/1/40.html"" rel=""nofollow noreferrer"">http://subversion.wandisco.com/component/content/article/1/40.html</a></p>

<p>I think it's fairly safe to say that amongst developers, the SVN Vs. Git argument has been raging for some time now, with everyone having their own view on which is better.  This was even brought up in the of the questions during our Webinar on Subversion in 2010 and Beyond.</p>

<p>Hyrum Wright, our Director of Open Source and the President for the  Subversion Corporation talks about the differences between Subversion and Git, along with other Distributed Version Control Systems (DVCS).</p>

<p>He also talks about the upcoming changes in Subversion, such as Working Copy Next Generation (WC-NG), which he believes will cause a number of Git users to convert back to Subversion.</p>

<p>Have a watch of his video and let us know what you think by either commenting on this blog, or by posting in our forums.  Registration is simple and will only take a moment!</p>
",,,1
871,875,True,"<p>Git is not better than Subversion. But is also not worse. It's different.</p>

<p>The key difference is that it is decentralized. Imagine you are a developer on the road, you develop on your laptop and you want to have source control so that you can go back 3 hours.</p>

<p>With Subversion, you have a Problem: The SVN Repository may be in a location you can't reach (in your company, and you don't have internet at the moment), you cannot commit. If you want to make a copy of your code, you have to literally copy/paste it.</p>

<p>With Git, you do not have this problem. Your local copy is a repository, and you can commit to it and get all benefits of source control. When you regain connectivity to the main repository, you can commit against it.</p>

<p>This looks good at first, but just keep in mind the added complexity to this approach.</p>

<p>Git seems to be the ""new, shiny, cool"" thing. It's by no means bad (there is a reason Linus wrote it for the Linux Kernel development after all), but I feel that many people jump on the ""Distributed Source Control"" train just because it's new and is written by Linus Torvalds, without actually knowing why/if it's better.</p>

<p>Subversion has Problems, but so does Git, Mercurial, CVS, TFS or whatever.</p>

<p><strong>Edit:</strong> So this answer is now a year old and still generates many upvotes, so I thought I'll add some more explanations. In the last year since writing this, Git has gained a lot of momentum and support, particularly since sites like GitHub really took off. I'm using both Git and Subversion nowadays and I'd like to share some personal insight.</p>

<p>First of all, Git can be really confusing at first when working decentralized. What is a remote? and How to properly set up the initial repository? are two questions that come up at the beginning, especially compared to SVN's simple ""svnadmin create"", Git's ""git init"" can take the parameters --bare and --shared which seems to be the ""proper"" way to set up a centralized repository. There are reasons for this, but it adds complexity. The documentation of the ""checkout"" command is very confusing to people changing over - the ""proper"" way seems to be ""git clone"", while ""git checkout"" seems to switch branches.</p>

<p>Git REALLY shines when you are decentralized. I have a server at home and a Laptop on the road, and SVN simply doesn't work well here. With SVN, I can't have local source control if I'm not connected to the repository (Yes, I know about SVK or about ways to copy the repo). With Git, that's the default mode anyway. It's an extra command though (git commit commits locally, whereas git push origin master pushes the master branch to the remote named ""origin"").</p>

<p>As said above: Git adds complexity. Two modes of creating repositories, checkout vs. clone, commit vs. push... You have to know which commands work locally and which work with ""the server"" (I'm assuming most people still like a central ""master-repository"").</p>

<p>Also, the tooling is still insufficient, at least on Windows. Yes, there is a Visual Studio AddIn, but I still use git bash with msysgit.</p>

<p>SVN has the advantage that it's MUCH simpler to learn: There is your repository, all changes to towards it, if you know how to create, commit and checkout and you're ready to go and can pickup stuff like branching, update etc. later on.</p>

<p>Git has the advantage that it's MUCH better suited if some developers are not always connected to the master repository. Also, it's much faster than SVN. And from what I hear, branching and merging support is a lot better (which is to be expected, as these are the core reasons it was written).</p>

<p>This also explains why it gains so much buzz on the Internet, as Git is perfectly suited for Open Source projects: Just Fork it, commit your changes to your own Fork, and then ask the original project maintainer to pull your changes. With Git, this just works. Really, try it on Github, it's magic.</p>

<p>What I also see are Git-SVN Bridges: The central repository is a Subversion repo, but developers locally work with Git and the bridge then pushes their changes to SVN.</p>

<p>But even with this lengthy addition, I still stand by my core message: Git is not better or worse, it's just different. If you have the need for ""Offline Source Control"" and the willingness to spend some extra time learning it, it's fantastic. But if you have a strictly centralized Source Control and/or are struggling to introduce Source Control in the first place because your co-workers are not interested, then the simplicity and excellent tooling (at least on Windows) of SVN shine.</p>
",91.0,166977.0,548
871,1560184,False,"<p>Subversion is very easy to use. I have never found in the last years a problem or that something doesn't work as expected. Also there are many excellent GUI tools and the support for SVN integration is big.</p>

<p>With Git you get a more flexible VCS. You can use it the same way like SVN with a remote repository where you commit all changes. But you can also use it mostly offline and only push the changes from time to time to the remote repository.
But Git is more complex and has a steeper learning curve. I found myself in the first time committing to wrong branches, creating branches indirectly or get error messages with not much informations about the mistake and where I must search with Google to get better informations.
Some easy things like substitution of markers ($Id$) doesn't work but GIT has a very flexible filtering and hook mechanism to merge own scripts and so you get all things you need and more but it needs more time and reading of the documentation ;)</p>

<p>If you work mostly offline with your local repository you have no backup if something is lost on your local machine. With SVN you are mostly working with a remote repository which is also the same time your backup on another server... 
Git can work in the same way but this was not the main goal of Linus to have something like SVN2. It was designed for the Linux kernel developers and the needs of a distributed version control system.</p>

<p>Is Git better then SVN? Developers which needs only some version history and a backup mechanism have a good and easy life with SVN. Developers working often with branches, testing more versions at the same time or working mostly offline can benefit from the features of Git. There are some very useful features like stashing not found with SVN which can make the life easier. But on the other side not all people will need all features. So I cannot see the dead of SVN.</p>

<p>Git needs some better documentation and the error reporting must be more helpful. Also the existing useful GUIs are only rarely. This time I have only found 1 GUI for Linux with support of most Git features (git-cola). Eclipse integration is working but its not official released and there is no official update site (only some external update site with periodical builds from the trunk <a href=""http://www.jgit.org/updates"" rel=""nofollow noreferrer"">http://www.jgit.org/updates</a>)
So the most preferred way to use Git this days is the command line.</p>
",68906.0,1802.0,2
871,137069,False,"<p>Other answers have done a good job of explaining the core features of Git (which are great). But there's also so many <em>little</em> ways that Git behaves better and helps keep my life more sane. Here are some of the little things:</p>

<ol>
<li>Git has a 'clean' command. SVN desperately needs this command, considering how frequently it will dump extra files on your disk.</li>
<li>Git has the 'bisect' command. It's nice.</li>
<li>SVN creates .svn directories in every single folder (Git only creates <em>one</em> .git directory). Every script you write, and every grep you do, will need to be written to ignore these .svn directories. You also need an entire command (""svn export"") just to get a sane copy of your files.</li>
<li>In SVN, each file &amp; folder can come from a different revision or branch. At first, it sounds nice to have this freedom. But what this actually means is that there is a million different ways for your local checkout to be completely screwed up. (for example, if ""svn switch"" fails halfway through, or if you enter a command wrong). And the worst part is: if you ever get into a situation where some of your files are coming from one place, and some of them from another, the ""svn status"" will tell you that everything is normal. You'll need to do ""svn info"" on each file/directory to discover how weird things are. If ""git status"" tells you that things are normal, then you can trust that things really are normal.</li>
<li>You have to tell SVN whenever you move or delete something. Git will just figure it out.</li>
<li>Ignore semantics are easier in Git. If you ignore a pattern (such as *.pyc), it will be ignored for <em>all</em> subdirectories. (But if you really want to ignore something for just one directory, you can). With SVN, it seems that there is no easy way to ignore a pattern across all subdirectories.</li>
<li>Another item involving ignore files. Git makes it possible to have ""private"" ignore settings (using the file .git/info/exclude), which won't affect anyone else.</li>
</ol>
",21482.0,16084.0,110
871,876,False,"<p>Well, it's distributed. Benchmarks indicate that it's considerably faster (given its distributed nature, operations like diffs and logs are all local so of course it's blazingly faster in this case), and working folders are smaller (which still blows my mind).</p>

<p>When you're working on subversion, or any other client/server revision control system, you essentially create working copies on your machine by <em>checking-out</em> revisions. This represents a snapshot in time of what the repository looks like. You update your working copy via updates, and you update the repository via commits.</p>

<p>With a distributed version control, you don't have a snapshot, but rather the entire codebase. Wanna do a diff with a 3 month old version? No problem, the 3 month old version is still on your computer. This doesn't only mean things are way faster, but if you're disconnected from your central server, you can still do many of the operations you're used to. In other words, you don't just have a snapshot of a given revision, but the entire codebase.</p>

<p>You'd think that Git would take up a bunch of space on your harddrive, but from a couple benchmarks I've seen, it actually takes less. Don't ask me how. I mean, it was built by Linus, he knows a thing or two about filesystems I guess.</p>
",34.0,20440.0,26
871,162148,False,"<p>The funny thing is:
I host projects in Subversion Repos, but access them via the Git Clone command.</p>

<p>Please read <a href=""http://google-opensource.blogspot.com/2008/05/develop-with-git-on-google-code-project.html"" rel=""nofollow noreferrer"">Develop with Git on a Google Code Project</a></p>

<blockquote>
  <p>Although Google Code natively speaks
  Subversion, you can easily use Git
  during development. Searching for ""git
  svn"" suggests this practice is
  widespread, and we too encourage you
  to experiment with it.</p>
</blockquote>

<p>Using Git on a Svn Repository gives me benefits:</p>

<ol>
<li>I can work <em>distributed</em> on several
machines, commiting and pulling from
and to them</li>
<li>I have a <em>central</em> <code>backup/public</code> svn repository for others to check out</li>
<li>And they are free to use Git for their own</li>
</ol>
",21027.0,6042.0,15
871,95553,False,"<p>Subversion is still a much more used version control system, which means that it has better tool support.  You'll find mature SVN plugins for almost any <a href=""http://en.wikipedia.org/wiki/Integrated_development_environment"" rel=""nofollow noreferrer"">IDE</a>, and there are good explorer extensions available (like TurtoiseSVN).  Other than that, I'll have to agree with <a href=""https://stackoverflow.com/questions/871?sort=votes#875"">Michael</a>:  Git isn't better or worse than Subversion, it's different.</p>
",13365.0,14731.0,9
871,35911,False,"<p>Thanks to the fact it doesn't need to communicate with a central server constantly, pretty much every command runs in less than a second (obviously git push/pull/fetch are slower simply because they have to initalise SSH connections). Branching is far far easier (one simple command to branch, one simple command to merge)</p>
",745.0,152698.0,3
871,22658,False,"<p>One of the things about SubVersion that irks me is that it puts its own folder in each directory of a project, whereas git only puts one in the root directory. It's not <em>that</em> big of a deal, but little things like that add up.</p>

<p>Of course, SubVersion has Tortoise, which is [usually] very nice.</p>
",736.0,44788.0,8
871,22652,False,"<p><a href=""http://www.gnome.org/~newren/eg/"" rel=""nofollow noreferrer"">Easy Git</a> has a nice page comparing actual usage of <a href=""http://www.gnome.org/~newren/eg/git-for-svn-users.html"" rel=""nofollow noreferrer"">Git and SVN</a> which will give you an idea of what things Git can do (or do more easily) compared to SVN.  (Technically, this is based on Easy Git, which is a lightweight wrapper on top of Git.)</p>
",825.0,184868.0,6
871,893,False,"<p>It's all about the ease of use/steps required to do something.</p>

<p>If I'm developing a single project on my PC/laptop, git is better, because it is far easier to set up and use. 
You don't need a server, and you don't need to keep typing repository URL's in when you do merges.</p>

<p>If it were just 2 people, I'd say git is also easier, because you can just push and pull from eachother.</p>

<p>Once you get beyond that though, I'd go for subversion, because at that point you need to set up a 'dedicated' server or location. </p>

<p>You can do this just as well with git as with SVN, but the benefits of git get outweighed by the need to do additional steps to synch with a central server. In SVN you just commit. In git you have to git commit, then git push. The additional step gets annoying simply because you end up doing it so much.</p>

<p>SVN also has the benefit of better GUI tools, however the git ecosystem seems to be catching up quickly, so I wouldn't worry about this in the long term.</p>
",234.0,113281.0,6
871,886,False,"<p>Git and DVCS in general is great for developers doing a lot of coding independently of each other because everyone has their own branch.  If you need a change from someone else, though, she has to commit to her local repo and then she must push that changeset to you or you must pull it from her.</p>

<p>My own reasoning also makes me think DVCS makes things harder for QA and release management if you do things like centralized releases.  Someone has to be responsible for doing that push/pull from everyone else's repository, resolving any conflicts that would have been resolved at initial commit time before, then doing the build, and then having all the other developers re-sync their repos.</p>

<p>All of this can be addressed with human processes, of course; DVCS just broke something that was fixed by centralized version control in order to provide some new conveniences.</p>
",153.0,1703.0,5
871,873,False,"<p>Google Tech Talk: Linus Torvalds on git</p>

<p><a href=""http://www.youtube.com/watch?v=4XpnKHJAok8"" rel=""nofollow noreferrer"">http://www.youtube.com/watch?v=4XpnKHJAok8</a></p>

<p>The Git Wiki's comparison page</p>

<p><a href=""http://git.or.cz/gitwiki/GitSvnComparsion"" rel=""nofollow noreferrer"">http://git.or.cz/gitwiki/GitSvnComparsion</a></p>
",150.0,7240.0,54
879,67052160,False,"<p>Regarding how objects are passed to functions you still need to understand that without &quot;&amp;&quot;, you pass to the function an object handle , object handle that is still passed by value , and it contains the value of a pointer. But you can not change this pointer until you pass it by reference using the &quot;&amp;&quot;</p>
<pre><code>&lt;?php
        class Example 
        {
            public $value;
         
        }
        
        function test1($x) 
        {
             //let's say $x is 0x34313131
             $x-&gt;value = 1;  //will reflect outsite of this function
                             //php use pointer 0x34313131 and search for the 
                             //address of 'value' and change it to 1

        }
        
        function test2($x) 
        {
             //$x is 0x34313131
             $x = new Example;
             //now $x is 0x88888888
             //this will NOT reflect outside of this function 
             //you need to rewrite it as &quot;test2(&amp;$x)&quot;
             $x-&gt;value = 1000; //this is 1000 JUST inside this function
                 
        
        }
         
     $example = new Example;
    
     $example-&gt;value = 0;
    
     test1($example); // $example-&gt;value changed to  1
    
     test2($example); // $example did NOT changed to a new object 
                      // $example-&gt;value is still 1
     
 ?&gt;
</code></pre>
",4195727.0,128.0,1
879,66762810,False,"<p>See this example:</p>
<pre><code>&lt;?php

$string = 'First String. ';
$string .= 'Second String. ';
$string .= 'Third String. ';

echo $string;

// output: First String. Second String. Third String. 

?&gt;
</code></pre>
",9176196.0,11.0,0
879,60082753,False,"<p><strong>TL;DR</strong>: PHP supports both pass by value and pass by reference. References are declared using an ampersand (<code>&amp;</code>); this is very similar to how C++ does it. When the formal parameter of a function is not declared with an ampersand (i.e., it's not a reference), <strong>everything</strong> is passed by value, including objects. There is no distinction between how objects and primitives are passed around. The key is to understand <em>what</em> gets passed along when you pass in objects to a function. This is where understanding pointers is invaluable.</p>
<p>For anyone who comes across this in the future, I want to share this gem from the <a href=""https://www.php.net/manual/en/language.oop5.references.php"" rel=""nofollow noreferrer"">PHP docs, posted by an anonymous user</a>:</p>
<blockquote>
<p>There seems to be some confusion here. The distinction between pointers and references is not particularly helpful.
The behavior in some of the &quot;comprehensive&quot; examples already posted can be explained in simpler unifying terms. Hayley's code, for example, is doing EXACTLY what you should expect it should. (Using &gt;= 5.3)</p>
</blockquote>
<blockquote>
<p>First principle:
A pointer stores a memory address to access an object. Any time an object is assigned, a pointer is generated. (I haven't delved TOO deeply into the Zend engine yet, but as far as I can see, this applies)</p>
</blockquote>
<blockquote>
<p>2nd principle, and source of the most confusion:
Passing a variable to a function is done by default as a value pass, ie, you are working with a copy. &quot;But objects are passed by reference!&quot; A common misconception both here and in the Java world. I never said a copy OF WHAT. The default passing is done by value. Always. WHAT is being copied and passed, however, is the pointer. When using the &quot;-&gt;&quot;, you will of course be accessing the same internals as the original variable in the caller function. Just using &quot;=&quot; will only play with copies.</p>
</blockquote>
<blockquote>
<p>3rd principle:
&quot;&amp;&quot; automatically and permanently sets another variable name/pointer to the same memory address as something else until you decouple them. It is correct to use the term &quot;alias&quot; here. Think of it as joining two pointers at the hip until forcibly separated with &quot;unset()&quot;. This functionality exists both in the same scope and when an argument is passed to a function. Often the passed argument is called a &quot;reference,&quot; due to certain distinctions between &quot;passing by value&quot; and &quot;passing by reference&quot; that were clearer in C and C++.</p>
</blockquote>
<blockquote>
<p>Just remember: pointers to objects, not objects themselves, are passed to functions. These pointers are COPIES of the original unless you use &quot;&amp;&quot; in your parameter list to actually pass the originals. Only when you dig into the internals of an object will the originals change.</p>
</blockquote>
<p>And here's the example they provide:</p>
<pre class=""lang-php prettyprint-override""><code>&lt;?php

//The two are meant to be the same
$a = &quot;Clark Kent&quot;; //a==Clark Kent
$b = &amp;$a; //The two will now share the same fate.

$b=&quot;Superman&quot;; // $a==&quot;Superman&quot; too.
echo $a;
echo $a=&quot;Clark Kent&quot;; // $b==&quot;Clark Kent&quot; too.
unset($b); // $b divorced from $a
$b=&quot;Bizarro&quot;;
echo $a; // $a==&quot;Clark Kent&quot; still, since $b is a free agent pointer now.

//The two are NOT meant to be the same.
$c=&quot;King&quot;;
$d=&quot;Pretender to the Throne&quot;;
echo $c.&quot;\n&quot;; // $c==&quot;King&quot;
echo $d.&quot;\n&quot;; // $d==&quot;Pretender to the Throne&quot;
swapByValue($c, $d);
echo $c.&quot;\n&quot;; // $c==&quot;King&quot;
echo $d.&quot;\n&quot;; // $d==&quot;Pretender to the Throne&quot;
swapByRef($c, $d);
echo $c.&quot;\n&quot;; // $c==&quot;Pretender to the Throne&quot;
echo $d.&quot;\n&quot;; // $d==&quot;King&quot;

function swapByValue($x, $y){
$temp=$x;
$x=$y;
$y=$temp;
//All this beautiful work will disappear
//because it was done on COPIES of pointers.
//The originals pointers still point as they did.
}

function swapByRef(&amp;$x, &amp;$y){
$temp=$x;
$x=$y;
$y=$temp;
//Note the parameter list: now we switched 'em REAL good.
}

?&gt;
</code></pre>
<p><a href=""https://www.aleksandrhovhannisyan.com/blog/javascript-pass-by-reference/"" rel=""nofollow noreferrer"">I wrote an extensive, detailed blog post on this subject for JavaScript</a>, but I believe it applies equally well to PHP, C++, and any other language where people seem to be confused about pass by value vs. pass by reference.</p>
<p>Clearly, PHP, like C++, is a language that does support pass by reference. By default, objects are passed by value. When working with variables that store objects, it helps to see those variables as pointers (because that is fundamentally what they are, at the assembly level). If you pass a pointer by value, you can still &quot;trace&quot; the pointer and modify the properties of the object being pointed to. What you cannot do is have it point to a different object. Only if you explicitly declare a parameter as being passed by reference will you be able to do that.</p>
",5323344.0,745.0,2
879,574631,False,"<p>You can do it either way.</p>
<p>Put an '&amp;' symbol in front and the variable you are passing becomes one and the same as its origin i.e. you can pass by reference, rather than make a copy of it.</p>
<p>so</p>
<pre><code>    $fred = 5;
    $larry = &amp; $fred;
    $larry = 8;
    echo $fred;//this will output 8, as larry and fred are now the same reference.
</code></pre>
",69518.0,633.0,6
879,881,False,"<p>PHP variables are assigned by value, passed to functions by value and when containing/representing objects are passed by reference. You can force variables to pass by reference using an '&amp;'.</p>
<p>Assigned by value/reference example:</p>
<pre><code>$var1 = &quot;test&quot;;
$var2 = $var1;
$var2 = &quot;new test&quot;;
$var3 = &amp;$var2;
$var3 = &quot;final test&quot;;

print (&quot;var1: $var1, var2: $var2, var3: $var3);
</code></pre>
<p>output:</p>
<blockquote>
<p>var1: test, var2: final test, var3: final test</p>
</blockquote>
<p>Passed by value/reference example:</p>
<pre><code>$var1 = &quot;foo&quot;;
$var2 = &quot;bar&quot;;

changeThem($var1, $var2);

print &quot;var1: $var1, var2: $var2&quot;;

function changeThem($var1, &amp;$var2){
    $var1 = &quot;FOO&quot;;
    $var2 = &quot;BAR&quot;;
}
</code></pre>
<p>output:</p>
<blockquote>
<p>var1: foo, var2 BAR</p>
</blockquote>
<p>Object variables passed by reference example:</p>
<pre><code>class Foo{
    public $var1;

    function __construct(){
        $this-&gt;var1 = &quot;foo&quot;;
    }

    public function printFoo(){
        print $this-&gt;var1;
    }
}


$foo = new Foo();

changeFoo($foo);

$foo-&gt;printFoo();

function changeFoo($foo){
    $foo-&gt;var1 = &quot;FOO&quot;;
}
</code></pre>
<p>output:</p>
<blockquote>
<p>FOO</p>
</blockquote>
<p>(The last example could be better probably.)</p>
",58.0,43521.0,29
879,9696799,False,"<p>In PHP, by default, objects are passed as reference to a new object.</p>
<p>See this example:</p>
<pre><code>class X {
  var $abc = 10; 
}

class Y {

  var $abc = 20; 
  function changeValue($obj)
  {
   $obj-&gt;abc = 30;
  }
}

$x = new X();
$y = new Y();

echo $x-&gt;abc; //outputs 10
$y-&gt;changeValue($x);
echo $x-&gt;abc; //outputs 30
</code></pre>
<p>Now see this:</p>
<pre><code>class X {
  var $abc = 10; 
}

class Y {

  var $abc = 20; 
  function changeValue($obj)
  {
    $obj = new Y();
  }
}

$x = new X();
$y = new Y();

echo $x-&gt;abc; //outputs 10
$y-&gt;changeValue($x);
echo $x-&gt;abc; //outputs 10 not 20 same as java does.
</code></pre>
<p>Now see this:</p>
<pre><code>class X {
  var $abc = 10; 
}

class Y {

  var $abc = 20; 
  function changeValue(&amp;$obj)
  {
    $obj = new Y();
  }
}

$x = new X();
$y = new Y();

echo $x-&gt;abc; //outputs 10
$y-&gt;changeValue($x);
echo $x-&gt;abc; //outputs 20 not possible in java.
</code></pre>
<p>I hope you can understand this.</p>
",805437.0,7907.0,82
879,7483,False,"<p>It seems a lot of people get confused by the way objects are passed to functions and what passing by reference means. Object are still passed by value, it's just the value that is passed in PHP5 is a reference handle. As proof:</p>
<pre><code>&lt;?php
class Holder {
    private $value;

    public function __construct($value) {
        $this-&gt;value = $value;
    }

    public function getValue() {
        return $this-&gt;value;
    }
}

function swap($x, $y) {
    $tmp = $x;
    $x = $y;
    $y = $tmp;
}

$a = new Holder('a');
$b = new Holder('b');
swap($a, $b);

echo $a-&gt;getValue() . &quot;, &quot; . $b-&gt;getValue() . &quot;\n&quot;;
</code></pre>
<p>Outputs:</p>
<pre><code>a, b
</code></pre>
<p>To <a href=""http://en.wikipedia.org/wiki/Pass_by_reference#Call_by_reference"" rel=""nofollow noreferrer"">pass by reference</a> means we can modify the variables that are seen by the caller, which clearly the code above does not do. We need to change the swap function to:</p>
<pre><code>&lt;?php
function swap(&amp;$x, &amp;$y) {
    $tmp = $x;
    $x = $y;
    $y = $tmp;
}

$a = new Holder('a');
$b = new Holder('b');
swap($a, $b);

echo $a-&gt;getValue() . &quot;, &quot; . $b-&gt;getValue() . &quot;\n&quot;;
</code></pre>
<p>Outputs:</p>
<pre><code>b, a
</code></pre>
<p>in order to pass by reference.</p>
",486.0,14772.0,61
879,31429088,False,"<p>Actually both methods are valid but it depends upon your requirement. Passing values by reference often makes your script slow. So it's better to pass variables by value considering time of execution. Also the code flow is more consistent when you pass variables by value.</p>
",5027344.0,89.0,0
879,49587783,False,"<p>Use this for functions when you wish to simply alter the original variable and return it again to the same variable name with its new value assigned.</p>

<pre><code>function add(&amp;$var){ // The &amp;amp; is before the argument $var
   $var++;
}
$a = 1;
$b = 10;
add($a);
echo ""a is $a,"";
add($b);
echo "" a is $a, and b is $b""; // Note: $a and $b are NOT referenced
</code></pre>
",9411789.0,5742.0,0
879,885,True,"<p>It's by value according to the <a href=""http://php.net/manual/en/functions.arguments.php"" rel=""noreferrer"">PHP Documentation</a>.</p>

<blockquote>
  <p>By default, function arguments are passed by value (so that if the value of the argument within the function is changed, it does not get changed outside of the function). To allow a function to modify its arguments, they must be passed by reference.</p>
  
  <p>To have an argument to a function always passed by reference, prepend an ampersand (<strong>&amp;</strong>) to the argument name in the function definition.</p>
</blockquote>

<pre><code>&lt;?php
function add_some_extra(&amp;$string)
{
    $string .= 'and something extra.';
}

$str = 'This is a string, ';
add_some_extra($str);
echo $str;    // outputs 'This is a string, and something extra.'
?&gt;
</code></pre>
",91.0,166977.0,336
879,27588152,False,"<p>You can pass a variable to a function by reference. This function will be able to modify the original variable.</p>

<p>You can define the passage by reference in the function definition:</p>

<pre><code>&lt;?php
function changeValue(&amp;$var)
{
    $var++;
}

$result=5;
changeValue($result);

echo $result; // $result is 6 here
?&gt;
</code></pre>
",3699965.0,618.0,9
879,2812176,False,"<pre><code>class Holder
{
    private $value;

    public function __construct( $value )
    {
        $this-&gt;value = $value;
    }

    public function getValue()
    {
        return $this-&gt;value;
    }

    public function setValue( $value )
    {
        return $this-&gt;value = $value;
    }
}

class Swap
{       
    public function SwapObjects( Holder $x, Holder $y )
    {
        $tmp = $x;

        $x = $y;

        $y = $tmp;
    }

    public function SwapValues( Holder $x, Holder $y )
    {
        $tmp = $x-&gt;getValue();

        $x-&gt;setValue($y-&gt;getValue());

        $y-&gt;setValue($tmp);
    }
}


$a1 = new Holder('a');

$b1 = new Holder('b');



$a2 = new Holder('a');

$b2 = new Holder('b');


Swap::SwapValues($a1, $b1);

Swap::SwapObjects($a2, $b2);



echo 'SwapValues: ' . $a2-&gt;getValue() . "", "" . $b2-&gt;getValue() . ""&lt;br&gt;"";

echo 'SwapObjects: ' . $a1-&gt;getValue() . "", "" . $b1-&gt;getValue() . ""&lt;br&gt;"";
</code></pre>

<p>Attributes are still modifiable when not passed by reference so beware.</p>

<p>Output:</p>

<p>SwapObjects: b, a
SwapValues: a, b</p>
",338456.0,972.0,1
879,2034022,False,"<p>Objects are passed by reference in PHP 5 and by value in PHP 4.
Variables are passed by value by default!</p>

<p>Read here: <a href=""http://www.webeks.net/programming/php/ampersand-operator-used-for-assigning-reference.html"" rel=""nofollow noreferrer"">http://www.webeks.net/programming/php/ampersand-operator-used-for-assigning-reference.html</a></p>
",247128.0,27.0,1
879,897,False,"<p>Variables containing primitive types are passed by value in PHP5. Variables containing objects are passed by reference. There's quite an interesting article from Linux Journal from 2006 which mentions this and other OO differences between 4 and 5.</p>

<p><a href=""http://www.linuxjournal.com/article/9170"" rel=""noreferrer"">http://www.linuxjournal.com/article/9170</a></p>
",137.0,22414.0,5
879,896,False,"<p><a href=""http://www.php.net/manual/en/migration5.oop.php"" rel=""noreferrer"">http://www.php.net/manual/en/migration5.oop.php</a></p>

<blockquote>
  <p>In PHP 5 there is a new Object Model. PHP's handling of objects has been completely rewritten, allowing for better performance and more features. In previous versions of PHP, objects were handled like primitive types (for instance integers and strings). The drawback of this method was that semantically the whole object was copied when a variable was assigned, or passed as a parameter to a method. In the new approach, objects are referenced by handle, and not by value (one can think of a handle as an object's identifier).</p>
</blockquote>
",34.0,20440.0,32
879,880,False,"<p>Depends on the version, 4 is by value, 5 is by reference.</p>
",34.0,20440.0,-6
888,36131176,False,"<h3><a href=""http://phpdbg.com/"" rel=""nofollow noreferrer"">PHP DBG</a></h3>

<p>The Interactive Stepthrough PHP Debugger implemented as a SAPI module which can give give you complete control over the environment without impacting the functionality or performance of your code. It aims to be a lightweight, powerful, easy to use debugging platform for PHP 5.4+ and it's shipped out-of-box with PHP 5.6.</p>

<p>Features includes:</p>

<ul>
<li>Stepthrough Debugging</li>
<li>Flexible Breakpoints (Class Method, Function, File:Line, Address, Opcode)</li>
<li>Easy Access to PHP with built-in eval()</li>
<li>Easy Access to Currently Executing Code</li>
<li>Userland API</li>
<li>SAPI Agnostic - Easily Integrated</li>
<li>PHP Configuration File Support</li>
<li>JIT Super Globals - Set Your Own!!</li>
<li>Optional readline Support - Comfortable Terminal Operation</li>
<li>Remote Debugging Support - Bundled Java GUI</li>
<li>Easy Operation</li>
</ul>

<p>See the screenshots:</p>

<p><a href=""https://i.stack.imgur.com/yFHuH.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/yFHuH.png"" alt=""PHP DBG - Stepthrough Debugging - screenshot""></a></p>

<p><a href=""https://i.stack.imgur.com/WVFoN.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/WVFoN.png"" alt=""PHP DBG - Stepthrough Debugging - screenshot""></a></p>

<p>Home page: <a href=""http://phpdbg.com/"" rel=""nofollow noreferrer"">http://phpdbg.com/</a></p>

<h3><a href=""http://phperror.net/"" rel=""nofollow noreferrer"">PHP Error</a> - Better error reporting for PHP</h3>

<p>This is very easy to use library (actually a file) to debug your PHP scripts.</p>

<p>The only thing that you need to do is to include one file as below (at the beginning on your code):</p>

<pre><code>require('php_error.php');
\php_error\reportErrors();
</code></pre>

<p>Then all errors will give you info such as backtrace, code context, function arguments, server variables, etc. For example:</p>

<p><a href=""https://i.stack.imgur.com/csob7.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/csob7.png"" alt=""PHP Error | Improve Error Reporting for PHP - screenshot of backtrace""></a>
<a href=""https://i.stack.imgur.com/ulpyZ.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/ulpyZ.png"" alt=""PHP Error | Improve Error Reporting for PHP - screenshot of backtrace""></a>
<a href=""https://i.stack.imgur.com/ZiJwK.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/ZiJwK.png"" alt=""PHP Error | Improve Error Reporting for PHP - screenshot of backtrace""></a></p>

<p>Features include:</p>

<ul>
<li>trivial to use, it's just one file</li>
<li>errors displayed in the browser for normal and ajaxy requests</li>
<li>AJAX requests are paused, allowing you to automatically re-run them</li>
<li>makes errors as strict as possible (encourages code quality, and tends to improve performance)</li>
<li>code snippets across the whole stack trace</li>
<li>provides more information (such as full function signatures)</li>
<li>fixes some error messages which are just plain wrong</li>
<li>syntax highlighting</li>
<li>looks pretty!</li>
<li>customization</li>
<li>manually turn it on and off</li>
<li>run specific sections without error reporting</li>
<li>ignore files allowing you to avoid highlighting code in your stack trace</li>
<li>application files; these are prioritized when an error strikes!</li>
</ul>

<p>Home page: <a href=""http://phperror.net/"" rel=""nofollow noreferrer"">http://phperror.net/</a></p>

<p>GitHub: <a href=""https://github.com/JosephLenton/PHP-Error"" rel=""nofollow noreferrer"">https://github.com/JosephLenton/PHP-Error</a></p>

<p>My fork (with extra fixes): <a href=""https://github.com/kenorb-contrib/PHP-Error"" rel=""nofollow noreferrer"">https://github.com/kenorb-contrib/PHP-Error</a></p>

<h3><a href=""https://en.wikipedia.org/wiki/DTrace"" rel=""nofollow noreferrer"">DTrace</a></h3>

<p>If your system supports <a href=""http://php.net/manual/en/features.dtrace.php"" rel=""nofollow noreferrer"">DTrace dynamic tracing</a> (installed by default on OS X) and your PHP is compiled with the DTrace probes enabled (<code>--enable-dtrace</code>) which should be by default, this command can help you to debug PHP script with no time:</p>

<pre><code>sudo dtrace -qn 'php*:::function-entry { printf(""%Y: PHP function-entry:\t%s%s%s() in %s:%d\n"", walltimestamp, copyinstr(arg3), copyinstr(arg4), copyinstr(arg0), basename(copyinstr(arg1)), (int)arg2); }'
</code></pre>

<p>So given the following alias has been added into your <em>rc</em> files (e.g. <code>~/.bashrc</code>, <code>~/.bash_aliases</code>):</p>

<pre><code>alias trace-php='sudo dtrace -qn ""php*:::function-entry { printf(\""%Y: PHP function-entry:\t%s%s%s() in %s:%d\n\"", walltimestamp, copyinstr(arg3), copyinstr(arg4), copyinstr(arg0), basename(copyinstr(arg1)), (int)arg2); }""'
</code></pre>

<p>you may trace your script with easy to remember alias: <code>trace-php</code>.</p>

<p>Here is more advanced dtrace script, just save it into <code>dtruss-php.d</code>, make it executable (<code>chmod +x dtruss-php.d</code>) and run:</p>

<pre><code>#!/usr/sbin/dtrace -Zs
# See: https://github.com/kenorb/dtruss-lamp/blob/master/dtruss-php.d

#pragma D option quiet

php*:::compile-file-entry
{
    printf(""%Y: PHP compile-file-entry:\t%s (%s)\n"", walltimestamp, basename(copyinstr(arg0)), copyinstr(arg1));
}

php*:::compile-file-return
{
    printf(""%Y: PHP compile-file-return:\t%s (%s)\n"", walltimestamp, basename(copyinstr(arg0)), basename(copyinstr(arg1)));
}

php*:::error
{
    printf(""%Y: PHP error message:\t%s in %s:%d\n"", walltimestamp, copyinstr(arg0), basename(copyinstr(arg1)), (int)arg2);
}

php*:::exception-caught
{
    printf(""%Y: PHP exception-caught:\t%s\n"", walltimestamp, copyinstr(arg0));
}

php*:::exception-thrown
{
    printf(""%Y: PHP exception-thrown:\t%s\n"", walltimestamp, copyinstr(arg0));
}

php*:::execute-entry
{
    printf(""%Y: PHP execute-entry:\t%s:%d\n"", walltimestamp, basename(copyinstr(arg0)), (int)arg1);
}

php*:::execute-return
{
    printf(""%Y: PHP execute-return:\t%s:%d\n"", walltimestamp, basename(copyinstr(arg0)), (int)arg1);
}

php*:::function-entry
{
    printf(""%Y: PHP function-entry:\t%s%s%s() in %s:%d\n"", walltimestamp, copyinstr(arg3), copyinstr(arg4), copyinstr(arg0), basename(copyinstr(arg1)), (int)arg2);
}

php*:::function-return
{
    printf(""%Y: PHP function-return:\t%s%s%s() in %s:%d\n"", walltimestamp, copyinstr(arg3), copyinstr(arg4), copyinstr(arg0), basename(copyinstr(arg1)), (int)arg2);
}

php*:::request-shutdown
{
    printf(""%Y: PHP request-shutdown:\t%s at %s via %s\n"", walltimestamp, basename(copyinstr(arg0)), copyinstr(arg1), copyinstr(arg2));
}

php*:::request-startup
{
    printf(""%Y, PHP request-startup:\t%s at %s via %s\n"", walltimestamp, basename(copyinstr(arg0)), copyinstr(arg1), copyinstr(arg2));
}
</code></pre>

<p><sup>Home page: <a href=""https://github.com/kenorb/dtruss-lamp"" rel=""nofollow noreferrer"">dtruss-lamp</a> at GitHub</sup></p>

<p>Here is simple usage:</p>

<ol>
<li>Run: <code>sudo dtruss-php.d</code>.</li>
<li>On another terminal run: <code>php -r ""phpinfo();""</code>.</li>
</ol>

<p>To test that, you can go to any docroot with <code>index.php</code> and run PHP builtin server by:</p>

<pre><code>php -S localhost:8080
</code></pre>

<p>After that you can access the site at <a href=""http://localhost:8080/"" rel=""nofollow noreferrer"">http://localhost:8080/</a> (or choose whatever port is convenient for you). From there access some pages to see the trace output.</p>

<p>Note: Dtrace is available on OS X by default, on Linux you probably need <a href=""https://github.com/dtrace4linux/linux"" rel=""nofollow noreferrer"">dtrace4linux</a> or check for some other <a href=""https://stackoverflow.com/q/2059311/55075"">alternatives</a>.</p>

<p>See: <a href=""http://php.net/manual/en/features.dtrace.dtrace.php"" rel=""nofollow noreferrer"">Using PHP and DTrace</a> at php.net</p>

<hr>

<h3><a href=""https://en.wikipedia.org/wiki/SystemTap"" rel=""nofollow noreferrer"">SystemTap</a></h3>

<p>Alternatively check for SystemTap tracing by installing SystemTap SDT development package (e.g. <code>yum install systemtap-sdt-devel</code>).</p>

<p>Here is example script (<code>all_probes.stp</code>) for tracing all core PHP static probe points throughout the duration of a running PHP script with SystemTap:</p>

<pre><code>probe process(""sapi/cli/php"").provider(""php"").mark(""compile__file__entry"") {
    printf(""Probe compile__file__entry\n"");
    printf(""  compile_file %s\n"", user_string($arg1));
    printf(""  compile_file_translated %s\n"", user_string($arg2));
}
probe process(""sapi/cli/php"").provider(""php"").mark(""compile__file__return"") {
    printf(""Probe compile__file__return\n"");
    printf(""  compile_file %s\n"", user_string($arg1));
    printf(""  compile_file_translated %s\n"", user_string($arg2));
}
probe process(""sapi/cli/php"").provider(""php"").mark(""error"") {
    printf(""Probe error\n"");
    printf(""  errormsg %s\n"", user_string($arg1));
    printf(""  request_file %s\n"", user_string($arg2));
    printf(""  lineno %d\n"", $arg3);
}
probe process(""sapi/cli/php"").provider(""php"").mark(""exception__caught"") {
    printf(""Probe exception__caught\n"");
    printf(""  classname %s\n"", user_string($arg1));
}
probe process(""sapi/cli/php"").provider(""php"").mark(""exception__thrown"") {
    printf(""Probe exception__thrown\n"");
    printf(""  classname %s\n"", user_string($arg1));
}
probe process(""sapi/cli/php"").provider(""php"").mark(""execute__entry"") {
    printf(""Probe execute__entry\n"");
    printf(""  request_file %s\n"", user_string($arg1));
    printf(""  lineno %d\n"", $arg2);
}
probe process(""sapi/cli/php"").provider(""php"").mark(""execute__return"") {
    printf(""Probe execute__return\n"");
    printf(""  request_file %s\n"", user_string($arg1));
    printf(""  lineno %d\n"", $arg2);
}
probe process(""sapi/cli/php"").provider(""php"").mark(""function__entry"") {
    printf(""Probe function__entry\n"");
    printf(""  function_name %s\n"", user_string($arg1));
    printf(""  request_file %s\n"", user_string($arg2));
    printf(""  lineno %d\n"", $arg3);
    printf(""  classname %s\n"", user_string($arg4));
    printf(""  scope %s\n"", user_string($arg5));
}
probe process(""sapi/cli/php"").provider(""php"").mark(""function__return"") {
    printf(""Probe function__return: %s\n"", user_string($arg1));
    printf("" function_name %s\n"", user_string($arg1));
    printf(""  request_file %s\n"", user_string($arg2));
    printf(""  lineno %d\n"", $arg3);
    printf(""  classname %s\n"", user_string($arg4));
    printf(""  scope %s\n"", user_string($arg5));
}
probe process(""sapi/cli/php"").provider(""php"").mark(""request__shutdown"") {
    printf(""Probe request__shutdown\n"");
    printf(""  file %s\n"", user_string($arg1));
    printf(""  request_uri %s\n"", user_string($arg2));
    printf(""  request_method %s\n"", user_string($arg3));
}
probe process(""sapi/cli/php"").provider(""php"").mark(""request__startup"") {
    printf(""Probe request__startup\n"");
    printf(""  file %s\n"", user_string($arg1));
    printf(""  request_uri %s\n"", user_string($arg2));
    printf(""  request_method %s\n"", user_string($arg3));
}
</code></pre>

<p>Usage:</p>

<pre><code>stap -c 'sapi/cli/php test.php' all_probes.stp
</code></pre>

<p>See: <a href=""http://php.net/manual/en/features.dtrace.systemtap.php"" rel=""nofollow noreferrer"">Using SystemTap with PHP DTrace Static Probes</a> at php.net</p>
",55075.0,116798.0,1
888,890,True,"<p>Try <a href=""https://eclipse.org/pdt/"" rel=""noreferrer"">Eclipse PDT</a> to setup an Eclipse environment that has debugging features like you mentioned. The ability to step into the code is a much better way to debug then the old method of var_dump and print at various points to see where your flow goes wrong. When all else fails though and all I have is SSH and vim I still <code>var_dump()</code>/<code>die()</code> to find where the code goes south.</p>
",200.0,12856.0,145
888,2599,False,"<p>You can use Firephp an add-on to firebug to debug php in the same environment as javascript.</p>

<p>I also use <a href=""http://xdebug.org/"" rel=""noreferrer"">Xdebug</a> mentioned earlier for profiling php.</p>
",238.0,34792.0,80
888,32886213,False,"<p>There are many PHP debugging techniques that can save you countless hours when coding. An effective but basic debugging technique is to simply turn on error reporting. Another slightly more advanced technique involves using print statements, which can help pinpoint more elusive bugs by displaying what is actually going onto the screen. PHPeclipse is an Eclipse plug-in that can highlight common syntax errors and can be used in conjunction with a debugger to set breakpoints.</p>

<pre><code>display_errors = Off
error_reporting = E_ALL 
display_errors = On
</code></pre>

<p>and also used</p>

<pre><code>error_log();
console_log();
</code></pre>
",5291660.0,21.0,2
888,22691,False,"<p><a href=""http://www.xdebug.org/"" rel=""noreferrer"">XDebug</a> is essential for development. I install it before any other extension. It gives you stack traces on any error and you can enable profiling easily.</p>

<p>For a quick look at a data structure use <a href=""http://www.php.net/manual/en/function.var-dump.php"" rel=""noreferrer""><code>var_dump()</code></a>. Don't use <code>print_r()</code> because you'll have to surround it with <code>&lt;pre&gt;</code> and it only prints one var at a time.</p>

<pre><code>&lt;?php var_dump(__FILE__, __LINE__, $_REQUEST); ?&gt;
</code></pre>

<p>For a real debugging environment the best I've found is <a href=""http://www.activestate.com/Products/komodo_ide/index.mhtml"" rel=""noreferrer"">Komodo IDE</a> but it costs $$.</p>
",2148.0,10746.0,26
888,1058375,False,"<p>This is my little debug environment:</p>

<pre><code>error_reporting(-1);
assert_options(ASSERT_ACTIVE, 1);
assert_options(ASSERT_WARNING, 0);
assert_options(ASSERT_BAIL, 0);
assert_options(ASSERT_QUIET_EVAL, 0);
assert_options(ASSERT_CALLBACK, 'assert_callcack');
set_error_handler('error_handler');
set_exception_handler('exception_handler');
register_shutdown_function('shutdown_handler');

function assert_callcack($file, $line, $message) {
    throw new Customizable_Exception($message, null, $file, $line);
}

function error_handler($errno, $error, $file, $line, $vars) {
    if ($errno === 0 || ($errno &amp; error_reporting()) === 0) {
        return;
    }

    throw new Customizable_Exception($error, $errno, $file, $line);
}

function exception_handler(Exception $e) {
    // Do what ever!
    echo '&lt;pre&gt;', print_r($e, true), '&lt;/pre&gt;';
    exit;
}

function shutdown_handler() {
    try {
        if (null !== $error = error_get_last()) {
            throw new Customizable_Exception($error['message'], $error['type'], $error['file'], $error['line']);
        }
    } catch (Exception $e) {
        exception_handler($e);
    }
}

class Customizable_Exception extends Exception {
    public function __construct($message = null, $code = null, $file = null, $line = null) {
        if ($code === null) {
            parent::__construct($message);
        } else {
            parent::__construct($message, $code);
        }
        if ($file !== null) {
            $this-&gt;file = $file;
        }
        if ($line !== null) {
            $this-&gt;line = $line;
        }
    }
}
</code></pre>
",113154.0,3351.0,38
888,10799401,False,"<p>Nusphere is also a good debugger for php
<a href=""http://www.nusphere.com/download.php.ide.htm"" rel=""nofollow"">nusphere</a></p>
",1326539.0,5374.0,2
888,3209562,False,"<p>I use Netbeans with XDebug and the <a href=""http://www.elime.be/easyxdebug.htm"" rel=""noreferrer"" title=""Easy XDebug FireFox Add-on"">Easy XDebug FireFox Add-on</a> </p>

<p>The add-on is essential when you debug MVC projects, because the normal way XDebug runs in Netbeans is to register the dbug session via the url. With the add-on installed in FireFox, you would set your Netbeans project properties -> Run Configuratuion -> Advanced and select ""Do Not Open Web Browser"" You can now set your break points and start the debugging session with Ctrl-F5 as usual. Open FireFox and right-click the Add-on icon in the right bottom corner to start monitoring for breakpoints. When the code reaches the breakpoint it will stop and you can inspect your variable states and call-stack.</p>
",96944.0,21312.0,11
888,2801595,False,"<p>I often use CakePHP when Rails isn't possible. To debug errors I usually find the <code>error.log</code> in the tmp folder and tail it in the terminal with the command...</p>

<pre><code>tail -f app/tmp/logs/error.log
</code></pre>

<p>It give's you running dialog from cake of what is going on, which is pretty handy, if you want to output something to it mid code you can use.</p>

<pre><code>$this-&gt;log('xxxx');
</code></pre>

<p>This can usually give you a good idea of what is going on/wrong.</p>
",269404.0,5735.0,3
888,2801537,False,"<p>The most of bugs can be found easily by simply <code>var_dump</code>ing some of key variables, but it obviously depends on what kind of application you develop.</p>

<p>For a more complex algorithms the step/breakpoint/watch functions are very helpful (if not necessary)</p>
",190438.0,8009.0,1
888,4172,False,"<p>1) I use print_r(). In TextMate, I have a snippet for 'pre' which expands to this:</p>

<pre><code>echo ""&lt;pre&gt;"";
print_r();
echo ""&lt;/pre&gt;"";
</code></pre>

<p>2) I use Xdebug, but haven't been able to get the GUI to work right on my Mac. It at least prints out a readable version of the stack trace.</p>
",586.0,3500.0,17
888,515128,False,"<p>PhpEd is really good. You can step into/over/out of functions. You can run ad-hoc code, inspect variables, change variables. It is amazing.</p>
",563932.0,337.0,19
888,224986,False,"<p>Output buffering is very useful if you don't want to mess up your output. I do this in a one-liner which I can comment/uncomment at will </p>

<pre><code> ob_start();var_dump(); user_error(ob_get_contents()); ob_get_clean();
</code></pre>
",20074.0,70658.0,10
888,224920,False,"<p>Usually I find create a custom log function able to save on file, store debug info, and eventually re-print on a common footer.</p>

<p>You can also override common Exception class, so that this type of debugging is semi-automated.</p>
",15392.0,525.0,0
888,89699,False,"<p>Well, to some degree it depends on where things are going south. That's the first thing I try to isolate, and then I'll use echo/print_r() as necessary.</p>

<p>NB: You guys know that you can pass true as a second argument to print_r() and it'll return the output instead of printing it? E.g.:</p>

<pre><code>echo ""&lt;pre&gt;"".print_r($var, true).""&lt;/pre&gt;"";
</code></pre>
",9780.0,2251.0,3
888,81725,False,"<p>PhpEdit has a built in debugger, but I usually end up using echo(); and print_r(); the old fashioned way!!</p>
",6244.0,10544.0,9
888,66572,False,"<p>Xdebug and the DBGp plugin for Notepad++ for heavy duty bug hunting, FirePHP for lightweight stuff. Quick and dirty? Nothing beats <a href=""http://dbug.ospinto.com/"" rel=""noreferrer"">dBug</a>.</p>
",9673.0,3918.0,32
888,28284,False,"<p>I use Netbeans with XDebug. 
Check it out at its website for docs on how to configure it.
<a href=""http://php.netbeans.org/"" rel=""noreferrer"">http://php.netbeans.org/</a></p>
",3086.0,7494.0,11
888,23359,False,"<p>The integrated debuggers where you can watch the values of variable change as you step through code are really cool. They do, however, require software setup on the server and a certain amount of configuration on the client. Both of which require periodic maintenance to keep in good working order.</p>

<p>A print_r is easy to write and is guaranteed to work in any setup.</p>
",2158.0,17.0,0
888,22695,False,"<p>Komodo IDE works well with xdebug, even for the remore debugging. It needs minimum amount of configuration. All you need is a version of php that Komodo can use locally to step through the code on a breakpoint. If you have the script imported into komodo project, then you can set breakpoints with a mouse-click just how you would set it inside eclipse for debugging a java program.
Remote debugging is obviously more tricky to get it to work correctly ( you might have to map the remote url with a php script in your workspace ) than a local debugging setup which is pretty easy to configure if you are on a MAC or a linux desktop.</p>
",,,2
888,22681,False,"<p>Manual debugging is generally quicker for me - <code>var_dump()</code> and <code>debug_print_backtrace()</code> are all the tools you need to arm your logic with.</p>
",2025.0,42948.0,4
888,22675,False,"<p>For the really gritty problems that would be too time consuming to use print_r/echo to figure out I use my IDE's (PhpEd) debugging feature.  Unlike other IDEs I've used, PhpEd requires pretty much no setup.  the only reason I don't use it for any problems I encounter is that it's <em>painfully</em> slow.  I'm not sure that slowness is specific to PhpEd or any php debugger.  PhpEd is not free but I believe it uses one of the open-source debuggers (like XDebug previously mentioned) anyway.  The benefit with PhpEd, again, is that it requires no setup which I have found really pretty tedious in the past.</p>
",2494.0,17497.0,8
888,13817,False,"<p>i use zend studio for eclipse with the built in debugger. Its still slow compared to debugging with eclipse pdt with xdebug. Hopefully they will fix those issues, the speed has improved over the recent releases but still stepping over things takes 2-3 seconds.
The zend firefox toolbar really makes things easy (debug next page, current page, etc). Also it provides a profiler that will benchmark your code and provide pie-charts, execution time, etc.</p>
",1425.0,2453.0,1
888,11956,False,"<p>In a production environment, I log relevant data to the server's error log with error_log().</p>
",,,1
888,3579,False,"<p>Depending on the issue I like a combination of error_reporting(E_ALL) mixed with echo tests (to find the offending line/file the error happened in initally; you KNOW it's not always the line/file php tells you right?), IDE brace matching (to resolve ""Parse error: syntax error, unexpected $end"" issues), and print_r(); exit; dumps (real programmers view the source ;p). </p>

<p>You also can't beat phpdebug (check sourceforge) with ""memory_get_usage();"" and ""memory_get_peak_usage();"" to find the problem areas.</p>
",538.0,1396.0,0
888,1758,False,"<p>+1 for print_r(). Use it to dump out the contents of an object or variable. To make it more readable, do it with a pre tag so you don't need to view source. </p>

<pre><code>echo '&lt;pre&gt;';
print_r($arrayOrObject);
</code></pre>

<p>Also var_dump($thing) - this is very useful to see the type of subthings</p>
",137.0,22414.0,0
888,1602,False,"<p>In all honesty, a combination of print and print_r() to print out the variables. I know that many prefer to use other more advanced methods but I find this the easiest to use.</p>

<p>I will say that I didn't fully appreciate this until I did some Microprocessor programming at Uni and was not able to use even this.</p>
",1384652.0,97775.0,16
888,1587,False,"<p><a href=""http://xdebug.org/"" rel=""noreferrer"">Xdebug</a>, by Derick Rethans, is very good. I used it some time ago and found it was not so easy to install. Once you're done, you won't understand how you managed without it :-)</p>

<p>There is a good article on <a href=""http://devzone.zend.com/article/2803-introducing-xdebug"" rel=""noreferrer"">Zend Developer Zone</a> (installing on Linux doesn't seem any easier) and even a <a href=""https://addons.mozilla.org/fr/firefox/addon/3960"" rel=""noreferrer"">Firefox plugin</a>, which I never used.</p>
",341.0,17787.0,14
888,891,False,"<p>print_r( debug_backtrace() );</p>

<p>or something like that :-)</p>
",234.0,113281.0,2
888,889,False,"<p>I've used the <a href=""http://www.zend.com/products/studio/"" rel=""noreferrer"">Zend Studio (5.5)</a>, together with <a href=""http://www.zend.com/en/products/platform/"" rel=""noreferrer"">Zend Platform</a>. That gives proper debugging, breakpoints/stepping over the code etc., although at a price.</p>
",91.0,166977.0,16
904,52311670,False,"<p>You can use 0 width space after hyphen character:</p>

<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-css lang-css prettyprint-override""><code>div {
  width: 150px;
}</code></pre>
<pre class=""snippet-code-html lang-html prettyprint-override""><code>&lt;div&gt;
  12333-&amp;#8203;2333-&amp;#8203;233-&amp;#8203;23339392-&amp;#8203;332332323
&lt;/div&gt;</code></pre>
</div>
</div>
</p>

<p>if You want line break before hyphen use <code>&amp;#8203;-</code> instead.</p>
",387194.0,51395.0,0
904,343686,False,"<p>In this specific instance (where your string is going to contain hyphens) I'd transform the text to this server-side:</p>

<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-html lang-html prettyprint-override""><code>&lt;div style=""width:150px;""&gt;
  &lt;span&gt;12333-&lt;/span&gt;&lt;span&gt;2333-&lt;/span&gt;&lt;span&gt;233-&lt;/span&gt;&lt;span&gt;23339392-&lt;/span&gt;&lt;span&gt;332332323&lt;/span&gt;
&lt;/div&gt;</code></pre>
</div>
</div>
</p>
",8513.0,2855.0,8
904,45979734,False,"<p>Hope this may help</p>

<p>use <code>&lt;br&gt;</code>(break) tag where you want to break the line.</p>
",8040185.0,916.0,0
904,911,True,"<p>Replace your hyphens with this:</p>

<pre><code>&amp;shy;
</code></pre>

<p>It's called a ""soft"" hyphen.</p>

<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-css lang-css prettyprint-override""><code>div {
  width: 150px;
}</code></pre>
<pre class=""snippet-code-html lang-html prettyprint-override""><code>&lt;div&gt;
  12333&amp;shy;2333&amp;shy;233&amp;shy;23339392&amp;shy;332332323
&lt;/div&gt;</code></pre>
</div>
</div>
</p>
",55.0,9396.0,72
904,9060345,False,"<p>In all modern browsers<sup>*</sup> (and in some <a href=""http://www.quirksmode.org/oddsandends/wbr.html"" rel=""noreferrer"">older browsers</a>, too), the <a href=""https://developer.mozilla.org/en/HTML/Element/wbr"" rel=""noreferrer""><code>&lt;wbr&gt;</code> element</a> is the perfect tool for providing the opportunity to break long words at specific points.</p>

<p>To quote from that link:</p>

<blockquote>
  <p>The Word Break Opportunity (<code>&lt;wbr&gt;</code>) HTML element represents a position within text where the browser may optionally break a line, though its line-breaking rules would not otherwise create a break at that location.</p>
</blockquote>

<p>Here's how it could be used to in the OP's example (or see it in action at <a href=""http://jsfiddle.net/AdleyEskridge/qrgaK/"" rel=""noreferrer"">JSFiddle</a>):</p>

<pre><code>&lt;div style=""width: 150px;""&gt;
  12333-&lt;wbr&gt;2333-&lt;wbr&gt;233-&lt;wbr&gt;23339392-&lt;wbr&gt;332332323
&lt;/div&gt;
</code></pre>

<p><sup>*</sup>I've tested it in IE9, IE10, and the latest versions of Chrome, Firefox, and Opera, and Safari.</p>

<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-css lang-css prettyprint-override""><code>div {
  width: 150px;
}</code></pre>
<pre class=""snippet-code-html lang-html prettyprint-override""><code>&lt;div&gt;
  12333-&lt;wbr&gt;2333-&lt;wbr&gt;233-&lt;wbr&gt;23339392-&lt;wbr&gt;332332323
&lt;/div&gt;</code></pre>
</div>
</div>
</p>
",1125471.0,3376.0,33
904,32249676,False,"<p>You can also use :</p>

<pre><code>word-break:break-all;
</code></pre>

<p>ex.</p>

<pre><code>&lt;div style='width:10px'&gt;ababababababbabaabababababababbabababa&lt;/div&gt;
</code></pre>

<p>output:</p>

<pre><code>abababababa
ababababbba
abbabbababa
ababb
</code></pre>

<p>word-break is break all the word or line even if no-space in sentence that not feets in provided width or height. nut for that you must be provide a width or height.</p>
",2663073.0,2235.0,2
904,30229247,False,"<p>Instead of <code>-</code> you can use <code>&amp;hyphen;</code> or <code>\u2010</code>.</p>

<p>Also, make sure the <strong>hyphens</strong> css property was <strong>not</strong> set to <em>none</em> (The default value is <em>manual</em>).</p>

<p><code>&lt;wbr&gt;</code> is not supported by <em>Internet Explorer</em>.</p>
",4736743.0,41.0,0
904,912,False,"<p>As part of CSS3, it is not yet fully supported, <a href=""http://www.css3.info/preview/word-wrap/"" rel=""noreferrer"">but you can find information on word-wrapping here</a>. Another option is the <a href=""http://www.quirksmode.org/oddsandends/wbr.html"" rel=""noreferrer"">wbr tag, &amp;shy;, and &amp;#8203;</a> none of which are fully supported either.</p>
",200.0,12856.0,17
904,3725181,False,"<p>Depending on what you want to see exactly, you can use a combination of <code>hyphen</code>, <code>soft hyphen</code>, and/or <code>zero width space</code>.</p>

<p>On a soft hyphen, your browser can word-break (adding an hyphen).
On a zero width space, your browser can word break (without adding anything).</p>

<p>Thus, if your code is something like : </p>

<p><code>111111&amp;shy;222222&amp;shy;-333333&amp;#8203;444444-&amp;#8203;555555</code></p>

<p>then your browser will show this with no word-break :</p>

<blockquote>
  <p>1111112222222-33333334444444-5555555</p>
</blockquote>

<p>and this will every possible word-break :</p>

<blockquote>
  <p>111111-<br/>
  222222-<br/>
  -333333<br/>
  444444-<br/>
  555555</p>
</blockquote>

<p>Just pick up the option you need. In your case, it may be the one between 4s and 5s.</p>
",449300.0,71.0,7
904,22570418,False,"<p>The non-breaking hyphen works well.</p>

<p><strong>HTML Entity (decimal)</strong>   </p>

<pre><code>&amp;#8209;
</code></pre>
",3329778.0,2921.0,0
904,67878,False,"<p>Your example works as expected in Google Chrome, Safari (Windows), and IE8. The text breaks out of the 150px box in Firefox 3 and Opera 9.5.</p>

<p>Additionally <code>&amp;shy;</code> won't work for your example, as it will either:</p>

<ul>
<li><p>work when word-breaking but when not word-breaking not display any hyphens, or </p></li>
<li><p>work when not word-breaking but display two hyphens when word-breaking
since it adds a hyphen on a break.</p></li>
</ul>
",2486915.0,5467.0,8
905,942,True,"<p>All editions of <code>SQL Server 2000/2005/2008</code> support having multiple databases, each using their own collation sequence.  You don't need the Enterprise version.  </p>

<p>When you have a database that uses a collation sequence that is different from default collation for the database server, you will need to take some extra precautions if you use temporary tables and/or table variables.  Temp tables/variables live in the tempdb database, which uses the collation seqyuence used by by the master databases.  Just remember to use ""<code>COLLATE database_default</code>"" when defining character fields in the temp tables/variables.  I <a href=""http://anotherlab.rajapet.net/2008/07/handling-collation-sequences-with.html"" rel=""nofollow noreferrer"">blogged about that</a> not too long ago, if you want some more details.</p>
",206.0,4489.0,6
930,56179247,False,"<p>Charge the libraries</p>

<pre><code>using MySql.Data.MySqlClient;
</code></pre>

<p>This is the connection:</p>

<pre class=""lang-cs prettyprint-override""><code>public static MySqlConnection obtenerconexion()
{
    string server = ""Server"";
    string database = ""Name_Database"";
    string Uid = ""User"";
    string pwd = ""Password"";
    MySqlConnection conect = new MySqlConnection(""server = "" + server + "";"" + ""database ="" + database + "";"" + ""Uid ="" + Uid + "";"" + ""pwd="" + pwd + "";"");

    try
    {
        conect.Open();
        return conect;
    }
    catch (Exception)
    {
        MessageBox.Show(""Error. Ask the administrator"", ""An error has occurred while trying to connect to the system"", MessageBoxButtons.OK, MessageBoxIcon.Error);
        return conect;
    }
}
</code></pre>
",11507342.0,1.0,0
930,20049,False,"<p>If you are querying a SQL Server database (Version 7 and up) you should replace the OleDb classes with corresponding classes in the <a href=""https://docs.microsoft.com/en-us/dotnet/api/system.data.sqlclient"" rel=""nofollow noreferrer"">System.Data.SqlClient</a> namespace (<a href=""https://docs.microsoft.com/en-us/dotnet/api/system.data.sqlclient.sqlconnection"" rel=""nofollow noreferrer"">SqlConnection</a>, <a href=""https://docs.microsoft.com/en-us/dotnet/api/system.data.sqlclient.sqlcommand"" rel=""nofollow noreferrer"">SqlCommand</a> and <a href=""https://docs.microsoft.com/en-us/dotnet/api/system.data.sqlclient.sqldatareader"" rel=""nofollow noreferrer"">SqlDataReader</a>) as those classes have been optimized to work with SQL Server.</p>

<p>Another thing to note is that you should 'never' select all as this might lead to unexpected results later on if you add or remove columns to this table.</p>
",202.0,7809.0,4
930,65774,False,"<p>If you are intending on reading a large number of columns or records it's also worth caching the ordinals and accessing the strongly-typed methods, e.g.</p>

<pre><code>using (DbDataReader dr = cmd.ExecuteReader()) {
  if (dr.Read()) {
    int idxColumnName = dr.GetOrdinal(""columnName"");
    int idxSomethingElse = dr.GetOrdinal(""somethingElse"");

    do {
      Console.WriteLine(dr.GetString(idxColumnName));
      Console.WriteLine(dr.GetInt32(idxSomethingElse));
    } while (dr.Read());
  }
}
</code></pre>
",5720.0,6210.0,4
930,940,False,"<p>Very roughly and from memory since I don't have code on this laptop:</p>

<pre><code>using (OleDBConnection conn = new OleDbConnection())
{
  conn.ConnectionString = ""Whatever connection string"";

  using (OleDbCommand cmd = new OleDbCommand())
  {
    cmd.Connection = conn;
    cmd.CommandText = ""Select * from CoolTable"";

    using (OleDbDataReader dr = cmd.ExecuteReader())
    {
      while (dr.Read())
      {
        // do something like Console.WriteLine(dr[""column name""] as String);
      }
    }
  }
}
</code></pre>
",243.0,21897.0,17
930,951,True,"<p>@Goyuix -- that's excellent for something written from memory.
tested it here -- found the connection wasn't opened. Otherwise very nice.</p>

<pre><code>using System.Data.OleDb;
...

using (OleDbConnection conn = new OleDbConnection())
{
    conn.ConnectionString = ""Provider=sqloledb;Data Source=yourServername\\yourInstance;Initial Catalog=databaseName;Integrated Security=SSPI;"";

    using (OleDbCommand cmd = new OleDbCommand())
    {
        conn.Open();
        cmd.Connection = conn;
        cmd.CommandText = ""Select * from yourTable"";

        using (OleDbDataReader dr = cmd.ExecuteReader())
        {
            while (dr.Read())
            {
                Console.WriteLine(dr[""columnName""]);
            }
        }
    }
}
</code></pre>
",49.0,24433.0,33
930,12288220,False,"<p>I guess, you can try entity framework.</p>

<pre><code>using (SchoolDBEntities ctx = new SchoolDBEntities())
{
     IList&lt;Course&gt; courseList = ctx.GetCoursesByStudentId(1).ToList&lt;Course&gt;();
     //do something with courselist here
}
</code></pre>
",1650003.0,233.0,1
930,2369,False,"<p>This is an alternative way (DataReader is faster than this one):</p>

<pre><code>string s = """";
SqlConnection conn = new SqlConnection(""Server=192.168.1.1;Database=master;Connect Timeout=30;User ID=foobar;Password=raboof;"");
SqlDataAdapter da = new SqlDataAdapter(""SELECT TOP 5 name, dbid FROM sysdatabases"", conn);
DataTable dt = new DataTable();

da.Fill(dt);

for (int i = 0; i &lt; dt.Rows.Count; i++)
{
    s += dt.Rows[i][""name""].ToString() + "" -- "" + dt.Rows[i][""dbid""].ToString() + ""\n"";
}

MessageBox.Show(s);
</code></pre>
",95.0,15969.0,7
930,1022,False,"<p>That's definitely a good way to do it.  But you if you happen to be using a database that supports LINQ to SQL, it can be a lot more fun.  It can look something like this:</p>

<pre><code>MyDB db = new MyDB(""Data Source=..."");
var q = from db.MyTable
        select c;
foreach (var c in q)
  Console.WriteLine(c.MyField.ToString());
</code></pre>
",93.0,11651.0,12
935,938,True,"<p>Partially. The text is inserted, but the warning is still generated.</p>

<p>I found a discussion that indicated the text needed to be preceded with 'E', as such:</p>

<pre><code>insert into EscapeTest (text) values (E'This is the first part \n And this is the second');
</code></pre>

<p>This suppressed the warning, but the text was still not being returned correctly. When I added the additional slash as Michael suggested, it worked.</p>

<p>As such:</p>

<pre><code>insert into EscapeTest (text) values (E'This is the first part \\n And this is the second');
</code></pre>
",246.0,6613.0,139
935,2277307,False,"<p>The warning is issued since you are using backslashes in your strings. If you want to avoid the message, type this command ""set standard_conforming_strings=on;"". Then use ""E"" before your string including backslashes that you want postgresql to intrepret.</p>
",387880.0,1295.0,6
935,104780,False,"<p>I find it highly unlikely for Postgres to truncate your data on input - it either rejects it or stores it as is.</p>

<pre><code>milen@dev:~$ psql
Welcome to psql 8.2.7, the PostgreSQL interactive terminal.

Type:  \copyright for distribution terms
       \h for help with SQL commands
       \? for help with psql commands
       \g or terminate with semicolon to execute query
       \q to quit

milen=&gt; create table EscapeTest (text varchar(50));
CREATE TABLE
milen=&gt; insert into EscapeTest (text) values ('This will be inserted \n This will not be');
WARNING:  nonstandard use of escape in a string literal
LINE 1: insert into EscapeTest (text) values ('This will be inserted...
                                              ^
HINT:  Use the escape string syntax for escapes, e.g., E'\r\n'.
INSERT 0 1
milen=&gt; select * from EscapeTest;
          text
------------------------
 This will be inserted
  This will not be
(1 row)

milen=&gt;
</code></pre>
",15785.0,53711.0,3
935,72132,False,"<p>Really stupid question: Are you sure the string is being truncated, and not just broken at the linebreak you specify (and possibly not showing in your interface)? Ie, do you expect the field to show as</p>
<blockquote>
<p>This will be inserted \n This will not
be</p>
</blockquote>
<p>or</p>
<blockquote>
<p>This will be inserted</p>
<p>This will not be</p>
</blockquote>
<p>Also, what interface are you using? Is it possible that something along the way is eating your backslashes?</p>
",,,0
935,943,False,"<p>Cool.</p>

<p>I also found the documentation regarding the E:</p>

<p><a href=""http://www.postgresql.org/docs/8.3/interactive/sql-syntax-lexical.html#SQL-SYNTAX-STRINGS"" rel=""noreferrer"">http://www.postgresql.org/docs/8.3/interactive/sql-syntax-lexical.html#SQL-SYNTAX-STRINGS</a></p>

<blockquote>
  <p>PostgreSQL also accepts ""escape"" string constants, which are an extension to the SQL standard. An escape string constant is specified by writing the letter E (upper or lower case) just before the opening single quote, e.g. E'foo'. (When continuing an escape string constant across lines, write E only before the first opening quote.) Within an escape string, a backslash character (\) begins a C-like backslash escape sequence, in which the combination of backslash and following character(s) represents a special byte value. \b is a backspace, \f is a form feed, \n is a newline, \r is a carriage return, \t is a tab. Also supported are \digits, where digits represents an octal byte value, and \xhexdigits, where hexdigits represents a hexadecimal byte value. (It is your responsibility that the byte sequences you create are valid characters in the server character set encoding.) Any other character following a backslash is taken literally. Thus, to include a backslash character, write two backslashes (\\). Also, a single quote can be included in an escape string by writing \', in addition to the normal way of ''.</p>
</blockquote>
",91.0,166977.0,43
944,1114,False,"<p><strong>AppDomain.UnhandledException</strong> is an <strong>event</strong>, not a global exception handler. This means, by the time it is raised, your application is already on its way down the drain, and there is nothing you can do about it, except for doing cleanup and error logging.</p>

<p>What happened behind the scenes is this: The framework detected the exception, walked up the call stack to the very top, found no handlers that would recover from the error, so was unable to determine if it was safe to continue execution. So, it started the shutdown sequence and fired up this event as a courtesy to you so you can pay your respects to your already-doomed process. This happens when an exception is left unhandled in the main thread.</p>

<p>There is no single-point solution to this kind of error. You need to put a real exception handler (a catch block) upstream of all places where this error occurs and forward it to (for example) a global handler method/class that will determine if it is safe to simply report and continue, based on exception type and/or content.</p>

<p>Edit: It is possible to disable (=hack) the error-reporting mechanism built into Windows so the mandatory ""crash and burn"" dialog does not get displayed when your app goes down. However, this becomes effective for <em>all</em> the applications in the system, not just your own.</p>
",227.0,13526.0,5
944,108550,False,"<p>Unhandled exception behavior in a .NET 1.x Windows Forms application depends on:</p>

<ul>
<li>The type of thread that threw the exception</li>
<li>Whether it occurred during window message processing</li>
<li>Whether a debugger was attached to the process</li>
<li>The DbgJitDebugLaunchSetting registry setting</li>
<li>The jitDebugging flag in App.Config</li>
<li>Whether you overrode the Windows Forms exception handler</li>
<li>Whether you handled the CLR’s exception event</li>
<li>The phase of the moon</li>
</ul>

<p>The default behavior of unhandled exceptions is:</p>

<ul>
<li>If the exception occurs on the main thread when pumping window messages, it's intercepted by the Windows Forms exception handler.</li>
<li>If the exception occurs on the main thread when pumping window messages, it will terminate the app process unless it's intercepted by the Windows Forms exception handler.</li>
<li>If the exception occurs on a manual, thread-pool, or finalizer thread, it's swallowed by the CLR.</li>
</ul>

<p>The points of contact for an unhandled exception are: </p>

<ul>
<li>Windows Forms exception handler.</li>
<li>The JIT-debug registry switch DbgJitDebugLaunchSetting.</li>
<li>The CLR unhandled exception event.</li>
</ul>

<p>The Windows Form built-in exception handling does the following by default:</p>

<ul>
<li>Catches an unhandled exception when:

<ul>
<li>exception is on main thread and no debugger attached.</li>
<li>exception occurs during window message processing.</li>
<li>jitDebugging = false in App.Config.</li>
</ul></li>
<li>Shows dialog to user and prevents app termination.</li>
</ul>

<p>You can disable the latter behavior by setting jitDebugging = true in <code>App.Config</code>. But remember that this may be your last chance to stop app termination. So the next step to catch an unhandled exception is registering for event Application.ThreadException, e.g.:</p>

<pre><code>Application.ThreadException += new
Threading.ThreadExceptionHandler(CatchFormsExceptions);
</code></pre>

<p>Note the registry setting DbgJitDebugLaunchSetting under HKEY_LOCAL_MACHINE\Software.NetFramework. This has one of three values of which I'm aware:</p>

<ul>
<li>0: shows user dialog asking ""debug or terminate"".</li>
<li>1: lets exception through for CLR to deal with.</li>
<li>2: launches debugger specified in DbgManagedDebugger registry key.</li>
</ul>

<p>In Visual Studio, go to menu <em>Tools</em> → <em>Options</em> → <em>Debugging</em> → <em>JIT</em> to set this key to 0 or 2. But a value of 1 is usually best on an end-user's machine. Note that this registry key is acted on before the CLR unhandled exception event.</p>

<p>This last event is your last chance to log an unhandled exception. It's triggered before your Finally blocks have executed. You can intercept this event as follows:</p>

<pre><code>AppDomain.CurrentDomain.UnhandledException += new
System.UnhandledExceptionEventHandler(CatchClrExceptions);
</code></pre>
",13118.0,16219.0,5
944,986,False,"<p>Is this a console application or a Windows Forms application? If it's a .NET 1.1 console application this is, sadly, by design -- it's confirmed by an MSFT dev in the <a href=""https://blog.codinghorror.com/improved-unhandled-exception-behavior-in-net-20/"" rel=""nofollow noreferrer"">second blog post you referenced</a>:</p>

<blockquote>
  <p>BTW, on my 1.1 machine the example from MSDN does have the expected output; it's just that the second line doesn't show up until after you've attached a debugger (or not). In v2 we've flipped things around so that the UnhandledException event fires before the debugger attaches, which seems to be what most people expect.</p>
</blockquote>

<p>It sounds like .NET 2.0 does this better (thank goodness), but honestly, I never had time to go back and check.</p>
",1.0,60757.0,3
944,990,False,"<p>It's a Windows Forms application. The exceptions that are caught by Application.ThreadException work fine, and I don't get the ugly .NET exception box (<kbd>OK</kbd> to terminate, <kbd>Cancel</kbd> to debug? who came up with that??).</p>

<p>I was getting some exceptions that weren't being caught by that and ended up going to the AppDomain.UnhandledException event that were causing problems. I think I've caught most of those exceptions, and I am displaying them in our nice error box now.</p>

<p>So I'll just have to hope there are not some other circumstances that would cause exceptions to not be caught by the Application.ThreadException handler.</p>
",233.0,43255.0,1
944,1016,True,"<p>Oh, in Windows Forms you definitely should be able to get it to work. The only thing you have to watch out for is things happening on different threads.</p>

<p>I have an old Code Project article here which should help:</p>

<p><em><a href=""http://www.codeproject.com/KB/exception/ExceptionHandling.aspx"" rel=""nofollow noreferrer"">User Friendly Exception Handling</a></em></p>
",1.0,60757.0,12
947,1025,False,"<p>Well, based on the <a href=""http://msdn.microsoft.com/en-us/library/ms682411(VS.85).aspx"" rel=""nofollow noreferrer"">documentation</a> it looks like:</p>

<ol>
<li>Security attributes (can pass null)</li>
<li>Whether it's initially owned (can pass false)</li>
<li>The name of it</li>
</ol>

<p>HTH</p>
",77.0,71047.0,1
947,1028,True,"<p>The VB code looks something like this:</p>

<pre><code>hMutex = CreateMutex(ByVal 0&amp;, 1, ByVal 0&amp;)
</code></pre>

<p>The first parameter is a pointer to an <code>SECURITY_ATTRIBUTES</code> structure. If you don't know what it is, you don't need it. Pass NULL (0).</p>

<p>The second parameter is <code>TRUE</code> (non-zero, or 1) if the calling thread should take ownership of the mutex. <code>FALSE</code> otherwise.</p>

<p>The third parameter is the mutex name and may be NULL (0), as shown. If you need a named mutex, pass the name (anything unique) in. Not sure whether the <code>VB</code> wrapper marshals the length-prefixed <code>VB</code> string type (<code>BSTR</code>) over to a null-terminated Ascii/Unicode string if not, you'll need to do that and numerous examples are out there.</p>

<p>Good luck!</p>
",,,7
947,82335,False,"<p>Here's the VB6 declarations for <a href=""http://msdn.microsoft.com/en-us/library/ms682411(VS.85).aspx"" rel=""noreferrer"">CreateMutex</a> - I just copied them from the API viewer, which you should have as part of your VB6 installation. VB6 marshalls strings to null-terminated ANSI using the current code page.</p>

<pre><code>Public Type SECURITY_ATTRIBUTES
   nLength As Long
   lpSecurityDescriptor As Long
   bInheritHandle As Long 
End Type

Public Declare Function CreateMutex Lib ""kernel32"" Alias ""CreateMutexA"" _
   (lpMutexAttributes As SECURITY_ATTRIBUTES, ByVal bInitialOwner As Long, _
    ByVal lpName As String) As Long
</code></pre>

<p>Bear in mind that if you create a mutex from the VB6 IDE, the mutex belongs to the IDE and won't be destroyed when you stop running your program - only when you close the IDE.</p>
",15639.0,29192.0,9
972,64950870,False,"<p>Apart from what others said, I found that <code>__repr__</code> and <code>__str__</code> methods can't be monkeypatched on object level, because <code>repr()</code> and <code>str()</code> use class-methods, not locally-bounded object methods:</p>
<pre><code># Instance monkeypatch
[ins] In [55]: x.__str__ = show.__get__(x)                                                                 

[ins] In [56]: x                                                                                           
Out[56]: &lt;__main__.X at 0x7fc207180c10&gt;

[ins] In [57]: str(x)                                                                                      
Out[57]: '&lt;__main__.X object at 0x7fc207180c10&gt;'

[ins] In [58]: x.__str__()                                                                                 
Nice object!

# Class monkeypatch
[ins] In [62]: X.__str__ = lambda _: &quot;From class&quot;                                                          

[ins] In [63]: str(x)                                                                                      
Out[63]: 'From class'
</code></pre>
",1190453.0,2585.0,0
972,2982,True,"<p>In Python, there is a difference between functions and bound methods.</p>
<pre><code>&gt;&gt;&gt; def foo():
...     print &quot;foo&quot;
...
&gt;&gt;&gt; class A:
...     def bar( self ):
...         print &quot;bar&quot;
...
&gt;&gt;&gt; a = A()
&gt;&gt;&gt; foo
&lt;function foo at 0x00A98D70&gt;
&gt;&gt;&gt; a.bar
&lt;bound method A.bar of &lt;__main__.A instance at 0x00A9BC88&gt;&gt;
&gt;&gt;&gt;
</code></pre>
<p>Bound methods have been &quot;bound&quot; (how descriptive) to an instance, and that instance will be passed as the first argument whenever the method is called.</p>
<p>Callables that are attributes of a class (as opposed to an instance) are still unbound, though, so you can modify the class definition whenever you want:</p>
<pre><code>&gt;&gt;&gt; def fooFighters( self ):
...     print &quot;fooFighters&quot;
...
&gt;&gt;&gt; A.fooFighters = fooFighters
&gt;&gt;&gt; a2 = A()
&gt;&gt;&gt; a2.fooFighters
&lt;bound method A.fooFighters of &lt;__main__.A instance at 0x00A9BEB8&gt;&gt;
&gt;&gt;&gt; a2.fooFighters()
fooFighters
</code></pre>
<p>Previously defined instances are updated as well (as long as they haven't overridden the attribute themselves):</p>
<pre><code>&gt;&gt;&gt; a.fooFighters()
fooFighters
</code></pre>
<p>The problem comes when you want to attach a method to a single instance:</p>
<pre><code>&gt;&gt;&gt; def barFighters( self ):
...     print &quot;barFighters&quot;
...
&gt;&gt;&gt; a.barFighters = barFighters
&gt;&gt;&gt; a.barFighters()
Traceback (most recent call last):
  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;
TypeError: barFighters() takes exactly 1 argument (0 given)
</code></pre>
<p>The function is not automatically bound when it's attached directly to an instance:</p>
<pre><code>&gt;&gt;&gt; a.barFighters
&lt;function barFighters at 0x00A98EF0&gt;
</code></pre>
<p>To bind it, we can use the <a href=""https://docs.python.org/3/library/types.html#types.MethodType"" rel=""noreferrer"">MethodType function in the types module</a>:</p>
<pre><code>&gt;&gt;&gt; import types
&gt;&gt;&gt; a.barFighters = types.MethodType( barFighters, a )
&gt;&gt;&gt; a.barFighters
&lt;bound method ?.barFighters of &lt;__main__.A instance at 0x00A9BC88&gt;&gt;
&gt;&gt;&gt; a.barFighters()
barFighters
</code></pre>
<p>This time other instances of the class have not been affected:</p>
<pre><code>&gt;&gt;&gt; a2.barFighters()
Traceback (most recent call last):
  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;
AttributeError: A instance has no attribute 'barFighters'
</code></pre>
<p>More information can be found by reading about <a href=""https://docs.python.org/3/howto/descriptor.html"" rel=""noreferrer"">descriptors</a> and <a href=""https://web.archive.org/web/20090124004817/http://www.onlamp.com/pub/a/python/2003/04/17/metaclasses.html"" rel=""noreferrer"">metaclass</a> <a href=""http://www.gnosis.cx/publish/programming/metaclass_2.html"" rel=""noreferrer"">programming</a>.</p>
",99.0,11581.0,1010
972,982,False,"<p>In Python monkeypatching generally works by overwriting a class or function's signature with your own. Below is an example from the <a href=""http://web.archive.org/web/20130610034152/http://wiki.zope.org:80/zope2/MonkeyPatch"" rel=""nofollow noreferrer"">Zope Wiki</a>:</p>
<pre><code>from SomeOtherProduct.SomeModule import SomeClass
def speak(self):
   return &quot;ook ook eee eee eee!&quot;
SomeClass.speak = speak
</code></pre>
<p>This code will overwrite/create a method called <code>peak</code> in the class. In Jeff Atwood's <a href=""https://blog.codinghorror.com/monkeypatching-for-humans/"" rel=""nofollow noreferrer"">recent post on monkey patching</a>, he showed an example in C# 3.0 which is the current language I use for work.</p>
",200.0,12856.0,20
972,24865663,False,"<p>You can use lambda to bind a method to an instance:</p>

<pre><code>def run(self):
    print self._instanceString

class A(object):
    def __init__(self):
        self._instanceString = ""This is instance string""

a = A()
a.run = lambda: run(a)
a.run()
</code></pre>

<p>Output:</p>

<pre><code>This is instance string
</code></pre>
",3748584.0,568.0,15
972,28060251,False,"<p>Preface - a note on compatibility: other answers may only work in Python 2 - this answer should work perfectly well in Python 2 and 3. If writing Python 3 only, you might leave out explicitly inheriting from <code>object</code>, but otherwise the code should remain the same.</p>
<blockquote>
<h1>Adding a Method to an Existing Object Instance</h1>
<p>I've read that it is possible to add a method to an existing object (e.g. not in the class definition) in Python.</p>
<p>I understand that it's not always a good decision to do so. <strong>But, how might one do this?</strong></p>
</blockquote>
<h2>Yes, it is possible - But not recommended</h2>
<p>I don't recommend this. This is a bad idea. Don't do it.</p>
<p>Here's a couple of reasons:</p>
<ul>
<li>You'll add a bound object to every instance you do this to. If you do this a lot, you'll probably waste a lot of memory. Bound methods are typically only created for the short duration of their call, and they then cease to exist when automatically garbage collected. If you do this manually, you'll have a name binding referencing the bound method - which will prevent its garbage collection on usage.</li>
<li>Object instances of a given type generally have its methods on all objects of that type. If you add methods elsewhere, some instances will have those methods and others will not. Programmers will not expect this, and you risk violating the <a href=""https://en.wikipedia.org/wiki/Principle_of_least_astonishment"" rel=""noreferrer"">rule of least surprise</a>.</li>
<li>Since there are other really good reasons not to do this, you'll additionally give yourself a poor reputation if you do it.</li>
</ul>
<p>Thus, I suggest that you not do this unless you have a really good reason. <strong>It is far better to define the correct method in the class definition</strong> or <em>less</em> preferably to monkey-patch the class directly, like this:</p>
<pre><code>Foo.sample_method = sample_method
</code></pre>
<p>Since it's instructive, however, I'm going to show you some ways of doing this.</p>
<h2>How it can be done</h2>
<p>Here's some setup code. We need a class definition. It could be imported, but it really doesn't matter.</p>
<pre><code>class Foo(object):
    '''An empty class to demonstrate adding a method to an instance'''
</code></pre>
<p>Create an instance:</p>
<pre><code>foo = Foo()
</code></pre>
<p>Create a method to add to it:</p>
<pre><code>def sample_method(self, bar, baz):
    print(bar + baz)
</code></pre>
<h3>Method nought (0) - use the descriptor method, <code>__get__</code></h3>
<p>Dotted lookups on functions call the <code>__get__</code> method of the function with the instance, binding the object to the method and thus creating a &quot;bound method.&quot;</p>
<pre><code>foo.sample_method = sample_method.__get__(foo)
</code></pre>
<p>and now:</p>
<pre><code>&gt;&gt;&gt; foo.sample_method(1,2)
3
</code></pre>
<h3>Method one - types.MethodType</h3>
<p>First, import types, from which we'll get the method constructor:</p>
<pre><code>import types
</code></pre>
<p>Now we add the method to the instance. To do this, we require the MethodType constructor from the <code>types</code> module (which we imported above).</p>
<p>The argument signature for types.MethodType is <code>(function, instance, class)</code>:</p>
<pre><code>foo.sample_method = types.MethodType(sample_method, foo, Foo)
</code></pre>
<p>and usage:</p>
<pre><code>&gt;&gt;&gt; foo.sample_method(1,2)
3
</code></pre>
<h3>Method two: lexical binding</h3>
<p>First, we create a wrapper function that binds the method to the instance:</p>
<pre><code>def bind(instance, method):
    def binding_scope_fn(*args, **kwargs): 
        return method(instance, *args, **kwargs)
    return binding_scope_fn
</code></pre>
<p>usage:</p>
<pre><code>&gt;&gt;&gt; foo.sample_method = bind(foo, sample_method)    
&gt;&gt;&gt; foo.sample_method(1,2)
3
</code></pre>
<h3>Method three: functools.partial</h3>
<p>A partial function applies the first argument(s) to a function (and optionally keyword arguments), and can later be called with the remaining arguments (and overriding keyword arguments). Thus:</p>
<pre><code>&gt;&gt;&gt; from functools import partial
&gt;&gt;&gt; foo.sample_method = partial(sample_method, foo)
&gt;&gt;&gt; foo.sample_method(1,2)
3    
</code></pre>
<p>This makes sense when you consider that bound methods are partial functions of the instance.</p>
<h2>Unbound function as an object attribute - why this doesn't work:</h2>
<p>If we try to add the sample_method in the same way as we might add it to the class, it is unbound from the instance, and doesn't take the implicit self as the first argument.</p>
<pre><code>&gt;&gt;&gt; foo.sample_method = sample_method
&gt;&gt;&gt; foo.sample_method(1,2)
Traceback (most recent call last):
  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;
TypeError: sample_method() takes exactly 3 arguments (2 given)
</code></pre>
<p>We can make the unbound function work by explicitly passing the instance (or anything, since this method doesn't actually use the <code>self</code> argument variable), but it would not be consistent with the expected signature of other instances (if we're monkey-patching this instance):</p>
<pre><code>&gt;&gt;&gt; foo.sample_method(foo, 1, 2)
3
</code></pre>
<h2>Conclusion</h2>
<p>You now know several ways you <em>could</em> do this, but in all seriousness - don't do this.</p>
",541136.0,286899.0,111
972,45341362,False,"<pre><code>from types import MethodType

def method(self):
   print 'hi!'


setattr( targetObj, method.__name__, MethodType(method, targetObj, type(method)) )
</code></pre>

<p>With this, you can use the self pointer</p>
",4475534.0,93.0,2
972,43703054,False,"<p>I find it strange that nobody mentioned that all of the methods listed above creates a cycle reference between the added method and the instance, causing the object to be persistent till garbage collection. There was an old trick adding a descriptor by extending the class of the object:</p>

<pre><code>def addmethod(obj, name, func):
    klass = obj.__class__
    subclass = type(klass.__name__, (klass,), {})
    setattr(subclass, name, func)
    obj.__class__ = subclass
</code></pre>
",3781929.0,191.0,2
972,8961717,False,"<p>I think that the above answers missed the key point. </p>

<p>Let's have a class with a method:</p>

<pre><code>class A(object):
    def m(self):
        pass
</code></pre>

<p>Now, let's play with it in ipython:</p>

<pre><code>In [2]: A.m
Out[2]: &lt;unbound method A.m&gt;
</code></pre>

<p>Ok, so <em>m()</em> somehow becomes an unbound method of <em>A</em>. But is it really like that?</p>

<pre><code>In [5]: A.__dict__['m']
Out[5]: &lt;function m at 0xa66b8b4&gt;
</code></pre>

<p>It turns out that <em>m()</em> is just a function, reference to which is added to <em>A</em> class dictionary - there's no magic. Then why <em>A.m</em> gives us an unbound method? It's because the dot is not translated to a simple dictionary lookup. It's de facto a call of A.__class__.__getattribute__(A, 'm'):</p>

<pre><code>In [11]: class MetaA(type):
   ....:     def __getattribute__(self, attr_name):
   ....:         print str(self), '-', attr_name

In [12]: class A(object):
   ....:     __metaclass__ = MetaA

In [23]: A.m
&lt;class '__main__.A'&gt; - m
&lt;class '__main__.A'&gt; - m
</code></pre>

<p>Now, I'm not sure out of the top of my head why the last line is printed twice, but still it's clear what's going on there.</p>

<p>Now, what the default __getattribute__ does is that it checks if the attribute is a so-called <a href=""http://docs.python.org/reference/datamodel.html#implementing-descriptors"" rel=""noreferrer"">descriptor</a> or not, i.e. if it implements a special __get__ method. If it implements that method, then what is returned is the result of calling that __get__ method. Going back to the first version of our <em>A</em> class, this is what we have:</p>

<pre><code>In [28]: A.__dict__['m'].__get__(None, A)
Out[28]: &lt;unbound method A.m&gt;
</code></pre>

<p>And because Python functions implement the descriptor protocol, if they are called on behalf of an object, they bind themselves to that object in their __get__ method.</p>

<p>Ok, so how to add a method to an existing object? Assuming you don't mind patching class, it's as simple as:</p>

<pre><code>B.m = m
</code></pre>

<p>Then <em>B.m</em> ""becomes"" an unbound method, thanks to the descriptor magic.</p>

<p>And if you want to add a method just to a single object, then you have to emulate the machinery yourself, by using types.MethodType:</p>

<pre><code>b.m = types.MethodType(m, b)
</code></pre>

<p>By the way:</p>

<pre><code>In [2]: A.m
Out[2]: &lt;unbound method A.m&gt;

In [59]: type(A.m)
Out[59]: &lt;type 'instancemethod'&gt;

In [60]: type(b.m)
Out[60]: &lt;type 'instancemethod'&gt;

In [61]: types.MethodType
Out[61]: &lt;type 'instancemethod'&gt;
</code></pre>
",176186.0,15252.0,39
972,34404761,False,"<p>This question was opened years ago, but hey, there's an easy way to simulate the binding of a function to a class instance using decorators:</p>

<pre><code>def binder (function, instance):
  copy_of_function = type (function) (function.func_code, {})
  copy_of_function.__bind_to__ = instance
  def bound_function (*args, **kwargs):
    return copy_of_function (copy_of_function.__bind_to__, *args, **kwargs)
  return bound_function


class SupaClass (object):
  def __init__ (self):
    self.supaAttribute = 42


def new_method (self):
  print self.supaAttribute


supaInstance = SupaClass ()
supaInstance.supMethod = binder (new_method, supaInstance)

otherInstance = SupaClass ()
otherInstance.supaAttribute = 72
otherInstance.supMethod = binder (new_method, otherInstance)

otherInstance.supMethod ()
supaInstance.supMethod ()
</code></pre>

<p>There, when you pass the function and the instance to the binder decorator, it will create a new function, with the same code object as the first one. Then, the given instance of the class is stored in an attribute of the newly created function. The decorator return a (third) function calling automatically the copied function, giving the instance as the first parameter.
  <br/>
  <br/>
In conclusion you get a function simulating it's binding to the class instance. Letting the original function unchanged.</p>
",4548106.0,390.0,3
972,32076685,False,"<h1>This is actually an addon to the answer of &quot;Jason Pratt&quot;</h1>
<p>Although Jasons answer works, it does only work if one wants to add a function to a class.
It did not work for me when I tried to reload an already existing method from the .py source code file.</p>
<p>It took me for ages to find a workaround, but the trick seems simple...
1.st import the code from the source code file
2.nd force a reload
3.rd use types.FunctionType(...) to convert the imported and bound method to a function
you can also pass on the current global variables, as the reloaded method would be in a different namespace
4.th now you can continue as suggested by &quot;Jason Pratt&quot;
using the types.MethodType(...)</p>
<p>Example:</p>
<pre><code># this class resides inside ReloadCodeDemo.py
class A:
    def bar( self ):
        print &quot;bar1&quot;
        
    def reloadCode(self, methodName):
        ''' use this function to reload any function of class A'''
        import types
        import ReloadCodeDemo as ReloadMod # import the code as module
        reload (ReloadMod) # force a reload of the module
        myM = getattr(ReloadMod.A,methodName) #get reloaded Method
        myTempFunc = types.FunctionType(# convert the method to a simple function
                                myM.im_func.func_code, #the methods code
                                globals(), # globals to use
                                argdefs=myM.im_func.func_defaults # default values for variables if any
                                ) 
        myNewM = types.MethodType(myTempFunc,self,self.__class__) #convert the function to a method
        setattr(self,methodName,myNewM) # add the method to the function

if __name__ == '__main__':
    a = A()
    a.bar()
    # now change your code and save the file
    a.reloadCode('bar') # reloads the file
    a.bar() # now executes the reloaded code
</code></pre>
",5010481.0,280.0,5
972,24748849,False,"<p>If it can be of any help, I recently released a Python library named Gorilla to make the process of monkey patching more convenient.</p>

<p>Using a function <code>needle()</code> to patch a module named <code>guineapig</code> goes as follows:</p>

<pre><code>import gorilla
import guineapig
@gorilla.patch(guineapig)
def needle():
    print(""awesome"")
</code></pre>

<p>But it also takes care of more interesting use cases as shown in the <a href=""http://gorilla.readthedocs.org/en/latest/faq.html"" rel=""nofollow"">FAQ</a> from the <a href=""http://gorilla.readthedocs.org/"" rel=""nofollow"">documentation</a>.</p>

<p>The code is available on <a href=""https://github.com/christophercrouzet/gorilla"" rel=""nofollow"">GitHub</a>.</p>
",1640404.0,1477.0,3
972,16240409,False,"<p>There are at least two ways for attach a method to an instance without <code>types.MethodType</code>:</p>

<pre><code>&gt;&gt;&gt; class A:
...  def m(self):
...   print 'im m, invoked with: ', self

&gt;&gt;&gt; a = A()
&gt;&gt;&gt; a.m()
im m, invoked with:  &lt;__main__.A instance at 0x973ec6c&gt;
&gt;&gt;&gt; a.m
&lt;bound method A.m of &lt;__main__.A instance at 0x973ec6c&gt;&gt;
&gt;&gt;&gt; 
&gt;&gt;&gt; def foo(firstargument):
...  print 'im foo, invoked with: ', firstargument

&gt;&gt;&gt; foo
&lt;function foo at 0x978548c&gt;
</code></pre>

<p>1:</p>

<pre><code>&gt;&gt;&gt; a.foo = foo.__get__(a, A) # or foo.__get__(a, type(a))
&gt;&gt;&gt; a.foo()
im foo, invoked with:  &lt;__main__.A instance at 0x973ec6c&gt;
&gt;&gt;&gt; a.foo
&lt;bound method A.foo of &lt;__main__.A instance at 0x973ec6c&gt;&gt;
</code></pre>

<p>2:</p>

<pre><code>&gt;&gt;&gt; instancemethod = type(A.m)
&gt;&gt;&gt; instancemethod
&lt;type 'instancemethod'&gt;
&gt;&gt;&gt; a.foo2 = instancemethod(foo, a, type(a))
&gt;&gt;&gt; a.foo2()
im foo, invoked with:  &lt;__main__.A instance at 0x973ec6c&gt;
&gt;&gt;&gt; a.foo2
&lt;bound method instance.foo of &lt;__main__.A instance at 0x973ec6c&gt;&gt;
</code></pre>

<p>Useful links:<br>
<a href=""http://docs.python.org/2/reference/datamodel.html#invoking-descriptors"" rel=""noreferrer"">Data model - invoking descriptors</a><br>
<a href=""http://docs.python.org/2.7/howto/descriptor.html#invoking-descriptors"" rel=""noreferrer"">Descriptor HowTo Guide - invoking descriptors</a></p>
",1099876.0,19590.0,9
972,959064,False,"<p>Module <strong>new</strong> is deprecated since python 2.6 and removed in 3.0, use <strong>types</strong></p>

<p>see <a href=""http://docs.python.org/library/new.html"" rel=""noreferrer"">http://docs.python.org/library/new.html</a></p>

<p>In the example below I've deliberately removed return value from <code>patch_me()</code> function.
I think that giving return value may make one believe that patch returns a new object, which is not true - it modifies the incoming one. Probably this can facilitate a more disciplined use of monkeypatching.</p>

<pre><code>import types

class A(object):#but seems to work for old style objects too
    pass

def patch_me(target):
    def method(target,x):
        print ""x="",x
        print ""called from"", target
    target.method = types.MethodType(method,target)
    #add more if needed

a = A()
print a
#out: &lt;__main__.A object at 0x2b73ac88bfd0&gt;  
patch_me(a)    #patch instance
a.method(5)
#out: x= 5
#out: called from &lt;__main__.A object at 0x2b73ac88bfd0&gt;
patch_me(A)
A.method(6)        #can patch class too
#out: x= 6
#out: called from &lt;class '__main__.A'&gt;
</code></pre>
",110274.0,10146.0,101
972,9636303,False,"<p>Since this question asked for non-Python versions, here's JavaScript:</p>

<pre><code>a.methodname = function () { console.log(""Yay, a new method!"") }
</code></pre>
",650551.0,2581.0,6
972,9041763,False,"<p>Consolidating Jason Pratt's and the community wiki answers, with a look at the results of different methods of binding:</p>

<p>Especially note how adding the binding function as a class method <em>works</em>, but the referencing scope is incorrect.</p>

<pre><code>#!/usr/bin/python -u
import types
import inspect

## dynamically adding methods to a unique instance of a class


# get a list of a class's method type attributes
def listattr(c):
    for m in [(n, v) for n, v in inspect.getmembers(c, inspect.ismethod) if isinstance(v,types.MethodType)]:
        print m[0], m[1]

# externally bind a function as a method of an instance of a class
def ADDMETHOD(c, method, name):
    c.__dict__[name] = types.MethodType(method, c)

class C():
    r = 10 # class attribute variable to test bound scope

    def __init__(self):
        pass

    #internally bind a function as a method of self's class -- note that this one has issues!
    def addmethod(self, method, name):
        self.__dict__[name] = types.MethodType( method, self.__class__ )

    # predfined function to compare with
    def f0(self, x):
        print 'f0\tx = %d\tr = %d' % ( x, self.r)

a = C() # created before modified instnace
b = C() # modified instnace


def f1(self, x): # bind internally
    print 'f1\tx = %d\tr = %d' % ( x, self.r )
def f2( self, x): # add to class instance's .__dict__ as method type
    print 'f2\tx = %d\tr = %d' % ( x, self.r )
def f3( self, x): # assign to class as method type
    print 'f3\tx = %d\tr = %d' % ( x, self.r )
def f4( self, x): # add to class instance's .__dict__ using a general function
    print 'f4\tx = %d\tr = %d' % ( x, self.r )


b.addmethod(f1, 'f1')
b.__dict__['f2'] = types.MethodType( f2, b)
b.f3 = types.MethodType( f3, b)
ADDMETHOD(b, f4, 'f4')


b.f0(0) # OUT: f0   x = 0   r = 10
b.f1(1) # OUT: f1   x = 1   r = 10
b.f2(2) # OUT: f2   x = 2   r = 10
b.f3(3) # OUT: f3   x = 3   r = 10
b.f4(4) # OUT: f4   x = 4   r = 10


k = 2
print 'changing b.r from {0} to {1}'.format(b.r, k)
b.r = k
print 'new b.r = {0}'.format(b.r)

b.f0(0) # OUT: f0   x = 0   r = 2
b.f1(1) # OUT: f1   x = 1   r = 10  !!!!!!!!!
b.f2(2) # OUT: f2   x = 2   r = 2
b.f3(3) # OUT: f3   x = 3   r = 2
b.f4(4) # OUT: f4   x = 4   r = 2

c = C() # created after modifying instance

# let's have a look at each instance's method type attributes
print '\nattributes of a:'
listattr(a)
# OUT:
# attributes of a:
# __init__ &lt;bound method C.__init__ of &lt;__main__.C instance at 0x000000000230FD88&gt;&gt;
# addmethod &lt;bound method C.addmethod of &lt;__main__.C instance at 0x000000000230FD88&gt;&gt;
# f0 &lt;bound method C.f0 of &lt;__main__.C instance at 0x000000000230FD88&gt;&gt;

print '\nattributes of b:'
listattr(b)
# OUT:
# attributes of b:
# __init__ &lt;bound method C.__init__ of &lt;__main__.C instance at 0x000000000230FE08&gt;&gt;
# addmethod &lt;bound method C.addmethod of &lt;__main__.C instance at 0x000000000230FE08&gt;&gt;
# f0 &lt;bound method C.f0 of &lt;__main__.C instance at 0x000000000230FE08&gt;&gt;
# f1 &lt;bound method ?.f1 of &lt;class __main__.C at 0x000000000237AB28&gt;&gt;
# f2 &lt;bound method ?.f2 of &lt;__main__.C instance at 0x000000000230FE08&gt;&gt;
# f3 &lt;bound method ?.f3 of &lt;__main__.C instance at 0x000000000230FE08&gt;&gt;
# f4 &lt;bound method ?.f4 of &lt;__main__.C instance at 0x000000000230FE08&gt;&gt;

print '\nattributes of c:'
listattr(c)
# OUT:
# attributes of c:
# __init__ &lt;bound method C.__init__ of &lt;__main__.C instance at 0x0000000002313108&gt;&gt;
# addmethod &lt;bound method C.addmethod of &lt;__main__.C instance at 0x0000000002313108&gt;&gt;
# f0 &lt;bound method C.f0 of &lt;__main__.C instance at 0x0000000002313108&gt;&gt;
</code></pre>

<p>Personally, I prefer the external ADDMETHOD function route, as it allows me to dynamically assign new method names within an iterator as well.</p>

<pre><code>def y(self, x):
    pass
d = C()
for i in range(1,5):
    ADDMETHOD(d, y, 'f%d' % i)
print '\nattributes of d:'
listattr(d)
# OUT:
# attributes of d:
# __init__ &lt;bound method C.__init__ of &lt;__main__.C instance at 0x0000000002303508&gt;&gt;
# addmethod &lt;bound method C.addmethod of &lt;__main__.C instance at 0x0000000002303508&gt;&gt;
# f0 &lt;bound method C.f0 of &lt;__main__.C instance at 0x0000000002303508&gt;&gt;
# f1 &lt;bound method ?.y of &lt;__main__.C instance at 0x0000000002303508&gt;&gt;
# f2 &lt;bound method ?.y of &lt;__main__.C instance at 0x0000000002303508&gt;&gt;
# f3 &lt;bound method ?.y of &lt;__main__.C instance at 0x0000000002303508&gt;&gt;
# f4 &lt;bound method ?.y of &lt;__main__.C instance at 0x0000000002303508&gt;&gt;
</code></pre>
",841337.0,5334.0,5
972,22525,False,"<p>What Jason Pratt posted is correct.</p>

<pre><code>&gt;&gt;&gt; class Test(object):
...   def a(self):
...     pass
... 
&gt;&gt;&gt; def b(self):
...   pass
... 
&gt;&gt;&gt; Test.b = b
&gt;&gt;&gt; type(b)
&lt;type 'function'&gt;
&gt;&gt;&gt; type(Test.a)
&lt;type 'instancemethod'&gt;
&gt;&gt;&gt; type(Test.b)
&lt;type 'instancemethod'&gt;
</code></pre>

<p>As you can see, Python doesn't consider b() any different than a(). In Python all methods are just variables that happen to be functions. </p>
",2482.0,1206.0,2
972,4600,False,"<p>What you're looking for is <code>setattr</code> I believe.
Use this to set an attribute on an object.</p>

<pre><code>&gt;&gt;&gt; def printme(s): print repr(s)
&gt;&gt;&gt; class A: pass
&gt;&gt;&gt; setattr(A,'printme',printme)
&gt;&gt;&gt; a = A()
&gt;&gt;&gt; a.printme() # s becomes the implicit 'self' variable
&lt; __ main __ . A instance at 0xABCDEFG&gt;
</code></pre>
",618.0,13914.0,8
1005,37042,True,"<p><code>%</code> is replaced with the current file name, thus you can use:</p>

<pre><code>:w !sudo tee %
</code></pre>

<p>(<code>vim</code> will detect that the file has been changed and ask whether you want to it to be reloaded. Say yes by choosing <code>[L]</code> rather than OK.)</p>

<p>As a shortcut, you can define your own command. Put the following in your <code>.vimrc</code>:</p>

<pre><code>command W w !sudo tee % &gt;/dev/null
</code></pre>

<p>With the above you can type <code>:W&lt;Enter&gt;</code> to save the file. Since I wrote this, I have found a nicer way (in my opinion) to do this:</p>

<pre><code>cmap w!! w !sudo tee &gt;/dev/null %
</code></pre>

<p>This way you can type <code>:w!!</code> and it will be expanded to the full command line, leaving the cursor at the end, so you can replace the <code>%</code> with a file name of your own, if you like.</p>
",,,303
1005,125383,False,"<p>If you're using <a href=""http://www.vim.org/"" rel=""nofollow noreferrer"">Vim</a>, there is a script available named <a href=""http://www.vim.org/scripts/script.php?script_id=729"" rel=""nofollow noreferrer"">sudo.vim</a>.  If you find that you've opened a file that you need root access to read, type<pre>:e sudo:%</pre>Vim replaces the % with the name of the current file, and <code>sudo:</code> instructs the sudo.vim script to take over for reading and writing.</p>
",20713.0,179940.0,11
1005,12870763,False,"<h1>Common Caveats</h1>

<p>The most common method of getting around the read-only file problem is to open a pipe to current file as the super-user using an implementation of <code>sudo tee</code>.  However, all of the most popular solutions that I have found around the Internet have a combination of a several potential caveats:</p>

<ul>
<li>The entire file gets written to the terminal, as well as the file.  This can be slow for large files, especially over slow network connections.</li>
<li>The file loses its modes and similar attributes.</li>
<li>File paths with unusual characters or spaces might not be handled correctly.</li>
</ul>

<h1>Solutions</h1>

<p>To get around all of these issues, you can use the following command:</p>

<pre><code>"" On POSIX (Linux/Mac/BSD):
:silent execute 'write !sudo tee ' . shellescape(@%, 1) . ' &gt;/dev/null'

"" Depending on the implementation, you might need this on Windows:
:silent execute 'write !sudo tee ' . shellescape(@%, 1) . ' &gt;NUL'
</code></pre>

<p>These can be shortened, respectfully:</p>

<pre><code>:sil exec 'w !sudo tee ' . shellescape(@%, 1) . ' &gt;/dev/null'
:sil exec 'w !sudo tee ' . shellescape(@%, 1) . ' &gt;NUL'
</code></pre>

<h1>Explanation</h1>

<p><code>:</code> begins the command; you will need to type this character in normal mode to start entering a command.  It should be omitted in scripts.</p>

<p><code>sil[ent]</code> suppresses output from the command.  In this case, we want to stop the <code>Press any key to continue</code>-like prompt that appears after running the <code>:!</code> command.</p>

<p><code>exec[ute]</code> executes a string as a command.  We can't just run <code>:write</code> because it won't process the necessary function call.</p>

<p><code>!</code> represents the <code>:!</code> command: the only command that <code>:write</code> accepts.  Normally, <code>:write</code> accepts a file path to which to write.  <code>:!</code> on its own runs a command in a shell (for example, using <code>bash -c</code>).  With <code>:write</code>, it will run the command in the shell, and then write the entire file to <code>stdin</code>.</p>

<p><code>sudo</code> should be obvious, since that's why you're here.  Run the command as the super-user.  There's plenty of information around the 'net about how that works.</p>

<p><code>tee</code> pipes <code>stdin</code> to the given file.  <code>:write</code> will write to <code>stdin</code>, then the super-user <code>tee</code> will receive the file contents and write the file.  It won't create a new file--just overwrite the contents--so file modes and attributes will be preserved.</p>

<p><code>shellescape()</code> escapes special characters in the given file path as appropriate for the current shell.  With just one parameter, it would typically just enclose the path in quotes as necessary.  Since we're sending to a full shell command line, we'll want to pass a non-zero value as the second argument to enable backslash-escaping of other special characters that might otherwise trip up the shell.</p>

<p><code>@%</code> reads the contents of the <code>%</code> register, which contains the current buffer's file name.  It's not necessarily an absolute path, so ensure that you haven't changed the current directory.  In some solutions, you will see the commercial-at symbol omitted.  Depending on the location, <code>%</code> is a valid expression, and has the same effect as reading the <code>%</code> register.  Nested inside another expression the shortcut is generally disallowed, however: such as in this case.</p>

<p><code>&gt;NUL</code> and <code>&gt;/dev/null</code> redirect <code>stdout</code> to the platform's null device.  Even though we've silenced the command, we don't want all of the overhead associated with piping <code>stdin</code> back to vim--best to dump it as early as possible.  <code>NUL</code> is the null device on DOS, MS-DOS, and Windows, not a valid file.  As of Windows 8 redirections to NUL don't result in a file named NUL being written.  Try creating a file on your desktop named NUL, with or without a file extension: you will be unable to do so.  (There are several other device names in Windows that might be worth getting to know.)</p>

<h1>~/.vimrc</h1>

<h2>Platform-Dependent</h2>

<p>Of course, you still don't want to memorize those and type them out each time.  It's much easier to map the appropriate command to a simpler user command.  To do this on POSIX, you could add the following line to your <code>~/.vimrc</code> file, creating it if it doesn't already exist:</p>

<pre><code>command W silent execute 'write !sudo tee ' . shellescape(@%, 1) . ' &gt;/dev/null'
</code></pre>

<p>This will allow you to type the :W (case-sensitive) command to write the current file with super-user permissions--much easier.</p>

<h2>Platform-Independent</h2>

<p>I use a platform-independent <code>~/.vimrc</code> file that synchronizes across computers, so I added multi-platform functionality to mine.  Here's a <code>~/.vimrc</code> with only the relevant settings:</p>

<pre><code>#!vim
"" Use za (not a command; the keys) in normal mode to toggle a fold.
"" META_COMMENT Modeline Definition: {{{1
"" vim: ts=4 sw=4 sr sts=4 fdm=marker ff=unix fenc=utf-8
""   ts:     Actual tab character stops.
""   sw:     Indentation commands shift by this much.
""   sr:     Round existing indentation when using shift commands.
""   sts:    Virtual tab stops while using tab key.
""   fdm:    Folds are manually defined in file syntax.
""   ff:     Line endings should always be &lt;NL&gt; (line feed #09).
""   fenc:   Should always be UTF-8; #! must be first bytes, so no BOM.


"" General Commands: User Ex commands. {{{1
    command W call WriteAsSuperUser(@%)         "" Write file as super-user.


"" Helper Functions: Used by user Ex commands. {{{1
    function GetNullDevice() "" Gets the path to the null device. {{{2
        if filewritable('/dev/null')
            return '/dev/null'
        else
            return 'NUL'
        endif
    endfunction

    function WriteAsSuperUser(file) "" Write buffer to a:file as the super user (on POSIX, root). {{{2
        exec '%write !sudo tee ' . shellescape(a:file, 1) . ' &gt;' . GetNullDevice()
    endfunction


"" }}}1
"" EOF
</code></pre>
",1188377.0,16193.0,19
1005,2163726,False,"<p>Here's another one that has appeared since this question was answered, a plugin called SudoEdit which provides SudoRead and SudoWrite functions, which will by default try to use sudo first and su if that fails: <a href=""http://www.vim.org/scripts/script.php?script_id=2709"" rel=""nofollow noreferrer"">http://www.vim.org/scripts/script.php?script_id=2709</a></p>
",105950.0,3792.0,1
1005,662081,False,"<p>I have this in my ~/.bashrc:</p>

<pre><code>alias svim='sudo vim'
</code></pre>

<p>Now whenever I need to edit a config file I just open it with svim.</p>
",78414.0,1481.0,0
1005,9113,False,"<p>When you go into insert mode on a file you need sudo access to edit, you get a status message saying</p>

<pre><code>-- INSERT -- W10: Warning: Changing a readonly file
</code></pre>

<p>If I miss that, generally I do</p>

<pre><code>:w ~/edited_blah.tmp
:q
</code></pre>

<p>..then..</p>

<pre><code>sudo ""cat edited_blah.tmp &gt; /etc/blah""
</code></pre>

<p>..or..</p>

<pre><code>sudo mv edited_blah.tmp /etc/blah
</code></pre>

<p>There's probably a less roundabout way to do it, but it works.</p>
",745.0,152698.0,3
1005,2930,False,"<p>A quick hack you can consider is doing a chmod on the file you're editing, save with vim, and then chmod back to what the file was originally.</p>

<pre><code>ls -l test.file (to see the permissions of the file)
chmod 777 test.file
[This is where you save in vim]
chmod xxx test.file (restore the permissions you found in the first step)
</code></pre>

<p>Of course I don't recommend this approach in a system where you're worried about security, as for a few seconds anyone can read/change the file without you realizing.</p>
",306.0,4488.0,-2
1005,1065,False,"<p>In general, you can't change the effective user id of the vi process, but you can do this:</p>

<pre><code>:w !sudo tee myfile
</code></pre>
",116.0,265948.0,33
1005,1012,False,"<p>Ryan's advice is generally good, however, if following step 3, don't move the temporary file; it'll have the wrong ownership and permissions. Instead, <code>sudoedit</code> the correct file and read in the contents (using <code>:r</code> or the like) of the temporary file.</p>

<p>If following step 2, use <code>:w!</code> to force the file to be written.</p>
",13.0,205366.0,7
1005,1006,False,"<p>A quick Google seems to give this advice:</p>

<ol>
<li>Don't try to edit if it's read-only.</li>
<li>You might be able to change the permissions on the file. (Whether or not it will let you save is up to experimentation.)</li>
<li>If you still edited anyway, save to a temporary file and then move it.</li>
</ol>

<p><a href=""http://ubuntuforums.org/showthread.php?t=782136"" rel=""nofollow noreferrer"">http://ubuntuforums.org/showthread.php?t=782136</a></p>
",55.0,9396.0,1
1010,2058,False,"<p>I enabled compression following similar articles to those posted above. The key to accessing the ViewState before the application sends it was overriding this method;</p>

<pre><code>protected override void SavePageStateToPersistenceMedium(object viewState)
</code></pre>

<p>You can call the base method within this override and then add whatever additional logic you require to handle the ViewState.</p>
",371.0,10903.0,2
1010,1093,False,"<p>See this <a href=""http://aspguy.wordpress.com/2008/07/09/reducing-the-page-size-by-storing-viewstate-on-server/"" rel=""nofollow noreferrer"">blog post</a> where the author describes a method for overriding the default behavior for generating the ViewState and instead shows how to save it on the server Session object.</p>

<blockquote>
  <p>In ASP.NET 2.0, ViewState is saved by
  a descendant of PageStatePersister
  class. This class is an abstract class
  for saving and loading ViewsState and
  there are two implemented descendants
  of this class in .Net Framework, named
  HiddenFieldPageStatePersister and
  SessionPageStatePersister. By default
  HiddenFieldPageStatePersister is used
  to save/load ViewState information,
  but we can easily get the
  SessionPageStatePersister to work and
  save ViewState in Session object.</p>
</blockquote>

<p>Although I did not test his code, it seems to show exactly what you want: a way to gain access to ViewState code while still on the server, before postback. </p>
",51.0,37890.0,4
1010,1074,True,"<p>Rex, I suspect a good place to start looking is solutions that <strong>compress the ViewState</strong> -- they're grabbing ViewState on the server before it's sent down to the client and gzipping it. That's exactly where you want to be.</p>

<ul>
<li><a href=""http://www.hanselman.com/blog/CommentView,guid,febce059-7e7c-439e-af3d-c53d250b3e9c.aspx"" rel=""noreferrer"">Scott Hanselman on ViewState Compression</a> (2005)</li>
<li><a href=""http://www.bloggingdeveloper.com/post/How-To-Compress-ViewState-in-ASPNET-20-ViewState-Compression-with-SystemIOCompression.aspx"" rel=""noreferrer"">ViewState Compression with System.IO.Compression</a> (2007)</li>
</ul>
",1.0,60757.0,12
1024,1026,False,"<p>This was caused by a change in rails 2.1 which prevents rails from loading views from any arbitrary path for security reasons.</p>

<p>There is now an updated version of the plugin on github, so the solution is to use that.</p>

<hr>

<p>The old solution here for posterity</p>

<p>To work around it, edit <code>init.rb</code> under your <code>vendor/plugins/exception_notification</code> directory, and add the following code to the end</p>

<pre><code>ActionController::Base.class_eval do
  append_view_path File.dirname(__FILE__) + '/lib/../views'
end
</code></pre>

<p>This adds the ExceptionNotifier plugins' views folder to the list, so it is allowed to load them.</p>
",234.0,113281.0,8
1024,171170,True,"<p>You ought to upgrade to the newest Exception Notification plugin which is in <a href=""http://github.com/rails/exception_notification/tree/master"" rel=""nofollow noreferrer"">its new home at GitHub</a>.</p>
",6304.0,3954.0,0
1033,65161079,False,"<p>You can give a try to <a href=""https://astroip.co"" rel=""nofollow noreferrer"">https://astroip.co</a>, it is a new Geolocation API I built which exposes geo data together with other useful datapoints like currency, timezone, ASN data and security.</p>
<p>Here it is an example of the json response:</p>
<pre><code>curl https://api.astroip.co/70.163.7.1
{
  &quot;status_code&quot;: 200,
  &quot;geo&quot;: {
    &quot;is_metric&quot;: false,
    &quot;is_eu&quot;: false,
    &quot;longitude&quot;: -77.0924,
    &quot;latitude&quot;: 38.7591,
    &quot;country_geo_id&quot;: 6252001,
    &quot;zip_code&quot;: &quot;22306&quot;,
    &quot;city&quot;: &quot;Alexandria&quot;,
    &quot;region_code&quot;: &quot;VA&quot;,
    &quot;region_name&quot;: &quot;Virginia&quot;,
    &quot;continent_code&quot;: &quot;NA&quot;,
    &quot;continent_name&quot;: &quot;North America&quot;,
    &quot;capital&quot;: &quot;Washington&quot;,
    &quot;country_name&quot;: &quot;United States&quot;,
    &quot;country_code&quot;: &quot;US&quot;
  },
  &quot;asn&quot;: {
    &quot;route&quot;: &quot;70.160.0.0/14&quot;,
    &quot;type&quot;: &quot;isp&quot;,
    &quot;domain&quot;: &quot;cox.net&quot;,
    &quot;organization&quot;: &quot;ASN-CXA-ALL-CCI-22773-RDC&quot;,
    &quot;asn&quot;: &quot;AS22773&quot;
  },
  &quot;currency&quot;: {
    &quot;native_name&quot;: &quot;US Dollar&quot;,
    &quot;code&quot;: &quot;USD&quot;,
    &quot;name&quot;: &quot;US Dollar&quot;,
    &quot;symbol&quot;: &quot;$&quot;
  },
  &quot;timezone&quot;: {
    &quot;is_dst&quot;: false,
    &quot;gmt_offset&quot;: -18000,
    &quot;date_time&quot;: &quot;2020-12-05T17:04:48-05:00&quot;,
    &quot;microsoft_name&quot;: &quot;Eastern Standard Time&quot;,
    &quot;iana_name&quot;: &quot;America/New_York&quot;
  },
  &quot;security&quot;: {
    &quot;is_crawler&quot;: false,
    &quot;is_proxy&quot;: false,
    &quot;is_tor&quot;: false,
    &quot;tor_insights&quot;: null,
    &quot;proxy_insights&quot;: null,
    &quot;crawler_insights&quot;: null
  },
  &quot;error&quot;: null,
  &quot;ip_type&quot;: &quot;ipv4&quot;,
  &quot;ip&quot;: &quot;70.163.7.1&quot;
}
</code></pre>
",1378258.0,491.0,-1
1033,48855469,False,"<p>See <a href=""https://ipdata.co"" rel=""nofollow noreferrer"">ipdata.co</a> which gives you several data points from an IP address.</p>
<p>The API is pretty fast, with 10 global endpoints each being able to handle &gt;800M calls daily.</p>
<p>Here's a curl example:</p>
<pre><code>curl https://api.ipdata.co/78.8.53.5
{
    &quot;ip&quot;: &quot;78.8.53.5&quot;,
    &quot;city&quot;: &quot;G\u0142og\u00f3w&quot;,
    &quot;region&quot;: &quot;Lower Silesia&quot;,
    &quot;region_code&quot;: &quot;DS&quot;,
    &quot;country_name&quot;: &quot;Poland&quot;,
    &quot;country_code&quot;: &quot;PL&quot;,
    &quot;continent_name&quot;: &quot;Europe&quot;,
    &quot;continent_code&quot;: &quot;EU&quot;,
    &quot;latitude&quot;: 51.6461,
    &quot;longitude&quot;: 16.1678,
    &quot;asn&quot;: &quot;AS12741&quot;,
    &quot;organisation&quot;: &quot;Netia SA&quot;,
    &quot;postal&quot;: &quot;67-200&quot;,
    &quot;currency&quot;: &quot;PLN&quot;,
    &quot;currency_symbol&quot;: &quot;z\u0142&quot;,
    &quot;calling_code&quot;: &quot;48&quot;,
    &quot;flag&quot;: &quot;https://ipdata.co/flags/pl.png&quot;,
    &quot;emoji_flag&quot;: &quot;\ud83c\uddf5\ud83c\uddf1&quot;,
    &quot;time_zone&quot;: &quot;Europe/Warsaw&quot;,
    &quot;is_eu&quot;: true,
    &quot;suspicious_factors&quot;: {
        &quot;is_tor&quot;: false
    }
}⏎  
</code></pre>
",3176550.0,8438.0,1
1033,142851,False,"<p>The most accurate is <a href=""http://www.digital-element.net"" rel=""nofollow noreferrer"">Digital Elements</a> NetAcuity. It's not free but you get what you pay for most of the time.</p>
",11907.0,7040.0,3
1033,1257,False,"<p>I don't know how accurate <a href=""http://hostip.info"" rel=""nofollow noreferrer"">http://hostip.info</a> site is. I just visited that site, and it reported that my country is Canada.  I'm in the US and the ISP that my office uses only operates from the US.  It does allow you to correct its guess, but if you are using this service to track web site visitors by country, you'll have no way of knowing if the data is correct.  Of course, I'm just one data point. I downloaded the GeoLite Country database, which is just a .csv file, and my IP address was correctly identified as US.</p>
<p>Another benefit of the MaxMind product line (paid or free) is that you have the data, you don't incur the performance hit of making a web service call to another system.</p>
",206.0,4489.0,6
1033,49001745,False,"<p>You can try the free <a href=""https://lite.ip2location.com/database/ip-country"" rel=""nofollow noreferrer"">IP2Location LITE database</a></p>

<p>To create the table in MySQL</p>

<pre><code>CREATE DATABASE ip2location;
USE ip2location;
CREATE TABLE `ip2location_db1`(
    `ip_from` INT(10) UNSIGNED,
    `ip_to` INT(10) UNSIGNED,
    `country_code` CHAR(2),
    `country_name` VARCHAR(64),
    INDEX `idx_ip_to` (`ip_to`)
) ENGINE=MyISAM DEFAULT CHARSET=utf8 COLLATE=utf8_bin;
</code></pre>

<p>To import the data</p>

<pre><code>LOAD DATA LOCAL
    INFILE 'IP2LOCATION-LITE-DB1.CSV'
INTO TABLE
    `ip2location_db1`
FIELDS TERMINATED BY ','
ENCLOSED BY '""'
LINES TERMINATED BY '\r\n'
IGNORE 0 LINES;
</code></pre>

<p>PHP code to query the MySQL</p>

<pre><code>&lt;?php
// Replace this MYSQL server variables with actual configuration
$mysql_server = ""mysql_server.com"";
$mysql_user_name = ""UserName"";
$mysql_user_pass = ""Password"";

// Retrieve visitor IP address from server variable REMOTE_ADDR
$ipaddress = $_SERVER[""REMOTE_ADDR""];

// Convert IP address to IP number for querying database
$ipno = Dot2LongIP($ipaddress);

// Connect to the database server
$link = mysql_connect($mysql_server, $mysql_user_name, $mysql_user_pass) or die(""Could not connect to MySQL database"");

// Connect to the IP2Location database
mysql_select_db(""ip2location"") or die(""Could not select database"");

// SQL query string to match the recordset that the IP number fall between the valid range
$query = ""SELECT * FROM ip2location_db1 WHERE $ipno &lt;= ip_to LIMIT 1"";

// Execute SQL query
$result = mysql_query($query) or die(""IP2Location Query Failed"");

// Retrieve the recordset (only one)
$row = mysql_fetch_object($result);

// Keep the country information into two different variables
$country_code = $row-&gt;country_code;
$country_name = $row-&gt;country_name;

echo ""Country_code: "" . $country_code . ""&lt;br/&gt;"";
echo ""Country_name: "" . $country_name . ""&lt;br /&gt;"";

// Free recordset and close database connection
mysql_free_result($result);
mysql_close($link);

// Function to convert IP address (xxx.xxx.xxx.xxx) to IP number (0 to 256^4-1)
function Dot2LongIP ($IPaddr) {
 if ($IPaddr == """")
 {
   return 0;
 } else {
   $ips = explode(""."", $IPaddr);
   return ($ips[3] + $ips[2] * 256 + $ips[1] * 256 * 256 + $ips[0] * 256 * 256 * 256);
 }
}
?&gt;
</code></pre>
",6647585.0,1281.0,1
1033,1056,True,"<p>A lot of people (including my company) seem to use MaxMind GeoIP.</p>

<p>They have a free version <a href=""http://dev.maxmind.com/geoip/geoip2/geolite2/"" rel=""noreferrer"">GeoLite</a> which is not as accurate as the paid version, but if you're just after something simple, it may be good enough.</p>
",234.0,113281.0,38
1033,25498255,False,"<p>You can use my service, <a href=""http://ipinfo.io"" rel=""nofollow"">http://ipinfo.io</a>, for this. The API returns a whole bunch of different details about an IP address:</p>

<pre><code>$ curl ipinfo.io/8.8.8.8
{
  ""ip"": ""8.8.8.8"",
  ""hostname"": ""google-public-dns-a.google.com"",
  ""loc"": ""37.385999999999996,-122.0838"",
  ""org"": ""AS15169 Google Inc."",
  ""city"": ""Mountain View"",
  ""region"": ""CA"",
  ""country"": ""US"",
  ""phone"": 650
}
</code></pre>

<p>If you're only after the country code you just need to add /country to the URL:</p>

<pre><code>$ curl ipinfo.io/8.8.8.8/country
US
</code></pre>

<p>Here's a generic PHP function you could use:</p>

<pre><code>function ip_details($ip) {
    $json = file_get_contents(""http://ipinfo.io/{$ip}"");
    $details = json_decode($json);
    return $details;
}

$details = ip_details(""8.8.8.8"");

echo $details-&gt;city;     // =&gt; Mountain View
echo $details-&gt;country;  // =&gt; US
echo $details-&gt;org;      // =&gt; AS15169 Google Inc.
echo $details-&gt;hostname; // =&gt; google-public-dns-a.google.com
</code></pre>

<p>I've used the IP 8.8.8.8 in these examples, but if you want details for the user's IP just pass in <code>$_SERVER['REMOTE_ADDR']</code> instead. More details are available at <a href=""http://ipinfo.io/developers"" rel=""nofollow"">http://ipinfo.io/developers</a></p>
",36191.0,15697.0,3
1033,23872935,False,"<p>you can use web service API's which do this work like:</p>

<pre><code>see example of service: http://ip-api.com and usage: http://whatmyip.info
</code></pre>
",3463375.0,87.0,2
1033,17350045,False,"<p>use the function ipToCountry($ip) from <a href=""http://www.mmtutorialvault.com/php-ip-to-country-function/"" rel=""nofollow"">http://www.mmtutorialvault.com/php-ip-to-country-function/</a></p>
",1942132.0,617.0,2
1033,2056811,False,"<p><a href=""http://ipinfodb.com/"" rel=""noreferrer"">ipinfodb</a> provides a free database and API for IP to country and vice versa. They use free data from MaxMind. The data gets updated every month, and it's a great free alternative with decent accuracy.</p>
",141177.0,5062.0,9
1033,11717563,False,"<p>Try this php code</p>

<pre><code>  &lt;?php  $ip = $_SERVER['REMOTE_ADDR'];
    $json = file_get_contents(""http://api.easyjquery.com/ips/?ip="".$ip.""&amp;full=true"");
    $json = json_decode($json,true);
    $timezone = $json[localTimeZone];?&gt;
</code></pre>
",1298003.0,658.0,3
1033,7822524,False,"<p>You can use the solution provided for <a href=""https://stackoverflow.com/questions/7778844/how-to-program-different-welcome-pages-based-on-country-ip"">this question</a>.</p>

<p>But it returns a 2 digit country code.</p>
",249816.0,300.0,3
1033,2056874,False,"<p><a href=""http://code.google.com/p/gmaps-samples/source/browse/trunk/clientlocation/clientlocation.html"" rel=""nofollow noreferrer"">google's</a> clientlocation returns (<a href=""http://www.gralumo.com"" rel=""nofollow noreferrer"">my example</a>)</p>

<pre><code>latlng = new google.maps.LatLng(google.loader.ClientLocation.latitude, google.loader.ClientLocation.longitude);
location = ""IP location: "" + getFormattedLocation();
document.getElementById(""location"").innerHTML = location;
</code></pre>
",108207.0,22041.0,3
1033,66140,False,"<p>There are two approaches: using an Internet service and using some kind of local list (perhaps wrapped in a library). What you want will depend on what you are building.</p>

<p>For services:</p>

<ul>
<li><a href=""http://www.hostip.info/use.html"" rel=""nofollow noreferrer"">http://www.hostip.info/use.html</a> (as mentioned by <a href=""https://stackoverflow.com/questions/1033/ip-to-country#1034"">Mark</a>)</li>
<li><a href=""http://www.team-cymru.org/Services/ip-to-asn.html"" rel=""nofollow noreferrer"">http://www.team-cymru.org/Services/ip-to-asn.html</a></li>
</ul>

<p>For lists:</p>

<ul>
<li><a href=""http://www.maxmind.com/app/geoip_country"" rel=""nofollow noreferrer"">http://www.maxmind.com/app/geoip_country</a> (as mentioned by <a href=""https://stackoverflow.com/questions/1033/ip-to-country#1056"">Orion</a>)</li>
<li><p>You could roll your own by downloading the lists from the RIRs:</p>

<ul>
<li><a href=""ftp://ftp.arin.net/pub/stats/arin/delegated-arin-latest"" rel=""nofollow noreferrer"">ftp.arin.net/pub/stats/arin/delegated-arin-latest</a></li>
<li><a href=""ftp://ftp.ripe.net/ripe/stats/delegated-ripencc-latest"" rel=""nofollow noreferrer"">ftp.ripe.net/ripe/stats/delegated-ripencc-latest</a></li>
<li><a href=""ftp://ftp.afrinic.net/pub/stats/afrinic/delegated-afrinic-latest"" rel=""nofollow noreferrer"">ftp.afrinic.net/pub/stats/afrinic/delegated-afrinic-latest</a></li>
<li><a href=""ftp://ftp.apnic.net/pub/stats/apnic/delegated-apnic-latest"" rel=""nofollow noreferrer"">ftp.apnic.net/pub/stats/apnic/delegated-apnic-latest</a></li>
<li><p><a href=""ftp://ftp.lacnic.net/pub/stats/lacnic/delegated-lacnic-latest"" rel=""nofollow noreferrer"">ftp.lacnic.net/pub/stats/lacnic/delegated-lacnic-latest</a></p>

<p>The format is documented <a href=""ftp://ftp.arin.net/pub/stats/arin/README"" rel=""nofollow noreferrer"">in this README</a></p></li>
</ul></li>
</ul>
",1054.0,1191.0,41
1033,1034,False,"<p>Here's a nice free service with a public API:
<a href=""http://www.hostip.info/use.html"" rel=""noreferrer"">http://www.hostip.info/use.html</a></p>
",116.0,265948.0,11
1037,1066,False,"<p><a href=""https://stackoverflow.com/users/46/sven"">Sven</a>, you reached the same conclusion as I did: I found the Shockwave Flash Object, all be it from a slightly different route, but was stumped on how to load the files from somewhere other than file on disk/URL. The <a href=""https://www.f-in-box.com/dotnet/"" rel=""nofollow noreferrer"">F-IN-BOX</a>, although just a wrapper of the Shockwave Flash Object seems to provide much more functionality, which may just help me!</p>

<p>Shooting flys with bazookas may be fun, but an embeded web brower is not the path that I am looking for. :)</p>

<p><em>There was a link on Adobe's site that talked about ""Embedding and Communicating with the Macromedia Flash Player in C# Windows Applications"" but they seem to have removed it :(</em></p>
",231.0,9610.0,8
1037,1039,True,"<p>While I haven't used a flash object inside a windows form application myself, I do know that it's possible.
In Visual studio on your toolbox, choose to add a new component.
Then in the new window that appears choose the <strong>""COM Components""</strong> tab to get a list in which you can find the <strong>""Shockwave Flash Object""</strong></p>

<p>Once added to the toolbox, simply use the control as you would use any other ""standard"" control from visual studio.</p>

<p>three simple commands are available to interact with the control:</p>

<ul>
<li>AxShockwaveFlash1.Stop()</li>
<li>AxShockwaveFlash1.Movie = FilePath &amp;
""\FileName.swf""</li>
<li>AxShockwaveFlash1.Play()</li>
</ul>

<p>which, I think, are all self explanatory.</p>

<blockquote>
  <p>It would be great to be able to load
  the flash content from a stream of
  sorts rather than a file on disk.</p>
</blockquote>

<p>I just saw you are also looking for a means to load the content from a stream,
and because I'm not really sure that is possible with the shockwave flash object I will give you another option (two actually).</p>

<p>the first is the one I would advise you to use only when necessary, as it uses the full blown <strong>""webbrowser component""</strong> (also available as an extra toolbox item), which is like trying to shoot a fly with a bazooka.
of course it will work, as the control will act as <a href=""http://visualbasic.about.com/library/courses/blecvbsbs2202.htm"" rel=""noreferrer"">a real browser window</a> (actually the internet explorer browser), but its not really meant to be used in the way you need it.</p>

<p>the second option is to use something I just discovered while looking for more information about playing flash content inside a windows form. <a href=""http://www.f-in-box.com/dotnet/#feature_flv_playing"" rel=""noreferrer"">F-IN-BOX</a> is a commercial solution that will also play content from a given website URL. (The link provided will direct you to the .NET code you have to use).</p>
",46.0,17306.0,32
1040,1043,False,"<p>You can use this program, <a href=""https://docs.microsoft.com/en-gb/sysinternals/downloads/handle"" rel=""nofollow noreferrer"">Handle</a>, to find which process has the lock on your file. It's a command-line tool, so I guess you use the output from that. I'm not sure about finding it programmatically.</p>

<p>If deleting the file can wait, you could specify it for deletion when your computer next starts up:</p>

<ol>
<li><p>Start <code>REGEDT32 (W2K)</code> or <code>REGEDIT (WXP)</code> and navigate to:</p>

<pre><code>HKEY_LOCAL_MACHINE\System\CurrentControlSet\Control\Session Manager
</code></pre></li>
<li><p>W2K and WXP</p>

<ul>
<li><p><strong>W2K:</strong><br/>Edit<br/>Add Value...<br/>Data Type: <code>REG_MULTI_SZ</code><br/>Value Name: <code>PendingFileRenameOperations</code><br/><kbd>OK</kbd></p></li>
<li><p><strong>WXP:</strong><br/>Edit<br/>New<br/>Multi-String Value<br/><kbd>enter</kbd><br/>
<code>PendingFileRenameOperations</code></p></li>
</ul></li>
<li><p>In the Data area, enter <code>""\??\"" + filename</code> to be deleted. LFNs may
be entered without being embedded in quotes. To delete <code>C:\Long Directory Name\Long File Name.exe</code>, enter the following data:</p>

<pre><code>\??\C:\Long Directory Name\Long File Name.exe
</code></pre>

<p>Then press <kbd>OK</kbd>.</p></li>
<li><p>The ""destination file name"" is a null (zero) string. It is entered
as follows:</p>

<ul>
<li><p><strong>W2K:</strong><br/>Edit<br/>Binary<br/>select Data Format: Hex<br/>click at the end of the hex string<br/>enter 0000 (four zeros)<br/><kbd>OK</kbd></p></li>
<li><p><strong>WXP:</strong><br/>Right-click the value<br/>choose ""Modify Binary Data""<br/>click at the end of the hex string<br/>enter 0000 (four zeros)<br/><kbd>OK</kbd></p></li>
</ul></li>
<li><p>Close <code>REGEDT32/REGEDIT</code> and reboot to delete the file.</p></li>
</ol>

<p><sup>(Shamelessly stolen from <a href=""http://www.pcreview.co.uk/forums/thread-1581158.php"" rel=""nofollow noreferrer"">some random forum</a>, for posterity's sake.)</sup></p>
",55.0,9396.0,5
1040,1049,False,"<p>If you want to do it programmatically. I'm not sure... and I'd really recommend against it.
If you're just troubleshooting stuff on your own machine, <a href=""https://docs.microsoft.com/en-gb/sysinternals/downloads/process-explorer"" rel=""nofollow noreferrer"">SysInternals Process Explorer</a> can help you</p>

<p>Run it, use the Find Handle command (I think it's either in the find or handle menu), and search for the name of your file. Once the handle(s) is found, you can forcibly close them.</p>

<p>You can then delete the file and so on.</p>

<p><strong>Beware</strong>, doing this may cause the program which owns the handles to behave strangely, as you've just pulled the proverbial rug out from under it, but it works well when you are debugging your own errant code, or when visual studio/windows explorer is being crapped and not releasing file handles even though you told them to close the file ages ago... sigh :-)</p>
",234.0,113281.0,8
1040,1044,True,"<p>Killing other processes is not a healthy thing to do. If your scenario involves something like uninstallation, you could use the <a href=""https://docs.microsoft.com/en-us/windows/win32/api/winbase/nf-winbase-movefileexa"" rel=""nofollow noreferrer""><strong><code>MoveFileEx</code></strong> API function</a> to mark the file for deletion upon next reboot.</p>

<p>If it appears that you really need to delete a file in use by another process, I'd recommend re-considering the actual problem before considering any solutions.</p>
",227.0,13526.0,36
1040,610598,False,"<p>Using Orion Edwards advice I downloaded the Sysinternals <a href=""https://en.wikipedia.org/wiki/Process_Explorer"" rel=""nofollow noreferrer"">Process&nbsp;Explorer</a> which in turn allowed me to discover that the file I was having difficulties deleting was in fact being held not by the <code>Excel.Applications</code> object I thought, but rather the fact that my C# code send mail code had created an Attachment object that left a handle to this file open.</p>

<p>Once I saw this, I quite simple called on the dispose method of the Attachment object, and the handle was released.</p>

<p>The Sysinternals explorer allowed me to discover this used in conjunction with the Visual&nbsp;Studio&nbsp;2005 debugger.</p>

<p>I highly recommend this tool!</p>
",,,4
1040,1051,False,"<p>The typical method is as follows. You've said you want to do this in C# so here goes...</p>

<ol>
<li>If you don't know which process has the file locked, you'll need to examine each process's handle list, and query each handle to determine if it identifies the locked file. Doing this in C# will likely require P/Invoke or an intermediary C++/CLI to call the native APIs you'll need.</li>
<li>Once you've figured out which process(es) have the file locked, you'll need to safely inject a small native DLL into the process (you can also inject a managed DLL, but this is messier, as you then have to start or attach to the .NET runtime).</li>
<li>That bootstrap DLL then closes the handle using CloseHandle, etc.</li>
</ol>

<p>Essentially: the way to unlock a ""locked"" file is to inject a DLL file into the offending process's address space and close it yourself. You can do this using native or managed code. No matter what, you're going to need a small amount of native code or at least P/Invoke into the same.</p>

<p>Helpful links:</p>

<ul>
<li><em><a href=""http://www.codeproject.com/KB/threads/winspy.aspx"" rel=""nofollow noreferrer"">Three Ways to Inject Your Code into Another Process</a></em></li>
<li><em><a href=""http://damianblog.com/2008/07/02/net-code-injection/"" rel=""nofollow noreferrer"">.NET Code Injection</a></em></li>
</ul>

<p>Good luck!</p>
",,,16
1040,41902743,False,"<p>You can use code that you supply the full file path to, and it will return a <code>List&lt;Processes&gt;</code> of anything locking that file:</p>

<pre><code>using System.Runtime.InteropServices;
using System.Diagnostics;

static public class FileUtil
{
    [StructLayout(LayoutKind.Sequential)]
    struct RM_UNIQUE_PROCESS
    {
        public int dwProcessId;
        public System.Runtime.InteropServices.ComTypes.FILETIME ProcessStartTime;
    }

    const int RmRebootReasonNone = 0;
    const int CCH_RM_MAX_APP_NAME = 255;
    const int CCH_RM_MAX_SVC_NAME = 63;

    enum RM_APP_TYPE
    {
        RmUnknownApp = 0,
        RmMainWindow = 1,
        RmOtherWindow = 2,
        RmService = 3,
        RmExplorer = 4,
        RmConsole = 5,
        RmCritical = 1000
    }

    [StructLayout(LayoutKind.Sequential, CharSet = CharSet.Unicode)]
    struct RM_PROCESS_INFO
    {
        public RM_UNIQUE_PROCESS Process;

        [MarshalAs(UnmanagedType.ByValTStr, SizeConst = CCH_RM_MAX_APP_NAME + 1)]
        public string strAppName;

        [MarshalAs(UnmanagedType.ByValTStr, SizeConst = CCH_RM_MAX_SVC_NAME + 1)]
        public string strServiceShortName;

        public RM_APP_TYPE ApplicationType;
        public uint AppStatus;
        public uint TSSessionId;
        [MarshalAs(UnmanagedType.Bool)]
        public bool bRestartable;
    }

    [DllImport(""rstrtmgr.dll"", CharSet = CharSet.Unicode)]
    static extern int RmRegisterResources(uint pSessionHandle,
                                          UInt32 nFiles,
                                          string[] rgsFilenames,
                                          UInt32 nApplications,
                                          [In] RM_UNIQUE_PROCESS[] rgApplications,
                                          UInt32 nServices,
                                          string[] rgsServiceNames);

    [DllImport(""rstrtmgr.dll"", CharSet = CharSet.Auto)]
    static extern int RmStartSession(out uint pSessionHandle, int dwSessionFlags, string strSessionKey);

    [DllImport(""rstrtmgr.dll"")]
    static extern int RmEndSession(uint pSessionHandle);

    [DllImport(""rstrtmgr.dll"")]
    static extern int RmGetList(uint dwSessionHandle,
                                out uint pnProcInfoNeeded,
                                ref uint pnProcInfo,
                                [In, Out] RM_PROCESS_INFO[] rgAffectedApps,
                                ref uint lpdwRebootReasons);

    /// &lt;summary&gt;
    /// Find out what process(es) have a lock on the specified file.
    /// &lt;/summary&gt;
    /// &lt;param name=""path""&gt;Path of the file.&lt;/param&gt;
    /// &lt;returns&gt;Processes locking the file&lt;/returns&gt;
    /// &lt;remarks&gt;See also:
    /// http://msdn.microsoft.com/en-us/library/windows/desktop/aa373661(v=vs.85).aspx
    /// http://wyupdate.googlecode.com/svn-history/r401/trunk/frmFilesInUse.cs (no copyright in code at time of viewing)
    /// 
    /// &lt;/remarks&gt;
    static public List&lt;Process&gt; WhoIsLocking(string path)
    {
        uint handle;
        string key = Guid.NewGuid().ToString();
        List&lt;Process&gt; processes = new List&lt;Process&gt;();

        int res = RmStartSession(out handle, 0, key);
        if (res != 0) throw new Exception(""Could not begin restart session.  Unable to determine file locker."");

        try
        {
            const int ERROR_MORE_DATA = 234;
            uint pnProcInfoNeeded = 0,
                 pnProcInfo = 0,
                 lpdwRebootReasons = RmRebootReasonNone;

            string[] resources = new string[] { path }; // Just checking on one resource.

            res = RmRegisterResources(handle, (uint)resources.Length, resources, 0, null, 0, null);

            if (res != 0) throw new Exception(""Could not register resource."");                                    

            //Note: there's a race condition here -- the first call to RmGetList() returns
            //      the total number of process. However, when we call RmGetList() again to get
            //      the actual processes this number may have increased.
            res = RmGetList(handle, out pnProcInfoNeeded, ref pnProcInfo, null, ref lpdwRebootReasons);

            if (res == ERROR_MORE_DATA)
            {
                // Create an array to store the process results
                RM_PROCESS_INFO[] processInfo = new RM_PROCESS_INFO[pnProcInfoNeeded];
                pnProcInfo = pnProcInfoNeeded;

                // Get the list
                res = RmGetList(handle, out pnProcInfoNeeded, ref pnProcInfo, processInfo, ref lpdwRebootReasons);
                if (res == 0)
                {
                    processes = new List&lt;Process&gt;((int)pnProcInfo);

                    // Enumerate all of the results and add them to the 
                    // list to be returned
                    for (int i = 0; i &lt; pnProcInfo; i++)
                    {
                        try
                        {
                            processes.Add(Process.GetProcessById(processInfo[i].Process.dwProcessId));
                        }
                        // catch the error -- in case the process is no longer running
                        catch (ArgumentException) { }
                    }
                }
                else throw new Exception(""Could not list processes locking resource."");                    
            }
            else if (res != 0) throw new Exception(""Could not list processes locking resource. Failed to get size of result."");                    
        }
        finally
        {
            RmEndSession(handle);
        }

        return processes;
    }
}
</code></pre>

<p>Then, iterate the list of processes and close them and delete the files:</p>

<pre><code>    string[] files = Directory.GetFiles(target_dir);
    List&lt;Process&gt; lstProcs = new List&lt;Process&gt;();

    foreach (string file in files)
    {
        lstProcs = ProcessHandler.WhoIsLocking(file);
        if (lstProcs.Count &gt; 0) // deal with the file lock
        {
            foreach (Process p in lstProcs)
            {
                if (p.MachineName == ""."")
                    ProcessHandler.localProcessKill(p.ProcessName);
                else
                    ProcessHandler.remoteProcessKill(p.MachineName, txtUserName.Text, txtPassword.Password, p.ProcessName);
            }
            File.Delete(file);
        }
        else
            File.Delete(file);
    }
</code></pre>

<p>And depending on if the file is on the local computer:</p>

<pre><code>public static void localProcessKill(string processName)
{
    foreach (Process p in Process.GetProcessesByName(processName))
    {
        p.Kill();
    }
}
</code></pre>

<p>or a network computer:</p>

<pre><code>public static void remoteProcessKill(string computerName, string fullUserName, string pword, string processName)
{
    var connectoptions = new ConnectionOptions();
    connectoptions.Username = fullUserName;  // @""YourDomainName\UserName"";
    connectoptions.Password = pword;

    ManagementScope scope = new ManagementScope(@""\\"" + computerName + @""\root\cimv2"", connectoptions);

    // WMI query
    var query = new SelectQuery(""select * from Win32_process where name = '"" + processName + ""'"");

    using (var searcher = new ManagementObjectSearcher(scope, query))
    {
        foreach (ManagementObject process in searcher.Get()) 
        {
            process.InvokeMethod(""Terminate"", null);
            process.Dispose();
        }
    }
}
</code></pre>

<p><strong>References:</strong><br>
<a href=""https://stackoverflow.com/questions/317071/how-do-i-find-out-which-process-is-locking-a-file-using-net"">How do I find out which process is locking a file using .NET?</a></p>

<p><a href=""https://stackoverflow.com/questions/41841590/delete-a-directory-where-someone-has-opened-a-file"">Delete a directory where someone has opened a file</a></p>
",1181535.0,5518.0,3
1040,587053,False,"<p>This looks promising. A way of killing the file handle....</p>

<p><a href=""http://www.timstall.com/2009/02/killing-file-handles-but-not-process.html"" rel=""nofollow noreferrer"">http://www.timstall.com/2009/02/killing-file-handles-but-not-process.html</a></p>
",2041.0,8293.0,3
1040,1050,False,"<p>Oh, one big hack I employed years ago, is that Windows won't let you <em>delete</em> files, but it does let you <em>move</em> them.</p>

<p>Pseudo-sort-of-code:</p>

<pre><code>mv %WINDIR%\System32\mfc42.dll %WINDIR\System32\mfc42.dll.old
Install new mfc42.dll
Tell user to save work and restart applications
</code></pre>

<p>When the applications restarted (note we didn't need to reboot the machine), they loaded the new <code>mfc42.dll</code>, and all was well. That, coupled with <code>PendingFileOperations</code> to delete the old one the next time the whole system restarted, worked pretty well.</p>
",234.0,113281.0,3
1041,76358,False,"<p>The free ATL Server Library and Tools from CodePlex includes a regex parser. See <a href=""https://archive.codeplex.com/?p=atlserver"" rel=""nofollow noreferrer"">AtlServer in the CodePlex Archive</a></p>

<blockquote>
  <p>ATL Server is a library of C++ classes that allow developers to build
  both client and server parts of service-type C++ applications and web
  services. It provides much of the functionality required to build
  large scale internet sites, such as SOAP messaging, caching
  facilities, threading facilities, regular expression processing,
  management of session-state, performance monitoring, MIME support,
  integration with IIS and class for interacting with security and
  cryptographic infrastructure. The earlier versions of the library are
  parts of Visual Studio 2002, Visual Studio 2003 and Visual Studio
  2005. The project has started from the version of the library released as part of Visual Studio 2005 SP1.</p>
</blockquote>
",,69706.0,2
1041,7564,False,"<p>Why don't you use Microsoft ATL's regex library? Kenny Kerr has written a <a href=""http://weblogs.asp.net/kennykerr/archive/2008/07/18/visual-c-in-short-regular-expressions.aspx"" rel=""nofollow noreferrer"">short article</a> on that recently.</p>

<blockquote>
  <p>ATL includes a lightweight regular expression implementation. Although
  originally part of Visual C++, it is now included with the ATL Server
  download.</p>
  
  <p>The <code>CAtlRegExp</code> class template implements the parser and matching
  engine.  ...</p>
  
  <p>The regular expression grammar is defined at the top of the <code>atlrx.h</code>
  header file.</p>
</blockquote>
",,945.0,3
1041,17198991,True,"<p>C++11 now includes the support of regular expressions.
It will be platform independent. You just need a recent compiler.
Check the following list to know which one to use.</p>

<p><a href=""http://wiki.apache.org/stdcxx/C%2B%2B0xCompilerSupport"" rel=""noreferrer"">http://wiki.apache.org/stdcxx/C%2B%2B0xCompilerSupport</a></p>

<p>Hope it helps</p>
",,3321.0,13
1041,37100978,False,"<p>C++11 and forward now contains the <a href=""http://en.cppreference.com/w/cpp/regex"" rel=""noreferrer"">standard regular expression library</a>.<br>
Include the <code>&lt;regex&gt;</code> header, and use.</p>
",,31428.0,4
1041,7189,False,"<p><a href=""http://qt.nokia.com/"" rel=""noreferrer"">Qt</a> has also a nice <a href=""http://en.wikipedia.org/wiki/Regular_expression"" rel=""noreferrer"">Regular Expression</a> implementation <a href=""http://qt-project.org/doc/qt-4.8/qregexp.html"" rel=""noreferrer"">QRegExp</a>. It is also platform independent.</p>
",,121.0,10
1041,1055,False,"<p>try <a href=""http://www.pcre.org/"" rel=""noreferrer"">libpcre</a></p>

<p>If you're stuck on windows they have a windows port which should work. I know <a href=""http://e-texteditor.com"" rel=""noreferrer"">e-texteditor</a> uses it, so at least that's proof it works :-)</p>
",,113281.0,12
1041,1062,False,"<p>The GNU C Library supports <a href=""http://www.gnu.org/software/libtool/manual/libc/Regular-Expressions.html"" rel=""noreferrer"">regular expressions</a>.  It's open, and the RE code seems to be easily extractable.</p>
",,265948.0,7
1041,1183,False,"<p>The GNU C library regular expressions facility (regcomp(), regexec() and friends) is broken. Use libetre instead; the function signatures match the ones provided by glibc.
<a href=""http://laurikari.net/tre/"" rel=""noreferrer"">http://laurikari.net/tre/</a></p>
",,,5
1041,1546,False,"<p>If you use Visual Studio you can use Visual C++ 2008 Feature Pack Release, this implements some of TR1, and includes regular expression parsing. <a href=""http://www.microsoft.com/downloads/details.aspx?FamilyId=D466226B-8DAB-445F-A7B4-448B326C48E7&amp;displaylang=en"" rel=""noreferrer"">Get it</a></p>
",,8502.0,10
1041,7611,False,"<p>I would second the recommendation for <a href=""http://pcre.org"" rel=""noreferrer"">PCRE</a>. I have used it in C++ projects in Windows and it works great. It's free, even for building commercial software. It also implements something of a de facto standard regular expression language, which will be welcome to your users. PCRE is of course Perl-compatible, and Python also uses the same library.</p>

<p>The native PCRE interface is a bit awkward and very C-style, so it's probably worth writing a nice C++ wrapper around it. There is very likely already is one out there, but I'm not familiar with any.</p>
",,821714.0,6
1042,1047,False,"<p>Quoting a much-replicated help page about Indexing Service query language:</p>

<blockquote>
  <p>To use specially treated characters such as &amp;, |, ^, #, @, $, (, ), in a query, enclose your query in quotation marks (“).</p>
</blockquote>

<p>As far as I know, full text search in <code>MSSQL</code> is also done by the Indexing Service, so this might help.</p>
",227.0,13526.0,1
1042,1061,True,"<p>The # char is indexed as punctuation and therefore ignored, so it looks like we'll remove the letter C from our word indexing ignore lists.</p>

<p>Tested it locally after doing that and rebuilding the indexes and I get results!</p>

<p>Looking at using a different word breaker language on the indexed column, so that those special characters aren't ignored.</p>

<p>EDIT: I also found <a href=""http://www.simple-talk.com/sql/learn-sql-server/sql-server-full-text-search-language-features/"" rel=""noreferrer"">this information</a>:</p>

<blockquote>
  <p>c# is indexed as c (if c is not in your noise word list, see more on noise word lists later), but C# is indexed as C# (in SQL 2005 and SQL 2000 running on Win2003 regardless if C or c is in your noise word list). It is not only C# that is stored as C#, but any capital letter followed by #. Conversely, c++ ( and any other lower-cased letter followed by a ++) is indexed as c (regardless of whether c is in your noise word list).</p>
</blockquote>
",3.0,15326.0,14
1053,43816298,False,"<p>I had looooong coffee chats with my best pal talking about Irrational numbers and the diference between other numbers. Well, both of us agree in this different point of view:</p>

<p>Irrational numbers are relations, as functions, in a way, what way? Well, think about ""if you want a perfect circle, give me a perfect pi"", but circles are diferent to the other figures (4 sides, 5, 6... 100, 200) but... How many more sides do you have, more like a circle it look like. If you followed me so far, connecting all this ideas here is the pi formula:
<a href=""https://i.stack.imgur.com/uM2PX.gif"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/uM2PX.gif"" alt=""enter image description here""></a></p>

<p>So, pi is a function, but one that never ends! because of the ∞ parameter, but I like to think that you can have ""instance"" of pi, if you change the ∞ parameter for a very big Int, you will have a very big pi instance.</p>

<p>Same with e, give me a huge parameter, I will give you a huge e.</p>

<p>Putting all the ideas together:</p>

<p>As we have memory limitations, the language and libs provide to us huge instance of irrational numbers, in this case, pi and e, as final result, you will have long aproach to get 0, like the examples provided by @Chris Jester-Young</p>
",7128034.0,14537.0,4
1053,1057,False,"<p>Is it possible to settle this dispute?</p>

<p>My first thought is to look to a symbolic language, like <a href=""http://en.wikipedia.org/wiki/Maple_(software)"" rel=""noreferrer"">Maple</a>. I don't think that counts as floating point though.</p>

<p>In fact, how does one represent <em>i</em> (or <em>j</em> for the engineers) in a conventional programming language?</p>

<p>Perhaps a better example is sin(π) = 0? (Or have I missed the point again?)</p>
",55.0,9396.0,7
1053,1773104,False,"<p>It's a limitation of our current floating point computational architectures. Floating point arithmetic is only an approximation of numeric poles like e or pi (or anything beyond the precision your bits allow). I really enjoy these numbers because they defy classification, and appear to have greater entropy(?) than even primes, which are a canonical series. A ratio defy's numerical representation, sometimes simple things like that can blow a person's mind (I love it).</p>

<p>Luckily entire languages and libraries can be dedicated to precision trigonometric functions by using notational concepts (similar to those described by <a href=""https://stackoverflow.com/users/267/lasse-v-karlsen"">Lasse V. Karlsen</a> ). </p>

<p>Consider a library/language that describes concepts like e and pi in a form that a machine can understand. Does a machine have any notion of what a perfect circle is? Probably not, but we can create an object - circle that satisfies all the known features we attribute to it (constant radius, relationship of radius to circumference is 2*pi*r = C). An object like pi is only described by the aforementioned ratio. r &amp; C can be numeric objects described by whatever precision you want to give them. e can be defined ""as the e is the unique real number such that the value of the derivative (slope of the tangent line) of the function f(x) = ex at the point x = 0 is exactly 1"" from <a href=""http://en.wikipedia.org/wiki/E_(mathematical_constant)"" rel=""nofollow noreferrer"">wikipedia</a>.</p>

<p>Fun question.</p>
",51700.0,4158.0,3
1053,394290,False,"<p>Numerical Analysis teaches us that you can't rely on the precise value of small differences between large numbers. </p>

<p>This doesn't just affect the equation in question here, but can bring instability to everything from solving a near-singular set of simultaneous equations, through finding the zeros of polynomials, to evaluating log(~1) or exp(~0) (I have even seen special functions for evaluating log(x+1) and (exp(x)-1) to get round this).</p>

<p>I would encourage you not to think in terms of zeroing the difference -- you can't -- but rather in doing the associated calculations in such a way as to ensure the minimum error.</p>

<p>I'm sorry, it's 43 years since I had this drummed into me at uni, and even if I could remember the references, I'm sure there's better stuff around now. I suggest <strong><em><a href=""http://en.wikipedia.org/wiki/Numerical_analysis#The_generation_and_propagation_of_errors"" rel=""nofollow noreferrer"">this</a></em></strong> as a starting point.</p>

<hr>

<p>If that sounds a bit patronising, I apologise. My ""Numerical Analysis 101"" was part of my Chemistry course, as there wasn't much CS in those days. I don't really have a feel for the place/importance numerical analysis has in a modern CS course. </p>
",9634.0,8757.0,3
1053,394225,True,"<p>It's not that most floating point implementations disagree, it's just that they cannot get the accuracy necessary to get a 100% answer. And the correct answer is that they can't.</p>

<p>PI is an infinite series of digits that nobody has been able to denote by anything other than  a symbolic representation, and e^X is the same, and thus the only way to get to 100% accuracy is to go symbolic.</p>
",267.0,348196.0,17
1053,26055,False,"<blockquote>
  <p>In fact, how does one represent i (or j for the engineers) in a conventional programming language?</p>
</blockquote>

<p>In a language that doesn't have a native representation, it is usually added using OOP to create a <code>Complex</code> class to represent <code>i</code> and <code>j</code>, with operator overloading to properly deal with operations involving other <code>Complex</code> numbers and or other number primitives native to the language.</p>

<p>Eg: <a href=""http://www.math.ksu.edu/~bennett/jomacg/c.html"" rel=""nofollow noreferrer"">Complex.java</a>, <a href=""http://msdn.microsoft.com/en-us/library/0352zzhd%28VS.80%29.aspx"" rel=""nofollow noreferrer"">C++ &lt; complex ></a></p>
",2134.0,6613.0,3
1053,26026,False,"<p>@Ryan Fox <blockquote>In fact, how does one represent i (or j for the engineers) in a conventional programming language?</blockquote></p>

<p>Native complex data types are far from unknown. Fortran had it by the mid-sixties, and the OP exhibits a variety of other languages that support them in hist followup. </p>

<p>And complex numbers can be added to other languages as libraries (with operator overloading they even look just like native types in the code).</p>

<p>But unless you provide a special case for this problem, the ""non-agreement"" is just an expression of imprecise machine arithmetic, no? It's like complaining that</p>

<pre><code>float r = 2/3;
float s = 3*r;
float t = s - 2;
</code></pre>

<p>ends with (t != 0) (At least if you use an dumb enough compiler)...</p>
",2509.0,90091.0,4
1053,26038,False,"<p>Your question seems a little odd to me, as you seem to be suggesting that the Floating Point math is implemented by the language.  That's generally not true, as the FP math is done using a floating point processor in hardware.  But software or hardware, floating point will always be inaccurate.  That's just how floats work.</p>

<p>If you need better precision you need to use a different number representation.  Just like if you're doing integer math on numbers that don't fit in an int or long.  Some languages have libraries for that built in (I know java has BigInteger and BigDecimal), but you'd have to explicitly use those libraries instead of native types, and the performance would be (sometimes significantly) worse than if you used floats.</p>
",1409.0,33825.0,5
1053,25528,False,"<p>I agree with Ryan, you would need to move to another number representation system. The solution is outside the realm of floating point math because you need pi to represented as an infinitely long decimal so any limited precision scheme just isn't going to work (at least not without employing some kind of fudge-factor to make up the lost precision).</p>
",2567.0,13754.0,5
1053,1054,False,"<p>Here's a short list of implementations and languages I've tried. It's sorted by closeness to zero:</p>

<ul>
<li>Scheme: <code>(+ 1 (make-polar 1 (atan 0 -1)))</code>

<ul>
<li>⇒ <code>0.0+1.2246063538223773e-16i</code> (Chez Scheme, MIT Scheme)</li>
<li>⇒ <code>0.0+1.22460635382238e-16i</code> (Guile)</li>
<li>⇒ <code>0.0+1.22464679914735e-16i</code> (Chicken with <code>numbers</code> egg)</li>
<li>⇒ <code>0.0+1.2246467991473532e-16i</code> (MzScheme, SISC, Gauche, Gambit)</li>
<li>⇒ <code>0.0+1.2246467991473533e-16i</code> (SCM)</li>
</ul></li>
<li>Common Lisp: <code>(1+ (exp (complex 0 pi)))</code>

<ul>
<li>⇒ <code>#C(0.0L0 -5.0165576136843360246L-20)</code> (CLISP)</li>
<li>⇒ <code>#C(0.0d0 1.2246063538223773d-16)</code> (CMUCL)</li>
<li>⇒ <code>#C(0.0d0 1.2246467991473532d-16)</code> (SBCL)</li>
</ul></li>
<li>Perl: <code>use Math::Complex; Math::Complex-&gt;emake(1, pi) + 1</code>

<ul>
<li>⇒ <code>1.22464679914735e-16i</code></li>
</ul></li>
<li>Python: <code>from cmath import exp, pi; exp(complex(0, pi)) + 1</code>

<ul>
<li>⇒ <code>1.2246467991473532e-16j</code> (CPython)</li>
</ul></li>
<li>Ruby: <code>require 'complex'; Complex::polar(1, Math::PI) + 1</code>

<ul>
<li>⇒ <code>Complex(0.0, 1.22464679914735e-16)</code> (MRI)</li>
<li>⇒ <code>Complex(0.0, 1.2246467991473532e-16)</code> (JRuby)</li>
</ul></li>
<li>R: <code>complex(argument = pi) + 1</code>

<ul>
<li>⇒ <code>0+1.224606353822377e-16i</code></li>
</ul></li>
</ul>
",13.0,205366.0,10
1064,1092,False,"<p>Just use glTranslatef (or the DirectX equivalent) to draw a cube using the same code, but moving the relative point where you draw it. Maybe there's a better way to do it though, I'm fairly new to OpenGL. Be sure to set your viewpoint so you can see them all.</p>
",,43404.0,8
1064,1096,False,"<p>You say you have enough trouble getting one cube to display... so I am not sure if you have got one to display or not.</p>

<p>Basically... put your code for writing a cube in one function, then just call that function 100 times.</p>

<pre><code>void DrawCube()
{
    //code to draw the cube
}

void DisplayCubes()
{
    for(int i = 0; i &lt; 10; ++i)
    {   
         for(int j = 0; j &lt; 10; ++j)
         {
             glPushMatrix();
             //alter these values depending on the size of your cubes.
             //This call makes sure that your cubes aren't drawn overtop of each other
             glTranslatef(i*5.0, j*5.0, 0);
             DrawCube();
             glPopMatrix();
         }
    }              
}
</code></pre>

<p>That is the basic outline for how you could go about doing this. If you want something more efficient take a look into Display Lists sometime once you have the basics figured out :)</p>
",,1058.0,9
1064,15989,False,"<p>Yeah, if you were being efficient you'd throw everything into the same vertex buffer, but I don't think drawing 100 cubes will push any GPU produced in the past 5 years, so you should be fine following the suggestions above.</p>

<p>Write a basic pass through vertex shader, shade however you desire in the pixel shader. Either pass in a world matrix and do the translation in the vertex shader, or just compute the world space vertex positions on the CPU side (do this if your cubes are going to stay fixed).</p>

<p>You could get fancy and do <a href=""http://en.wikipedia.org/wiki/Geometry_instancing"" rel=""noreferrer"">geometry instancing</a> etc, but just get the basics going first. </p>
",,4597.0,7
1069,1073,True,"<p>My first choice would be a dedicated heap tool such as <a href=""https://support.microsoft.com/en-us/kb/286470"" rel=""noreferrer"">pageheap.exe</a>.</p>

<p>Rewriting new and delete might be useful, but that doesn't catch the allocs committed by lower-level code. If this is what you want, better to Detour the <code>low-level alloc API</code>s using Microsoft Detours.</p>

<p>Also sanity checks such as: verify your run-time libraries match (release vs. debug, multi-threaded vs. single-threaded, dll vs. static lib), look for bad deletes (eg, delete where delete [] should have been used), make sure you're not mixing and matching your allocs.</p>

<p>Also try selectively turning off threads and see when/if the problem goes away.</p>

<p>What does the call stack etc look like at the time of the first exception?</p>
",,,29
1069,38911,False,"<p>Is this in low memory conditions? If so it might be that new is returning <code>NULL</code> rather than throwing std::bad_alloc. Older <code>VC++</code> compilers didn't properly implement this.  There is an article about <a href=""http://msdn.microsoft.com/en-us/magazine/cc164087.aspx"" rel=""nofollow noreferrer"">Legacy memory allocation failures</a> crashing <code>STL</code> apps built with <code>VC6</code>.  </p>
",3892.0,5209.0,3
1069,70088,False,"<p>Run the original application with <code>ADplus -crash -pn appnename.exe</code>
When the memory issue pops-up you will get a nice big dump.</p>

<p>You can analyze the dump to figure what memory location was corrupted.
If you are lucky the overwrite memory is a unique string you can figure out where it came from. If you are not lucky, you will need to dig into <code>win32</code> heap and figure what was the orignal memory characteristics. (heap -x  might help)</p>

<p>After you know what was messed-up, you can narrow appverifier usage with special heap settings. i.e. you can specify what <code>DLL</code> you monitor, or what allocation size to monitor.</p>

<p>Hopefully this will speedup the monitoring enough to catch the culprit.</p>

<p>In my experience, I never needed full heap verifier mode, but I spent a lot of time analyzing the crash dump(s) and browsing sources. </p>

<p><strong>P.S:</strong>
You can use <a href=""http://blogs.msdn.com/tess/archive/2008/05/21/debugdiag-1-1-or-windbg-which-one-should-i-use-and-how-do-i-gather-memory-dumps.aspx"" rel=""noreferrer"">DebugDiag</a> to analyze the dumps.
It can point out the <code>DLL</code> owning the corrupted heap, and give you other usefull details.</p>
",11287.0,1731.0,8
1069,196176,False,"<p>You should attack this problem with both runtime and static analysis.</p>

<p>For static analysis consider compiling with PREfast (<code>cl.exe /analyze</code>). It detects mismatched <code>delete</code> and <code>delete[]</code>, buffer overruns and a host of other problems. Be prepared, though, to wade through many kilobytes of L6 warning, especially if your project still has <code>L4</code> not fixed.</p>

<p>PREfast is available with Visual Studio Team System and, <a href=""http://www.cs.auckland.ac.nz/~pgut001/pubs/sal.html"" rel=""nofollow noreferrer"">apparently</a>, as part of Windows SDK.</p>
",20310.0,25564.0,4
1069,22912,False,"<p>We've had pretty good luck by writing our own malloc and free functions. In production, they just call the standard malloc and free, but in debug, they can do whatever you want. We also have a simple base class that does nothing but override the new and delete operators to use these functions, then any class you write can simply inherit from that class. If you have a ton of code, it may be a big job to replace calls to malloc and free to the new malloc and free (don't forget realloc!), but in the long run it's very helpful.</p>

<p>In Steve Maguire's book <a href=""http://www.microsoft.com/mspress/books/1024.aspx"" rel=""nofollow noreferrer"">Writing Solid Code</a> (highly recommended), there are examples of debug stuff that you can do in these routines, like:</p>

<ul>
<li>Keep track of allocations to find leaks</li>
<li>Allocate more memory than necessary and put markers at the beginning and end of memory -- during the free routine, you can ensure these markers are still there</li>
<li>memset the memory with a marker on allocation (to find usage of uninitialized memory) and on free (to find usage of free'd memory)</li>
</ul>

<p>Another good idea is to <em>never</em> use things like <code>strcpy</code>, <code>strcat</code>, or <code>sprintf</code> -- always use <code>strncpy</code>, <code>strncat</code>, and <code>snprintf</code>. We've written our own versions of these as well, to make sure we don't write off the end of a buffer, and these have caught lots of problems too.</p>
",1821.0,51677.0,7
1069,3329,False,"<p>I have same problems in my work (we also use <code>VC6</code> sometimes). And there is no easy solution for it. I have only some hints:</p>

<ul>
<li>Try with automatic crash dumps on production machine (see <a href=""http://www.microsoft.com/downloads/details.aspx?FamilyID=e089ca41-6a87-40c8-bf69-28ac08570b7e&amp;displaylang=en"" rel=""noreferrer"">Process Dumper</a>). My experience says Dr. Watson is <strong>not perfect</strong> for dumping.</li>
<li>Remove all <strong>catch(...)</strong> from your code. They often hide serious memory exceptions.</li>
<li>Check <a href=""https://rads.stackoverflow.com/amzn/click/com/0321374460"" rel=""noreferrer"" rel=""nofollow noreferrer"">Advanced Windows Debugging</a> - there are lots of great tips for problems like yours. I recomend this with all my heart.</li>
<li>If you use <code>STL</code> try <code>STLPort</code> and checked builds. Invalid iterator are hell.</li>
</ul>

<p>Good luck. Problems like yours take us months to solve. Be ready for this...</p>
",501.0,9078.0,11
1069,1514251,False,"<p>A couple of suggestions. You mention the copious warnings at W4 - I would suggest taking the time to fix your code to compile cleanly at warning level 4 - this will go a long way to preventing subtle hard to find bugs.</p>

<p>Second - for the /analyze switch - it does indeed generate copious warnings. To use this switch in my own project, what I did was to create a new header file that used #pragma warning to turn off all the additional warnings generated by /analyze. Then further down in the file, I turn on only those warnings I care about. Then use the /FI compiler switch to force this header file to be included first in all your compilation units. This should allow you to use the /analyze switch while controling the output</p>
",,,0
1069,1206734,False,"<p>Do you think this is a race condition?  Are multiple threads sharing one heap?  Can you give each thread a private heap with HeapCreate, then they can run fast with HEAP_NO_SERIALIZE.  Otherwise, a heap should be thread safe, if you're using the multi-threaded version of the system libraries.</p>
",,,0
1069,380781,False,"<p>The little time I had to solve a similar problem.
If the problem still exists I suggest you do this :
Monitor all calls to new/delete and malloc/calloc/realloc/free.
I make single DLL exporting a function for register all calls. This function receive parameter for identifying your code source, pointer to allocated area and type of call saving this information in a table.
All allocated/freed pair is eliminated. At the end or after you need you make a call to an other function for create report for left data.
With this you can identify wrong calls (new/free or malloc/delete) or missing.
If have any case of buffer overwritten in your code the information saved can be wrong but each test may detect/discover/include a solution of failure identified. Many runs to help identify the errors. 
Good luck.</p>
",47733.0,7529.0,0
1069,83323,False,"<p>If you choose to rewrite new/delete, I have done this and have simple source code at:</p>

<p><a href=""http://gandolf.homelinux.org/~smhanov/blog/?id=10"" rel=""nofollow noreferrer""><a href=""http://gandolf.homelinux.org/~smhanov/blog/?id=10"" rel=""nofollow noreferrer"">http://gandolf.homelinux.org/~smhanov/blog/?id=10</a></a></p>

<p>This catches memory leaks and also inserts guard data before and after the memory block to capture heap corruption. You can just integrate with it by putting #include ""debug.h"" at the top of every CPP file, and defining DEBUG and DEBUG_MEM.</p>
",15947.0,10233.0,1
1069,38809,False,"<p>Graeme's suggestion of custom malloc/free is a good idea. See if you can characterize some pattern about the corruption to give you a handle to leverage.</p>

<p>For example, if it is always in a block of the same size (say 64 bytes) then change your malloc/free pair to always allocate 64 byte chunks in their own page.  When you free a 64 byte chunk then set the memory protection bits on that page to prevent reads and wites (using VirtualQuery).  Then anyone attempting to access this memory will generate an exception rather than corrupting the heap.</p>

<p>This does assume that the number of outstanding 64 byte chunks is only moderate or you have a lot of memory to burn in the box!</p>
",3631.0,43789.0,0
1069,26726,False,"<p>The apparent randomness of the memory corruption sounds very much like a thread synchronization issue - a bug is reproduced depending on machine speed. If objects (chuncks of memory) are shared among threads and synchronization (critical section, mutex, semaphore, other) primitives are not on per-class (per-object, per-class) basis, then it is possible to come to a situation where class (chunk of memory) is deleted / freed while in use, or used after deleted / freed.</p>

<p>As a test for that, you could add synchronization primitives to each class and method. This will make your code slower because many objects will have to wait for each other, but if this eliminates the heap corruption, your heap-corruption problem will become a code optimization one.</p>
",2877.0,2286.0,3
1069,22847,False,"<p>So from the limited information you have, this can be a combination of one or more things:</p>

<ul>
<li>Bad heap usage, i.e., double frees, read after free, write after free, setting the HEAP_NO_SERIALIZE flag with allocs and frees from multiple threads on the same heap</li>
<li>Out of memory</li>
<li>Bad code (i.e., buffer overflows, buffer underflows, etc.)</li>
<li>""Timing"" issues</li>
</ul>

<p>If it's at all the first two but not the last, you should have caught it by now with either pageheap.exe.</p>

<p>Which most likely means it is due to how the code is accessing shared memory. Unfortunately, tracking that down is going to be rather painful. Unsynchronized access to shared memory often manifests as weird ""timing"" issues. Things like not using acquire/release semantics for synchronizing access to shared memory with a flag, not using locks appropriately, etc.</p>

<p>At the very least, it would help to be able to track allocations somehow, as was suggested earlier. At least then you can view what actually happened up until the heap corruption and attempt to diagnose from that.</p>

<p>Also, if you can easily redirect allocations to multiple heaps, you might want to try that to see if that either fixes the problem or results in more reproduceable buggy behavior.</p>

<p>When you were testing with VS2008, did you run with HeapVerifier with Conserve Memory set to Yes? That might reduce the performance impact of the heap allocator. (Plus, you have to run with it Debug->Start with Application Verifier, but you may already know that.)</p>

<p>You can also try debugging with Windbg and various uses of the !heap command.</p>

<p>MSN</p>
",1799.0,1058.0,1
1069,1086,False,"<p>My first action would be as follows:</p>

<ol>
<li>Build the binaries in ""Release"" version but creating debug info file (you will find this possibility in project settings).</li>
<li>Use Dr Watson as a defualt debugger (DrWtsn32 -I) on a machine on which you want to reproduce the problem.</li>
<li>Repdroduce the problem. Dr Watson will produce a dump that might be helpful in further analysis. </li>
</ol>

<p>Another try might be using WinDebug as a debugging tool which is quite powerful being at the same time also lightweight. </p>

<p>Maybe these tools will allow you at least to narrow the problem to certain component.</p>

<p>And are you sure that all the components of the project have correct runtime library settings (C/C++ tab, Code Generation category in VS 6.0 project settings)?</p>
",2090742.0,661.0,1
1069,1072,False,"<p>You tried old builds, but is there a reason you can't keep going further back in the repository history and seeing exactly when the bug was introduced?</p>

<p>Otherwise, I would suggest adding simple logging of some kind to help track down the problem, though I am at a loss of what specifically you might want to log.</p>

<p>If you can find out what exactly CAN cause this problem, via google and documentation of the exceptions you are getting, maybe that will give further insight on what to look for in the code.</p>
",122.0,42831.0,1
1070,1773,True,"<p>The exact definitions of <code>vsize</code>, <code>rss</code>, <code>rprvt</code>, <code>rshrd</code>, and other obscure-looking abbreviations vary from OS to OS.  The manual pages for the <code>top</code> and <code>ps</code> commands will have some sort of description, but all such descriptions are simplified greatly (or are based on long-extinct kernel implementations).<br>
""Process size"" as a concept is fiendishly difficult to pin down in the general case.  Answers in specific instances depend heavily on the actual memory management implementation in the OS, and are rarely as satisfying as the tidy ""process size"" concept that exists in the minds of most users (and most developers).</p>

<p>For example, none of those numbers (nor, likely, any combination of them) can be used to tell you exactly how many such processes can run at once in a given amount of free memory.  But really, your best bet is to come at it from that end: why do you want this number, and what will you use it for?  Given that information, I think you'll get more useful answers.</p>
",164.0,14231.0,17
1070,1082,False,"<p>Yes, you are right to lock at the VSZ.</p>

<p><code>ps u</code> will give you the VSZ and RSS, which are the virtual memory size and resident set size.  The RSS is how much physical memory has been allocated to the process, and the VSZ is the virtual memory size of the process.  If you have several copies of a program running, a lot of the memory in the VSZ will be shared between those processes.</p>
",116.0,265948.0,4
1070,107267,False,"<p>On Solaris, you can get detailed information on a process's memory usage with the <code>pmap</code> command. In particular, <code>pmap -x &lt;pid&gt;</code> shows you how much of a process's memory is shared and how much is specifically used by that process. This is useful for working out the ""marginal"" memory usage of a process -- with this technique you can avoid double-counting shared libraries.</p>
",19417.0,128.0,5
1070,22536892,False,"<p>I summed up the resident set size for all processes like this (as root):</p>

<pre><code>ps ax -o rss | awk '{rss += $1;} END { print rss}'
</code></pre>
",2761777.0,1521.0,2
1083,1090,False,"<p>Maybe <a href=""https://ci-bayes.dev.java.net/"" rel=""nofollow noreferrer"">https://ci-bayes.dev.java.net/</a> or <a href=""http://www.cs.cmu.edu/~javabayes/Home/node2.html"" rel=""nofollow noreferrer"">http://www.cs.cmu.edu/~javabayes/Home/node2.html</a>?</p>

<p>I never played with it either.</p>
",86.0,6657.0,5
1083,840232,False,"<p><a href=""http://codecube.net/2009/05/bayesian-filtering-with-c/"" rel=""nofollow noreferrer"">nBayes</a> - another C# implementation hosted on CodePlex</p>
",5416.0,43893.0,2
1083,42406,True,"<p>I definitely recommend <a href=""http://www.cs.waikato.ac.nz/ml/weka/"" rel=""noreferrer"">Weka</a> which is an <em>Open Source Data Mining Software</em> written in Java:</p>

<blockquote>
  <p>Weka is a collection of machine learning algorithms for data mining tasks. The algorithms can either be applied directly to a dataset or called from your own Java code. Weka contains tools for data pre-processing, classification, regression, clustering, association rules, and visualization. It is also well-suited for developing new machine learning schemes.</p>
</blockquote>

<p>As mentioned above, it ships with a bunch of different classifiers like <a href=""http://en.wikipedia.org/wiki/Support_vector_machine"" rel=""noreferrer"">SVM</a>, <a href=""http://en.wikipedia.org/wiki/Winnow_%28algorithm%29"" rel=""noreferrer"">Winnow</a>, <a href=""http://en.wikipedia.org/wiki/C4.5_algorithm"" rel=""noreferrer"">C4.5</a>, Naive Bayes (of course) and many more (see the <a href=""http://weka.sourceforge.net/doc/"" rel=""noreferrer"">API doc</a>).
Note that a lot of classifiers are known to have <strong>much better perfomance than Naive Bayes</strong> in the field of spam detection or text classification.</p>

<p>Furthermore Weka brings you a very <a href=""http://www.cs.waikato.ac.nz/~ml/weka/gui_explorer.html"" rel=""noreferrer"">powerful GUI</a>…</p>
",4308.0,11361.0,12
1083,37521,False,"<p>Check out Chapter 6 of <a href=""https://rads.stackoverflow.com/amzn/click/com/0596529325"" rel=""noreferrer"" rel=""nofollow noreferrer"">Programming Collective Intelligence</a></p>
",3973.0,13430.0,5
1083,1142,False,"<p>In French, but you should be able to find the download link :)
<a href=""http://xhtml.net/scripts/PHPNaiveBayesianFilter"" rel=""nofollow noreferrer"">PHP Naive Bayesian Filter</a></p>
",268.0,33176.0,1
1083,1095,False,"<p>Here is an implementation of Bayesian filtering in C#: <a href=""http://www.codeproject.com/KB/recipes/BayesianCS.aspx"" rel=""nofollow noreferrer"">A Naive Bayesian Spam Filter for C#</a> (hosted on CodeProject).</p>
",51.0,37890.0,3
1104,37101290,False,"<p>There was once an attempt to add <a href=""http://en.cppreference.com/w/cpp/language/except_spec"" rel=""nofollow"">dynamic exception specifications</a> to a function's signature, but since the language could not enforce their accuracy, they were later depreciated. </p>

<p>In C++11 and forward, we now have the <a href=""http://en.cppreference.com/w/cpp/language/noexcept_spec"" rel=""nofollow"">noexcept specifier</a>.<br>
Again, if the signature is marked to throw, there is still not requriement that it be handled by the caller.  </p>

<hr>

<p>Depending on the context, you can ensure that exceptional behaviour be handled by coding it into the type system.  </p>

<p><strong>See:</strong> <a href=""http://en.cppreference.com/w/cpp/utility/optional"" rel=""nofollow"">std::optional</a> as part of the library fundamentals.</p>
",908939.0,31428.0,0
1104,126184,False,"<p>You shouldn't be using an exception here. This obviously isn't an exceptional case if you need to be expecting it everywhere you use this function!</p>

<p>A better solution would be to get the function to return an instance of something like this. In debug builds (assuming developers exercise code paths they've just written), they'll get an assert if they forget to check whether the operation succeded or not.</p>

<pre><code>class SearchResult
{
  private:
    ResultType result_;
    bool succeeded_;
    bool succeessChecked_;

  public:
    SearchResult(Result&amp; result, bool succeeded)
      : result_(result)
      , succeeded_(succeeded)
      , successChecked_(false)
    {
    }

    ~SearchResult()
    {
      ASSERT(successChecked_);
    }

    ResultType&amp; Result() { return result_; }
    bool Succeeded() { successChecked_ = true; return succeeded_; }
}
</code></pre>
",11898.0,52916.0,9
1104,1454,False,"<p>Outside the scope of your question so I debated not posting this but in Java there are actually 2 types of exceptions, checked and unchecked. The basic difference is that, much like in <code>c[++]</code>, you dont have to catch an unchecked exception.</p>

<p>For a good reference <a href=""http://java.sun.com/docs/books/tutorial/essential/exceptions/runtime.html"" rel=""nofollow noreferrer"">try this</a> </p>
",292.0,26718.0,3
1104,1109,True,"<p>No.</p>

<p>See <a href=""http://www.gotw.ca/publications/mill22.htm"" rel=""noreferrer"">A Pragmatic Look at Exception Specifications</a> for reasons why not. </p>

<p>The only way you can ""help"" this is to document the exceptions your function can throw, say as a comment in the header file declaring it. This is not enforced by the compiler or anything. Use code reviews for that purpose.</p>
",13.0,205366.0,25
1104,1909,False,"<p><a href=""https://stackoverflow.com/questions/1104/#1109"">Chris</a>' probably has the best pure answer to the question:</p>

<p>However, I'm curious about the root of the question.  If the user should <em>always</em> wrap the call in a try/catch block, should the user-called function really be throwing exceptions in the first place?</p>

<p>This is a difficult question to answer without more context regarding the code-base in question.  Shooting from the hip, I think the best answer here is to wrap the function up such that the recommended (if not only, depending on the overall exception style of the code) public interface does the try/catch <em>for</em> the user.  If you're just trying to ensure that there are no unhandled exceptions in your code, unit tests and code review are probably the best solution.</p>
",363.0,26262.0,2
1104,1474,False,"<blockquote>
  <p>Is there a way one can ensure that the
  exceptions thrown are always caught
  using try/catch by the calling
  function?</p>
</blockquote>

<p>I find it rather funny, that the Java crowd - <a href=""http://dlinsin.blogspot.com/2008/01/wonderful-checked-exceptions.html"" rel=""nofollow noreferrer"">including myself</a> - is trying to avoid checked Exceptions. They are trying to work their way around being forced to catch Exceptions by using <a href=""http://java.sun.com/javase/6/docs/api/java/lang/RuntimeException.html"" rel=""nofollow noreferrer"">RuntimeExceptions</a>.</p>
",198.0,17111.0,0
1104,1437,False,"<p>Or you could start throwing critical exceptions. Surely, an access violation exception will <em>catch</em> your users' attention.</p>
",55.0,9396.0,-1
1108,43572540,False,"<p>Classic example <strong>""Index in Books""</strong></p>

<p>Consider a ""Book"" of 1000 pages, divided by 10 Chapters, each section with 100 pages.</p>

<p>Simple, huh?</p>

<p>Now, imagine you want to find a particular Chapter that contains a word ""<strong>Alchemist</strong>"". Without an index page, you have no other option than scanning through the entire book/Chapters. i.e: 1000 pages. </p>

<p>This analogy is known as <strong>""Full Table Scan""</strong> in database world.</p>

<p><a href=""https://i.stack.imgur.com/Mnuvr.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/Mnuvr.jpg"" alt=""enter image description here""></a></p>

<p>But with an index page, you know where to go! And more, to lookup any particular Chapter that matters, you just need to look over the index page, again and again, every time. After finding the matching index you can efficiently jump to that chapter by skipping the rest.</p>

<p>But then, in addition to actual 1000 pages, you will need another ~10 pages to show the indices, so totally 1010 pages.</p>

<blockquote>
  <p>Thus, the index is a separate section that stores values of indexed
  column + pointer to the indexed row in a sorted order for efficient
  look-ups.</p>
</blockquote>

<p>Things are simple in schools, isn't it? :P</p>
",2629588.0,7581.0,417
1108,38710465,False,"<h2><strong>Simple Description!</strong></h2>

<p>The index is nothing but a data structure that <strong>stores the values for a specific column</strong> in a table. An index is created on a column of a table. </p>

<p>Example: We have a database table called <code>User</code> with three columns – <code>Name</code>, <code>Age</code> and <code>Address</code>. Assume that the <code>User</code> table has thousands of rows.</p>

<p>Now, let’s say that we want to run a query to find all the details of any users who are named 'John'. 
If we run the following query: </p>

<pre><code>SELECT * FROM User 
WHERE Name = 'John'
</code></pre>

<p>The database software would literally have to look at every single row in the <code>User</code> table to see if the <code>Name</code> for that row is ‘John’. This will take a long time.</p>

<p>This is where <code>index</code> helps us: <em>index is used to speed up search queries by essentially cutting down the number of records/rows in a table that needs to be examined</em>.  </p>

<p>How to create an index:</p>

<pre><code>CREATE INDEX name_index
ON User (Name)
</code></pre>

<p>An <code>index</code> consists of <strong>column values(Eg: John) from one table</strong>, and those values are stored in a <strong>data structure</strong>.  </p>

<blockquote>
  <p>So now the database will use the index to find employees named John
  because the index will presumably be sorted alphabetically by the
  Users name. And, because it is sorted, it means searching for a name
  is a lot faster because all names starting with a “J” will be right
  next to each other in the index!</p>
</blockquote>
",5960393.0,1405.0,118
1108,41268376,False,"<p>Just think of Database Index as Index of a book.</p>

<p>If you have a book about dogs and you want to find an information about let's say, German Shepherds, you could of course flip through all the pages of the book and find what you are looking for  - but this of course is time consuming and not very fast. </p>

<p>Another option is that, you could just go to the Index section of the book and then find what you are looking for by using the Name of the entity you are looking ( in this instance, German Shepherds) and also looking at the page number to quickly find what you are looking for. </p>

<p>In Database, the page number is referred to as a pointer which directs the database to the address on the disk where entity is located. Using the same German Shepherd analogy, we could have something like this (“German Shepherd”, 0x77129) where <code>0x77129</code> is the address on the disk where the row data for German Shepherd is stored. </p>

<p>In short, an index is a data structure that stores the values for a specific column in a table so as to speed up query search.</p>
",5138921.0,6041.0,37
1108,1130,True,"<p><strong>Why is it needed?</strong></p>

<p>When data is stored on disk-based storage devices, it is stored as blocks of data. These blocks are accessed in their entirety, making them the atomic disk access operation. Disk blocks are structured in much the same way as linked lists; both contain a section for data, a pointer to the location of the next node (or block), and both need not be stored contiguously.</p>

<p>Due to the fact that a number of records can only be sorted on one field, we can state that searching on a field that isn’t sorted requires a Linear Search which requires <code>N/2</code> block accesses (on average), where <code>N</code> is the number of blocks that the table spans. If that field is a non-key field (i.e. doesn’t contain unique entries) then the entire tablespace must be searched at <code>N</code> block accesses.</p>

<p>Whereas with a sorted field, a Binary Search may be used, which has <code>log2 N</code> block accesses. Also since the data is sorted given a non-key field, the rest of the table doesn’t need to be searched for duplicate values, once a higher value is found. Thus the performance increase is substantial.</p>

<p><strong>What is indexing?</strong></p>

<p>Indexing is a way of sorting a number of records on multiple fields. Creating an index on a field in a table creates another data structure which holds the field value, and a pointer to the record it relates to. This index structure is then sorted, allowing Binary Searches to be performed on it.</p>

<p>The downside to indexing is that these indices require additional space on the disk since the indices are stored together in a table using the MyISAM engine, this file can quickly reach the size limits of the underlying file system if many fields within the same table are indexed.</p>

<p><strong>How does it work?</strong></p>

<p>Firstly, let’s outline a sample database table schema; </p>

<pre>
Field name       Data type      Size on disk
id (Primary key) Unsigned INT   4 bytes
firstName        Char(50)       50 bytes
lastName         Char(50)       50 bytes
emailAddress     Char(100)      100 bytes
</pre>

<p><strong>Note</strong>: char was used in place of varchar to allow for an accurate size on disk value. 
This sample database contains five million rows and is unindexed. The performance of several queries will now be analyzed. These are a query using the <em>id</em> (a sorted key field) and one using the <em>firstName</em> (a non-key unsorted field).</p>

<p><strong><em>Example 1</em></strong> - <em>sorted vs unsorted fields</em></p>

<p>Given our sample database of <code>r = 5,000,000</code> records of a fixed size giving a record length of <code>R = 204</code> bytes and they are stored in a table using the MyISAM engine which is using the default block size <code>B = 1,024</code> bytes. The blocking factor of the table would be <code>bfr = (B/R) = 1024/204 = 5</code> records per disk block. The total number of blocks required to hold the table is <code>N = (r/bfr) = 5000000/5 = 1,000,000</code> blocks. </p>

<p>A linear search on the id field would require an average of <code>N/2 = 500,000</code> block accesses to find a value, given that the id field is a key field. But since the id field is also sorted, a binary search can be conducted requiring an average of <code>log2 1000000 = 19.93 = 20</code> block accesses. Instantly we can see this is a drastic improvement.</p>

<p>Now the <em>firstName</em> field is neither sorted nor a key field, so a binary search is impossible, nor are the values unique, and thus the table will require searching to the end for an exact <code>N = 1,000,000</code> block accesses. It is this situation that indexing aims to correct.</p>

<p>Given that an index record contains only the indexed field and a pointer to the original record, it stands to reason that it will be smaller than the multi-field record that it points to. So the index itself requires fewer disk blocks than the original table, which therefore requires fewer block accesses to iterate through. The schema for an index on the <em>firstName</em> field is outlined below; </p>

<pre>
Field name       Data type      Size on disk
firstName        Char(50)       50 bytes
(record pointer) Special        4 bytes
</pre>

<p><strong>Note</strong>: Pointers in MySQL are 2, 3, 4 or 5 bytes in length depending on the size of the table.</p>

<p><strong><em>Example 2</em></strong>  - <em>indexing</em></p>

<p>Given our sample database of <code>r = 5,000,000</code> records with an index record length of <code>R = 54</code> bytes and using the default block size <code>B = 1,024</code> bytes. The blocking factor of the index would be <code>bfr = (B/R) = 1024/54 = 18</code> records per disk block. The total number of blocks required to hold the index is <code>N = (r/bfr) = 5000000/18 = 277,778</code> blocks.</p>

<p>Now a search using the <em>firstName</em> field can utilize the index to increase performance. This allows for a binary search of the index with an average of <code>log2 277778 = 18.08 = 19</code> block accesses. To find the address of the actual record, which requires a further block access to read, bringing the total to <code>19 + 1 = 20</code> block accesses, a far cry from the 1,000,000 block accesses required to find a <em>firstName</em> match in the non-indexed table.</p>

<p><strong>When should it be used?</strong></p>

<p>Given that creating an index requires additional disk space (277,778 blocks extra from the above example, a ~28% increase), and that too many indices can cause issues arising from the file systems size limits, careful thought must be used to select the correct fields to index.</p>

<p>Since indices are only used to speed up the searching for a matching field within the records, it stands to reason that indexing fields used only for output would be simply a waste of disk space and processing time when doing an insert or delete operation, and thus should be avoided. Also given the nature of a binary search, the cardinality or uniqueness of the data is important. Indexing on a field with a cardinality of 2 would split the data in half, whereas a cardinality of 1,000 would return approximately 1,000 records. With such a low cardinality the effectiveness is reduced to a linear sort, and the query optimizer will avoid using the index if the cardinality is less than 30% of the record number, effectively making the index a waste of space.</p>
",264.0,76235.0,3745
1108,21911020,False,"<p>An index is just a data structure that makes the searching faster for a specific column in a database. This structure is usually a b-tree or a hash table but it can be any other logic structure.</p>
",1611802.0,3566.0,263
1108,38935815,False,"<p>Now, let’s say that we want to run a query to find all the details of any employees who are named ‘Abc’?</p>

<pre><code>SELECT * FROM Employee 
WHERE Employee_Name = 'Abc'
</code></pre>

<p><strong>What would happen without an index?</strong></p>

<p>Database software would literally have to look at every single row in the Employee table to see if the Employee_Name for that row is ‘Abc’. And, because we want every row with the name ‘Abc’ inside it, we can not just stop looking once we find just one row with the name ‘Abc’, because there could be other rows with the name <strong>Abc</strong>. So, every row up until the last row must be searched – which means thousands of rows in this scenario will have to be examined by the database to find the rows with the name ‘Abc’. This is what is called a <strong>full table scan</strong></p>

<p><strong>How a database index can help performance</strong></p>

<p>The whole point of having an index is to speed up search queries by essentially cutting down the number of records/rows in a table that need to be examined. An index is a data structure (most commonly a B- tree) that stores the values for a specific column in a table. </p>

<p><strong>How does B-trees index work?</strong></p>

<p>The reason B- trees are the most popular data structure for indexes is due to the fact that they are time efficient – because look-ups, deletions, and insertions can all be done in logarithmic time. And, another major reason B- trees are more commonly used is because the data that is stored inside the B- tree can be sorted. The RDBMS typically determines which data structure is actually used for an index. But, in some scenarios with certain RDBMS’s, you can actually specify which data structure you want your database to use when you create the index itself.</p>

<p><strong>How does a hash table index work?</strong></p>

<p>The reason hash indexes are used is because hash tables are extremely efficient when it comes to just looking up values. So, queries that compare for equality to a string can retrieve values very fast if they use a hash index. </p>

<p>For instance, the query we discussed earlier could benefit from a hash index created on the Employee_Name column. The way a hash index would work is that the column value will be the key into the hash table and the actual value mapped to that key would just be a pointer to the row data in the table. Since a hash table is basically an associative array, a typical entry would look something like “Abc => 0x28939″, where 0x28939 is a reference to the table row where Abc is stored in memory. Looking up a value like “Abc” in a hash table index and getting back a reference to the row in memory is obviously a lot faster than scanning the table to find all the rows with a value of “Abc” in the Employee_Name column.</p>

<p><strong>The disadvantages of a hash index</strong></p>

<p>Hash tables are not sorted data structures, and there are many types of queries which hash indexes can not even help with. For instance, suppose you want to find out all of the employees who are less than 40 years old. How could you do that with a hash table index? Well, it’s not possible because a hash table is only good for looking up key value pairs – which means queries that check for equality </p>

<p><strong>What exactly is inside a database index?</strong>
So, now you know that a database index is created on a column in a table, and that the index stores the values in that specific column. But, it is important to understand that a database index does not store the values in the other columns of the same table. For example, if we create an index on the Employee_Name column, this means that the Employee_Age and Employee_Address column values are not also stored in the index. If we did just store all the other columns in the index, then it would be just like creating another copy of the entire table – which would take up way too much space and would be very inefficient.</p>

<p><strong>How does a database know when to use an index?</strong>
When a query like “SELECT * FROM Employee WHERE Employee_Name = ‘Abc’ ” is run, the database will check to see if there is an index on the column(s) being queried. Assuming the Employee_Name column does have an index created on it, the database will have to decide whether it actually makes sense to use the index to find the values being searched – because there are some scenarios where it is actually less efficient to use the database index, and more efficient just to scan the entire table.</p>

<p><strong>What is the cost of having a database index?</strong></p>

<p>It takes up space – and the larger your table, the larger your index. Another performance hit with indexes is the fact that whenever you add, delete, or update rows in the corresponding table, the same operations will have to be done to your index. Remember that an index needs to contain the same up to the minute data as whatever is in the table column(s) that the index covers.</p>

<p>As a general rule, an index should only be created on a table if the data in the indexed column will be queried frequently.</p>

<p>See also </p>

<ol>
<li><a href=""https://stackoverflow.com/questions/107132/what-columns-generally-make-good-indexes/8937872#8937872"">What columns generally make good indexes?</a></li>
<li><a href=""http://www.programmerinterview.com/index.php/database-sql/what-is-an-index/"" rel=""noreferrer"">How do database indexes work</a></li>
</ol>
",1045444.0,46459.0,183
1108,27937172,False,"<p>Just a quick suggestion.. As indexing costs you additional writes and storage space, so if your application requires more insert/update operation, you might want to use tables without indexes, but if it requires more data retrieval operations, you should go for indexed table.</p>
",3854119.0,2050.0,39
1108,16302431,False,"<p>The first time I read this it was very helpful to me. Thank you.</p>

<p>Since then I gained some insight about the downside of creating indexes:
if you write into a table (<code>UPDATE</code> or <code>INSERT</code>) with one index, you have actually two writing operations in the file system. One for the table data and another one for the index data (and the resorting of it (and - if clustered - the resorting of the table data)). If table and index are located on the same hard disk this costs more time. Thus a table without an index (a heap) , would allow for quicker write operations. (if you had two indexes you would end up with three write operations, and so on)</p>

<p>However, defining two different locations on two different hard disks for index data and table data can decrease/eliminate the problem of increased cost of time. This requires definition of additional file groups with according files on the desired hard disks and definition of table/index location as desired.</p>

<p>Another problem with indexes is their fragmentation over time as data is inserted. <code>REORGANIZE</code> helps, you must write routines to have it done.</p>

<p>In certain scenarios a heap is more helpful than a table with indexes, </p>

<p>e.g:- If you have lots of rivalling writes but only one nightly read outside business hours for reporting.</p>

<p>Also, a differentiation between clustered and non-clustered indexes is rather important. </p>

<p>Helped me:- <a href=""https://stackoverflow.com/questions/1251636/what-do-clustered-and-non-clustered-index-actually-mean"">What do Clustered and Non clustered index actually mean?</a></p>
",2331665.0,3048.0,253
1131,1384548,False,"<p>I don't like the html option, and actually moved from plain HTML to CHM by compressing and indexing them. Even use them on a handful of non-Windows customers even.
It simply solved the constant little breakage of people putting it on the network (nesting depth limited, strange locking effects), antivirus that died in directories with 30000 html files, and 20 minutes decompression time while installing on an older system, browser safety zones and features, miscalculations of needed space in the installer etc.</p>

<p>And then I don't even include the people that start ""correcting"" them, 3rd party product with faulty ""integration"" attempts etc, complaints about slowliness (browser start-up)</p>

<p>We all had waited years for the problems to go away as OSes and hardware improved, but the problems kept recurring in a bedazzling number of varieties and enough was enough. We found chmlib, and decided we could forever use something based on this as escape with a simple external reader, if the OS provided ones stopped working and switched.</p>

<p>Meanwhile we also have an own compiler, so we are MS free future-proof. That doesn't mean we never will change (solutions with local web-servers seem favourite nowadays), but at least we have a choice.</p>
",99354.0,24405.0,5
1131,1136,False,"<p>Is the question how to generate your own help files, or what is the best help file format?</p>

<p>Personally, I find CHM to be excellent.  One of the first things I do when setting up a machine is to download the PHP Manual in CHM format (<a href=""http://www.php.net/download-docs.php"" rel=""nofollow noreferrer"">http://www.php.net/download-docs.php</a>) and add a hotkey to it in <a href=""http://crimsoneditor.com/"" rel=""nofollow noreferrer"">Crimson Editor</a>.  So when I press F1 it loads the CHM and performs a search for the word my cursor is on (great for quick function reference).  </p>
",40.0,12742.0,3
1131,324618,False,"<p>I think the solution we're going to end up going with for our application is hosting the help files ourselves.  This gives us immediate access to the files and the ability to keep them up to date.  </p>

<p>What I plan is to have the content loaded into a huge series of XML files, each one containing help for a specific item.  This XML would contain links to other XML files.  We would use XSLT to display the contents as necessary.</p>

<p>Depending on the licensing, we may build a client-specific XSLT file in order to tailor the look and feel to what they need.  We may need to be able to only show help for particular versions of our product as well and that can be done by filtering out stuff in the XSLT.</p>
",37510.0,2578.0,2
1131,109848,False,"<p>It depends on how import the online documentation is to your product, a good documentation infrastructure can be complex to establish but once done it pays off. Here is how we do it -</p>

<ul>
<li>Help source <a href=""http://en.wikipedia.org/wiki/Darwin_Information_Typing_Architecture"" rel=""nofollow noreferrer"">DITA</a> compilant XML, stored in SCC (ClearCase).</li>
<li>Help editing <a href=""http://na.justsystems.com/content.php?page=xmetal"" rel=""nofollow noreferrer"">XMetal</a></li>
<li>Help compilation, customized <a href=""http://dita-ot.sourceforge.net/"" rel=""nofollow noreferrer"">Open DITA Toolkit</a>, with custom Perl/Java preprocessing</li>
<li>Help source cross references applications resources at compile time, .RC files etc</li>
<li>Help deliverables from single source, PDF, CHM, <a href=""http://help.eclipse.org/ganymede/index.jsp"" rel=""nofollow noreferrer"">Eclipse Help</a>, HTML.</li>
<li>Single source repository produces help for multiple products 10+ with thousands of shared topics.</li>
</ul>

<p>From what you describe I would look at Eclipse Help, its not simple to integrate into .NET or MFC applications, you basically have to do the help mapping to resolve the request to a URL then fire the URL to Eclipse Help wrapper or a browser.</p>
",2387.0,2219.0,3
1131,93232,False,"<p>I use a commercial package called AuthorIT that can generate a number of different formats, such as chm, html, pdf, word, windows help, xml, xhtml, and some others I have never heard of (does dita ring a bell?).
It is a content management system oriented towards the needs of technical documentation writers.
The advantage is that you can use and re-use the same content to build a set of guides, and then generate them in different formats.</p>

<p>So the bottom line relative to the question of choosing chm or html or whatever is that if you are using this you are not locked into a given format, but you can provide several among which the user can choose, and you can even add more formats as you go along, at no extra cost.</p>

<p>If you just have one guide to create it won't be worth your while, but if you have a documentation set to manage then it is the best to my knowledge. Their support is very helpful also.</p>
",,,1
1131,2701,False,"<blockquote>
  <p>PDF has the disadvantage of requiring the Adobe Reader</p>
</blockquote>

<p>I use <a href=""http://www.foxitsoftware.com/pdf/rd_intro.php"" rel=""nofollow noreferrer"">Foxit Reader</a> on Windows at home and at work. A lot smaller and very quick to open. Very handy when you are wondering what exactly a80000326.pdf is and why it is clogging up your documents folder.</p>
",342.0,15219.0,2
1131,1238,False,"<p>If you don't want to use an installer and you don't want the user to perform any extra steps to allow CHM files over the network, why not fall back to WinHelp?  Vista does not include WinHlp32.exe out of the box, but it is <a href=""http://support.microsoft.com/kb/917607"" rel=""nofollow noreferrer"">freely available as a download</a> for both Vista and Server 2008.</p>
",206.0,4489.0,3
1131,1175,False,"<p>If you are doing ""just extract and run"", you are going to run in security issues.  This is especially true if you are users are running Vista (or later).  is there a reason why you wanted to avoid packaging your applications inside an installer?  Using an installer would alleviate the ""external source"" problem.  You would be able to use .chm files without any problems.</p>

<p>We use <a href=""http://www.installaware.com"" rel=""nofollow noreferrer"">InstallAware</a> to create our install packages.  It's not cheap, but is very good.  If cost is your concern, <a href=""http://wix.sourceforge.net/"" rel=""nofollow noreferrer"">WIX</a> is open source and pretty robust.  WIX does have a learning curve, but it's easy to work with.</p>
",206.0,4489.0,2
1131,1141,False,"<p>Our software is both distributed locally to the clients and served from a network share. We opted for generating both a CHM file and a set of HTML files for serving from the network. Users starting the program locally use the CHM file, and users getting their program served from a network share has to use the HTML files.</p>

<p>We use <a href=""http://www.helpandmanual.com/"" rel=""nofollow noreferrer"">Help and Manual</a> and can thus easily produce both types of output from the same source project. The HTML files also contain searching capabilities and doesn't require a web server, so though it isn't an optimal solution, works fine.</p>

<p>So far all the single-file types for Windows seems broken in one way or another:</p>

<ul>
<li>WinHelp - obsoleted</li>
<li>HtmlHelp (CHM) - obsoleted on Vista, doesn't work from network share, other than that works really nice</li>
<li>Microsoft Help 2 (HXS) - this seems to work right up until the point when it doesn't, corrupted indexes or similar, this is used by Visual Studio 2005 and above, as an example</li>
</ul>
",267.0,348196.0,3
1131,1135,True,"<p>HTML would be the next best choice, ONLY IF you would serve them from a public web server. If you tried to bundle it with your app, all the files (and images (and stylesheets (and ...) ) ) would make CHM look like a gift from gods.</p>

<p>That said, when actually bundled in the installation package, (instead of being served over the network), I found the CHM files to work nicely.</p>

<p>OTOH, another pitfall about CHM files: Even if you try to open a CHM file on a <strong>local</strong> disk, you may bump into the security block if you initially downloaded it from somewhere, because the file could be marked as ""came from external source"" when it was obtained.</p>
",227.0,13526.0,14
1145,1154,True,"<p>As a general rule, you should <strong>never</strong> do a free or realloc on a user provided buffer. You don't know where the user allocated the space (in your module, in another DLL) so you cannot use any of the allocation functions on a user buffer.</p>

<p>Provided that you now cannot do any reallocation within your function, you should change its behavior a little, like doing only one replacement, so the user will be able to compute the resulting string max length and provide you with a buffer long enough for this one replacement to occur.</p>

<p>Then you could create another function to do the multiple replacements, but you will have to allocate the whole space for the resulting string and copy the user input string. Then you must provide a way to delete the string you allocated.</p>

<p>Resulting in:</p>

<pre><code>void  strrep(char *input, char *search, char *replace);
char* strrepm(char *input, char *search, char *replace);
void  strrepmfree(char *input);
</code></pre>
",268.0,33176.0,14
1145,220594,False,"<p>Someone else apologized for being late to the party - two and a half months ago.  Oh well, I spend quite a lot of time doing software archaeology.</p>

<p>I'm interested that no-one has commented explicitly on the memory leak in the original design, or the off-by-one error.  And it was observing the memory leak that tells me exactly why you are getting the double-free error (because, to be precise, you are freeing the same memory multiple times - and you are doing so after trampling over the already freed memory).</p>

<p>Before conducting the analysis, I'll agree with those who say your interface is less than stellar; however, if you dealt with the memory leak/trampling issues and documented the 'must be allocated memory' requirement, it could be 'OK'.</p>

<p>What are the problems?  Well, you pass a buffer to realloc(), and realloc() returns you a new pointer to the area you should use - and you ignore that return value.  Consequently, realloc() has probably freed the original memory, and then you pass it the same pointer again, and it complains that you're freeing the same memory twice because you pass the original value to it again.  This not only leaks memory, but means that you are continuing to use the original space -- and John Downey's shot in the dark points out that you are misusing realloc(), but doesn't emphasize how severely you are doing so.  There's also an off-by-one error because you do not allocate enough space for the NUL '\0' that terminates the string.</p>

<p>The memory leak occurs because you do not provide a mechanism to tell the caller about the last value of the string.  Because you kept trampling over the original string plus the space after it, it looks like the code worked, but if your calling code freed the space, it too would get a double-free error, or it might get a core dump or equivalent because the memory control information is completely scrambled.</p>

<p>Your code also doesn't protect against indefinite growth -- consider replacing 'Noel' with 'Joyeux Noel'.  Every time, you would add 7 characters, but you'd find another Noel in the replaced text, and expand it, and so on and so forth.  My fixup (below) does not address this issue - the simple solution is probably to check whether the search string appears in the replace string; an alternative is to skip over the replace string and continue the search after it.  The second has some non-trivial coding issues to address.</p>

<p>So, my suggested revision of your called function is:</p>

<pre><code>char *strrep(char *input, char *search, char *replace) {
    int searchLen = strlen(search);
    int replaceLen = strlen(replace);
    int delta = replaceLen - searchLen;
    char *find = input;

    while ((find = strstr(find, search)) != 0) {
        if (delta &gt; 0) {
            input = realloc(input, strlen(input) + delta + 1);
            find = strstr(input, search);            
        }

        memmove(find + replaceLen, find + searchLen, strlen(input) + 1 - (find - input));
        memmove(find, replace, replaceLen);
    }

    return(input);
}
</code></pre>

<p>This code does not detect memory allocation errors - and probably crashes (but if not, leaks memory) if realloc() fails.  See Steve Maguire's 'Writing Solid Code' book for an extensive discussion of memory management issues.</p>
",15168.0,663633.0,6
1145,6405,False,"<p>First off, sorry I'm late to the party. This is my first stackoverflow answer. :)</p>

<p>As has been pointed out, when realloc() is called, you can potentially change the pointer to the memory being reallocated. When this happens, the argument ""string"" becomes invalid. Even if you reassign it, the change goes out of scope once the function ends.</p>

<p>To answer the OP, realloc() returns a pointer to the newly-reallocated memory. The return value needs to be stored somewhere. Generally, you would do this:</p>

<pre><code>data *foo = malloc(SIZE * sizeof(data));
data *bar = realloc(foo, NEWSIZE * sizeof(data));

/* Test bar for safety before blowing away foo */
if (bar != NULL)
{
   foo = bar;
   bar = NULL;
}
else
{
   fprintf(stderr, ""Crap. Memory error.\n"");
   free(foo);
   exit(-1);
}
</code></pre>

<p>As TyBoer points out, you guys can't change the value of the pointer being passed in as the input to this function. You can assign whatever you want, but the change will go out of scope at the end of the function. In the following block, ""input"" may or may not be an invalid pointer once the function completes:</p>

<pre><code>void foobar(char *input, int newlength)
{
   /* Here, I ignore my own advice to save space. Check your return values! */
   input = realloc(input, newlength * sizeof(char));
}
</code></pre>

<p>Mark tries to work around this by returning the new pointer as the output of the function. If you do that, the onus is on the caller to never again use the pointer he used for input. If it matches the return value, then you have two pointers to the same spot and only need to call free() on one of them. If they don't match, the input pointer now points to memory that may or may not be owned by the process. Dereferencing it could cause a segmentation fault.</p>

<p>You could use a double pointer for the input, like this:</p>

<pre><code>void foobar(char **input, int newlength)
{
   *input = realloc(*input, newlength * sizeof(char));
}
</code></pre>

<p>If the caller has a duplicate of the input pointer somewhere, that duplicate still might be invalid now.</p>

<p>I think the cleanest solution here is to avoid using realloc() when trying to modify the function caller's input. Just malloc() a new buffer, return that, and let the caller decide whether or not to free the old text. This has the added benefit of letting the caller keep the original string!</p>
",773.0,780.0,11
1145,6024343,False,"<p>realloc is strange, complicated and should only be used when dealing with lots of memory lots of times per second. i.e. - where it actually makes your code faster. </p>

<p>I have seen code where </p>

<pre><code>realloc(bytes, smallerSize);
</code></pre>

<p>was used and worked to resize the buffer, making it smaller. Worked about a million times, then for some reason realloc decided that even if you were shortening the buffer, it would give you a nice new copy. So you crash in a random place 1/2 a second after the bad stuff happened. </p>

<p>Always use the return value of realloc. </p>
",69948.0,6758.0,3
1145,1163,False,"<p>This seems to work;</p>

<pre><code>char *strrep(char *string, const char *search, const char *replace) {
    char *p = strstr(string, search);

    if (p) {
        int occurrence = p - string;
        int stringlength = strlen(string);
        int searchlength = strlen(search);
        int replacelength = strlen(replace);

        if (replacelength &gt; searchlength) {
            string = (char *) realloc(string, strlen(string) 
                + replacelength - searchlength + 1);
        }

        if (replacelength != searchlength) {
            memmove(string + occurrence + replacelength, 
                        string + occurrence + searchlength, 
                        stringlength - occurrence - searchlength + 1);
        }

        strncpy(string + occurrence, replace, replacelength);
    }

    return string;
}
</code></pre>

<p>Sigh, is there anyway to post code without it sucking?</p>
",263.0,446.0,3
1145,1155,False,"<p>My quick hints.</p>

<p>Instead of:<br>
<code>void strrep(char *input, char *search, char *replace)</code><br>
try:<br>
<code>void strrep(char *&amp;input, char *search, char *replace)</code></p>

<p>and than in the body:<br>
<code>input = realloc(input, strlen(input) + delta);</code></p>

<p>Generally read about passing function arguments as values/reference and realloc() description :).</p>
",2090742.0,661.0,0
1145,1153,False,"<p><strong>Note, try to edit your code to get rid of the html escape codes.</strong></p>

<p>Well, though it has been a while since I used C/C++, realloc that grows only reuses the memory pointer value if there is room in memory after your original block.</p>

<p>For instance, consider this:</p>

<p>(xxxxxxxxxx..........)</p>

<p>If your pointer points to the first x, and . means free memory location, and you grow the memory size pointed to by your variable by 5 bytes, it'll succeed. This is of course a simplified example as blocks are rounded up to a certain size for alignment, but anyway.</p>

<p>However, if you subsequently try to grow it by another 10 bytes, and there is only 5 available, it will need to move the block in memory and update your pointer.</p>

<p>However, in your example you are passing the function a pointer to the character, not a pointer to your variable, and thus while the strrep function internally might be able to adjust the variable in use, it is a local variable to the strrep function and your calling code will be left with the original pointer variable value.</p>

<p>This pointer value, however, has been freed.</p>

<p>In your case, input is the culprit.</p>

<p>However, I would make another suggestion. In your case it looks like the <em>input</em> variable is indeed input, and if it is, it shouldn't be modified, at all.</p>

<p>I would thus try to find another way to do what you want to do, without changing <em>input</em>, as side-effects like this can be hard to track down.</p>
",267.0,348196.0,4
1145,1149,False,"<p>Just a shot in the dark because I haven't tried it yet but when you realloc it returns the pointer much like malloc. Because realloc can move the pointer if needed you are most likely operating on an invalid pointer if you don't do the following:</p>

<pre><code>input = realloc(input, strlen(input) + delta);
</code></pre>
",200.0,12856.0,6
1156,57400894,False,"<p>We can use following syntax to create index.</p>

<pre><code>CREATE INDEX &lt;index_name&gt; ON &lt;table_name&gt;(&lt;column_name&gt;)
</code></pre>

<p>If we do not want duplicate value to be allowed then we can add <strong>UNIQUE</strong> while creating index as follow </p>

<pre><code>CREATE UNIQUE INDEX &lt;index_name&gt; ON &lt;table_name&gt;(&lt;column_name&gt;)
</code></pre>

<p>We can create index on multiple column by giving multiple column name separated by '<strong>,</strong>'</p>
",2826658.0,59.0,0
1156,9853,False,"<p><code>Sql Server 2005</code> gives you the ability to specify a covering index.  This is an index that includes data from other columns at the leaf level, so you don't have to go back to the table to get columns that aren't included in the index keys.</p>

<pre><code>create nonclustered index my_idx on my_table (my_col1 asc, my_col2 asc) include (my_col3);
</code></pre>

<p>This is invaluable for a query that has <code>my_col3</code> in the select list, and <code>my_col1</code> and <code>my_col2</code> in the where clause.</p>
",1219.0,35398.0,7
1156,30597765,False,"<p>To create indexes following stuff can be used:</p>

<ol>
<li><p>Creates an index on a table. Duplicate values are allowed:
<code>CREATE INDEX index_name
ON table_name (column_name)</code></p></li>
<li><p>Creates a unique index on a table. Duplicate values are not allowed:
<code>CREATE UNIQUE INDEX index_name ON table_name (column_name)</code></p></li>
<li><p>Clustered Index: <code>CREATE CLUSTERED INDEX CL_ID ON SALES(ID);</code></p></li>
<li>Non-clustered index:<br>
<code>CREATE NONCLUSTERED INDEX NONCI_PC ON SALES(ProductCode);</code></li>
</ol>

<p>Refer: <a href=""http://www.codeproject.com/Articles/190263/Indexes-in-MS-SQL-Server"" rel=""nofollow noreferrer"">http://www.codeproject.com/Articles/190263/Indexes-in-MS-SQL-Server</a> for details.</p>
",4010493.0,41.0,2
1156,41695102,False,"<ol>
<li><p><code>CREATE INDEX name_index ON Employee (Employee_Name)</code></p></li>
<li><p>On a multi column: <code>CREATE INDEX name_index ON Employee (Employee_Name, Employee_Age)</code></p></li>
</ol>
",6920172.0,327.0,1
1156,50697793,False,"<p>An index is not always needed for all the databases. For eg: Kognitio aka WX2 engine doesn't offer a syntax for indexing as the database engine takes care of it implicitly. Data goes on via round-robin partitioning and Kognitio WX2 gets data on and off disk in the simplest possible way.</p>
",2772061.0,10095.0,0
1156,50649693,False,"<p>Since most of the answers are given for SQL databases, I am writing this for NOSQL databases, specifically for MongoDB.</p>

<p>Below is the syntax to create an index in the MongoDB using mongo shell.</p>

<pre><code>db.collection.createIndex( &lt;key and index type specification&gt;, &lt;options&gt; )
</code></pre>

<p>example - <code>db.collection.createIndex( { name: -1 } )</code></p>

<p>In the above example an single key descending index is created on the name 
field. </p>

<p>Keep in mind MongoDB indexes uses B-tree data structure.</p>

<p>There are multiple types of indexes we can create in mongodb, for more information refer to below link - <a href=""https://docs.mongodb.com/manual/indexes/"" rel=""nofollow noreferrer"">https://docs.mongodb.com/manual/indexes/</a></p>
",1269201.0,3263.0,0
1156,11055918,False,"<p>In SQL Server, you can do the following: (<a href=""http://msdn.microsoft.com/en-us/library/ms188783.aspx"" rel=""nofollow"">MSDN Link</a> to full list of options.)</p>

<pre><code>CREATE [ UNIQUE ] [ CLUSTERED | NONCLUSTERED ] INDEX index_name 
    ON &lt;object&gt; ( column [ ASC | DESC ] [ ,...n ] ) 
    [ INCLUDE ( column_name [ ,...n ] ) ]
    [ WHERE &lt;filter_predicate&gt; ]
</code></pre>

<p>(ignoring some more advanced options...)</p>

<p>The name of each Index must be unique database wide.</p>

<p>All indexes can have multiple columns, and each column can be ordered in whatever order you want.</p>

<p>Clustered indexes are unique - one per table. They can't have <code>INCLUDE</code>d columns.</p>

<p>Nonclustered indexes are not unique, and can have up to 999 per table. They can have included columns, and where clauses.</p>
",1132642.0,2455.0,4
1156,8973833,False,"<p>For python pytables, indexes don't have names and they are bound to single columns:</p>

<pre><code>tables.columns.column_name.createIndex()
</code></pre>
",1038264.0,7089.0,4
1156,1157,True,"<p>The following is SQL92 standard so should be supported by the majority of RDMBS that use SQL:</p>

<pre><code>CREATE INDEX [index name] ON [table name] ( [column name] )
</code></pre>
",200.0,12856.0,70
1160,1169,False,"<p>You have basically two options. Either you write a simple script that will start and parse output from</p>

<p><strong>svn.exe info --revision HEAD</strong></p>

<p>to obtain revision number (then generating AssemblyInfo.cs is pretty much straight forward) or just use plugin for CCNET. Here it is:</p>

<blockquote>
  <p><strong>SVN Revision Labeller</strong> is a plugin for
  CruiseControl.NET that allows you to
  generate CruiseControl labels for your
  builds, based upon the revision number
  of your Subversion working copy. This
  can be customised with a prefix and/or
  major/minor version numbers.</p>
  
  <p><a href=""http://code.google.com/p/svnrevisionlabeller/"" rel=""nofollow noreferrer"">http://code.google.com/p/svnrevisionlabeller/</a></p>
</blockquote>

<p>I prefer the first option because it's only roughly 20 lines of code:</p>

<pre><code>using System;
using System.Diagnostics;

namespace SvnRevisionNumberParserSample
{
    class Program
    {
        static void Main()
        {
            Process p = Process.Start(new ProcessStartInfo()
                {
                    FileName = @""C:\Program Files\SlikSvn\bin\svn.exe"", // path to your svn.exe
                    UseShellExecute = false,
                    RedirectStandardOutput = true,
                    Arguments = ""info --revision HEAD"",
                    WorkingDirectory = @""C:\MyProject"" // path to your svn working copy
                });

            // command ""svn.exe info --revision HEAD"" will produce a few lines of output
            p.WaitForExit();

            // our line starts with ""Revision: ""
            while (!p.StandardOutput.EndOfStream)
            {
                string line = p.StandardOutput.ReadLine();
                if (line.StartsWith(""Revision: ""))
                {
                    string revision = line.Substring(""Revision: "".Length);
                    Console.WriteLine(revision); // show revision number on screen                       
                    break;
                }
            }

            Console.Read();
        }
    }
}
</code></pre>
",275.0,23844.0,14
1160,12481921,False,"<p>No idea where I found this.  But I found this on the internet ""somewhere"".</p>

<p>This updates all the AssemblyInfo.cs files before the build takes place.</p>

<p>Works like a charm.  All my exe's and dll's show up as 1.2.3.333 (If ""333"" were the SVN revision at the time.) (And the original version in the AssemblyInfo.cs file was listed as ""1.2.3.0"")</p>

<hr>

<p>$(ProjectDir)   (Where my .sln file resides)</p>

<p>$(SVNToolPath)  (points to svn.exe)</p>

<p>are my custom variables, their declarations/definitions are not defined below.</p>

<hr>

<p><a href=""http://msbuildtasks.tigris.org/"" rel=""nofollow noreferrer"">http://msbuildtasks.tigris.org/</a>
and/or
<a href=""https://github.com/loresoft/msbuildtasks"" rel=""nofollow noreferrer"">https://github.com/loresoft/msbuildtasks</a>
has the ( FileUpdate and SvnVersion ) tasks.</p>

<hr>

<pre><code>  &lt;Target Name=""SubVersionBeforeBuildVersionTagItUp""&gt;

    &lt;ItemGroup&gt;
      &lt;AssemblyInfoFiles Include=""$(ProjectDir)\**\*AssemblyInfo.cs"" /&gt;
    &lt;/ItemGroup&gt;

    &lt;SvnVersion LocalPath=""$(MSBuildProjectDirectory)"" ToolPath=""$(SVNToolPath)""&gt;
      &lt;Output TaskParameter=""Revision"" PropertyName=""MySubVersionRevision"" /&gt;
    &lt;/SvnVersion&gt;

    &lt;FileUpdate Files=""@(AssemblyInfoFiles)""
            Regex=""(\d+)\.(\d+)\.(\d+)\.(\d+)""
            ReplacementText=""$1.$2.$3.$(MySubVersionRevision)"" /&gt;
  &lt;/Target&gt;
</code></pre>

<p>EDIT --------------------------------------------------</p>

<p>The above may start failing after your SVN revision number reaches 65534 or higher.</p>

<p>See:</p>

<p><a href=""https://stackoverflow.com/questions/13414409/turn-off-warning-cs1607/13751833#13751833"">Turn off warning CS1607</a></p>

<p>Here is the workaround.</p>

<pre><code>&lt;FileUpdate Files=""@(AssemblyInfoFiles)""
Regex=""AssemblyFileVersion\(&amp;quot;(\d+)\.(\d+)\.(\d+)\.(\d+)""
ReplacementText=""AssemblyFileVersion(&amp;quot;$1.$2.$3.$(SubVersionRevision)"" /&gt;
</code></pre>

<p>The result of this should be:</p>

<p>In Windows/Explorer//File/Properties…….</p>

<p>Assembly Version will be 1.0.0.0.  </p>

<p>File Version will be 1.0.0.333 if 333 is the SVN revision.</p>
",214977.0,21384.0,2
1160,1172,False,"<p>If you prefer doing it on the <code>MSBuild</code> side over the <code>CCNet</code> config, looks like the <code>MSBuild</code> Community Tasks extension's <a href=""http://msbuildtasks.tigris.org/"" rel=""nofollow noreferrer""><code>SvnVersion</code></a> task might do the trick.</p>
",266.0,29506.0,4
1160,1168,False,"<p>I found <a href=""http://code.google.com/p/svnrevisionlabeller"" rel=""nofollow noreferrer"">this</a> project on google code. This is <code>CCNET</code> plugin to generate the label in <code>CCNET</code>.</p>

<p>The <code>DLL</code> is tested with <code>CCNET 1.3</code> but it works with <code>CCNET 1.4</code> for me. I'm successfully using this plugin to label my build.</p>

<p>Now onto passing it to <code>MSBuild</code>...</p>
",120.0,1197.0,4
1160,975299,True,"<p>CruiseControl.Net 1.4.4 has now an <a href=""http://confluence.public.thoughtworks.org/display/CCNET/Assembly+Version+Labeller"" rel=""noreferrer"">Assembly Version Labeller</a>, which generates version numbers compatible with .Net assembly properties.</p>

<p>In my project I have it configured as:</p>

<pre><code>&lt;labeller type=""assemblyVersionLabeller"" incrementOnFailure=""true"" major=""1"" minor=""2""/&gt;
</code></pre>

<p>(Caveat: <code>assemblyVersionLabeller</code> won't start generating svn revision based labels until an actual commit-triggered build occurs.)</p>

<p>and then consume this from my MSBuild projects with <a href=""http://msbuildtasks.tigris.org/"" rel=""noreferrer"">MSBuildCommunityTasks.AssemblyInfo</a> :</p>

<pre><code>&lt;Import Project=""$(MSBuildExtensionsPath)\MSBuildCommunityTasks\MSBuild.Community.Tasks.Targets""/&gt;
&lt;Target Name=""BeforeBuild""&gt;
  &lt;AssemblyInfo Condition=""'$(CCNetLabel)' != ''"" CodeLanguage=""CS"" OutputFile=""Properties\AssemblyInfo.cs"" 
  AssemblyTitle=""MyTitle"" AssemblyCompany=""MyCompany"" AssemblyProduct=""MyProduct""
  AssemblyCopyright=""Copyright ©  2009"" ComVisible=""false"" Guid=""some-random-guid""
  AssemblyVersion=""$(CCNetLabel)"" AssemblyFileVersion=""$(CCNetLabel)""/&gt;
&lt;/Target&gt;
</code></pre>

<p>For sake of completness, it's just as easy for projects using NAnt instead of MSBuild:</p>

<pre><code>&lt;target name=""setversion"" description=""Sets the version number to CruiseControl.Net label.""&gt;
    &lt;script language=""C#""&gt;
        &lt;references&gt;
            &lt;include name=""System.dll"" /&gt;
        &lt;/references&gt;
        &lt;imports&gt;
            &lt;import namespace=""System.Text.RegularExpressions"" /&gt;
        &lt;/imports&gt;
        &lt;code&gt;&lt;![CDATA[
             [TaskName(""setversion-task"")]
             public class SetVersionTask : Task
             {
              protected override void ExecuteTask()
              {
               StreamReader reader = new StreamReader(Project.Properties[""filename""]);
               string contents = reader.ReadToEnd();
               reader.Close();
               string replacement = ""[assembly: AssemblyVersion(\"""" + Project.Properties[""CCNetLabel""] + ""\"")]"";
               string newText = Regex.Replace(contents, @""\[assembly: AssemblyVersion\("""".*""""\)\]"", replacement);
               StreamWriter writer = new StreamWriter(Project.Properties[""filename""], false);
               writer.Write(newText);
               writer.Close();
              }
             }
             ]]&gt;
        &lt;/code&gt;
    &lt;/script&gt;
    &lt;foreach item=""File"" property=""filename""&gt;
        &lt;in&gt;
            &lt;items basedir=""..""&gt;
                &lt;include name=""**\AssemblyInfo.cs""&gt;&lt;/include&gt;
            &lt;/items&gt;
        &lt;/in&gt;
        &lt;do&gt;
            &lt;setversion-task /&gt;
        &lt;/do&gt;
    &lt;/foreach&gt;
&lt;/target&gt;
</code></pre>
",3205.0,29328.0,45
1160,2619371,False,"<p>I'm not sure if this work with CCNET or not, but I've created an <a href=""http://happyturtle.codeplex.com/"" rel=""nofollow noreferrer"">SVN version plug-in</a> for the <a href=""http://autobuildversion.codeplex.com/"" rel=""nofollow noreferrer"">Build Version Increment</a> project on CodePlex.  This tool is pretty flexible and can be set to automatically create a version number for you using the svn revision.  It doesn't require writing any code or editing xml, so yay!</p>

<p>I hope this is helps!</p>
",74346.0,3045.0,3
1160,1414774,False,"<p>Based on skolimas solution I updated the NAnt script to also update the AssemblyFileVersion. Thanks to skolima for the code!</p>

<pre><code>&lt;target name=""setversion"" description=""Sets the version number to current label.""&gt;
        &lt;script language=""C#""&gt;
            &lt;references&gt;
                    &lt;include name=""System.dll"" /&gt;
            &lt;/references&gt;
            &lt;imports&gt;
                    &lt;import namespace=""System.Text.RegularExpressions"" /&gt;
            &lt;/imports&gt;
            &lt;code&gt;&lt;![CDATA[
                     [TaskName(""setversion-task"")]
                     public class SetVersionTask : Task
                     {
                      protected override void ExecuteTask()
                      {
                       StreamReader reader = new StreamReader(Project.Properties[""filename""]);
                       string contents = reader.ReadToEnd();
                       reader.Close();                     
                       // replace assembly version
                       string replacement = ""[assembly: AssemblyVersion(\"""" + Project.Properties[""label""] + ""\"")]"";
                       contents = Regex.Replace(contents, @""\[assembly: AssemblyVersion\("""".*""""\)\]"", replacement);                                        
                       // replace assembly file version
                       replacement = ""[assembly: AssemblyFileVersion(\"""" + Project.Properties[""label""] + ""\"")]"";
                       contents = Regex.Replace(contents, @""\[assembly: AssemblyFileVersion\("""".*""""\)\]"", replacement);                                        
                       StreamWriter writer = new StreamWriter(Project.Properties[""filename""], false);
                       writer.Write(contents);
                       writer.Close();
                      }
                     }
                     ]]&gt;
            &lt;/code&gt;
        &lt;/script&gt;
        &lt;foreach item=""File"" property=""filename""&gt;
            &lt;in&gt;
                    &lt;items basedir=""${srcDir}""&gt;
                            &lt;include name=""**\AssemblyInfo.cs""&gt;&lt;/include&gt;
                    &lt;/items&gt;
            &lt;/in&gt;
            &lt;do&gt;
                    &lt;setversion-task /&gt;
            &lt;/do&gt;
        &lt;/foreach&gt;
    &lt;/target&gt;
</code></pre>
",140607.0,1436.0,2
1160,508342,False,"<p>Be careful.  The structure used for build numbers is only a short so you have a ceiling on how high your revision can go.</p>

<p>In our case, we've already exceeded the limit.</p>

<p>If you attempt to put in the build number 99.99.99.599999, the file version property will actually come out as 99.99.99.10175.</p>
",54852.0,356.0,1
1160,505990,False,"<p>My approach is to use the aforementioned plugin for ccnet and a nant echo task to generate a <code>VersionInfo.cs</code> file containing nothing but the version attributes. I only have to include the <code>VersionInfo.cs</code> file into the build</p>

<p>The echo task simply outputs the string I give it to a file.</p>

<p>If there is a similar MSBuild task, you can use the same approach. Here's the small nant task I use:</p>

<pre><code>&lt;target name=""version"" description=""outputs version number to VersionInfo.cs""&gt;
  &lt;echo file=""${projectdir}/Properties/VersionInfo.cs""&gt;
    [assembly: System.Reflection.AssemblyVersion(""$(CCNetLabel)"")]
    [assembly: System.Reflection.AssemblyFileVersion(""$(CCNetLabel)"")]
  &lt;/echo&gt;
&lt;/target&gt;
</code></pre>

<p>Try this:</p>

<pre><code>&lt;ItemGroup&gt;
    &lt;VersionInfoFile Include=""VersionInfo.cs""/&gt;
    &lt;VersionAttributes&gt;
        [assembly: System.Reflection.AssemblyVersion(""${CCNetLabel}"")]
        [assembly: System.Reflection.AssemblyFileVersion(""${CCNetLabel}"")]
    &lt;/VersionAttributes&gt;
&lt;/ItemGroup&gt;
&lt;Target Name=""WriteToFile""&gt;
    &lt;WriteLinesToFile
        File=""@(VersionInfoFile)""
        Lines=""@(VersionAttributes)""
        Overwrite=""true""/&gt;
&lt;/Target&gt;
</code></pre>

<p>Please note that I'm not very intimate with MSBuild, so my script will probably not work out-of-the-box and need corrections...</p>
",46642.0,208828.0,2
1160,1235,False,"<p>I have written a NAnt build file that handles parsing SVN information and creating properties. I then use those property values for a variety of build tasks, including setting the label on the build. I use this target combined with the SVN Revision Labeller mentioned by lubos hasko with great results.</p>

<pre><code>&lt;target name=""svninfo"" description=""get the svn checkout information""&gt;
    &lt;property name=""svn.infotempfile"" value=""${build.directory}\svninfo.txt"" /&gt;
    &lt;exec program=""${svn.executable}"" output=""${svn.infotempfile}""&gt;
        &lt;arg value=""info"" /&gt;
    &lt;/exec&gt;
    &lt;loadfile file=""${svn.infotempfile}"" property=""svn.info"" /&gt;
    &lt;delete file=""${svn.infotempfile}"" /&gt;

    &lt;property name=""match"" value="""" /&gt;

    &lt;regex pattern=""URL: (?'match'.*)"" input=""${svn.info}"" /&gt;
    &lt;property name=""svn.info.url"" value=""${match}""/&gt;

    &lt;regex pattern=""Repository Root: (?'match'.*)"" input=""${svn.info}"" /&gt;
    &lt;property name=""svn.info.repositoryroot"" value=""${match}""/&gt;

    &lt;regex pattern=""Revision: (?'match'\d+)"" input=""${svn.info}"" /&gt;
    &lt;property name=""svn.info.revision"" value=""${match}""/&gt;

    &lt;regex pattern=""Last Changed Author: (?'match'\w+)"" input=""${svn.info}"" /&gt;
    &lt;property name=""svn.info.lastchangedauthor"" value=""${match}""/&gt;

    &lt;echo message=""URL: ${svn.info.url}"" /&gt;
    &lt;echo message=""Repository Root: ${svn.info.repositoryroot}"" /&gt;
    &lt;echo message=""Revision: ${svn.info.revision}"" /&gt;
    &lt;echo message=""Last Changed Author: ${svn.info.lastchangedauthor}"" /&gt;
&lt;/target&gt;
</code></pre>
",173.0,859.0,4
1160,1216,False,"<blockquote>
  <p><strong>Customizing csproj files to autogenerate AssemblyInfo.cs</strong><br>
  <a href=""http://www.codeproject.com/KB/dotnet/Customizing_csproj_files.aspx"" rel=""nofollow noreferrer"">http://www.codeproject.com/KB/dotnet/Customizing_csproj_files.aspx</a></p>
  
  <p>Every time we create a new C# project,
  Visual Studio puts there the
  AssemblyInfo.cs file for us. The file
  defines the assembly meta-data like
  its version, configuration, or
  producer.</p>
</blockquote>

<p>Found the above technique to auto-gen AssemblyInfo.cs using MSBuild. Will post sample shortly.</p>
",120.0,1197.0,3
1160,1164,False,"<p>I am currently ""manually"" doing it through a prebuild-exec Task, using my <a href=""http://www.stum.de/various-tools/cmdtools/"" rel=""nofollow noreferrer"">cmdnetsvnrev</a> tool, but if someone knows a better ccnet-integrated way of doing it, i'd be happy to hear :-)</p>
",91.0,166977.0,3
1171,34850877,False,"<p>No doubt NetworkX is the best data structure till now for graph. It comes with utilities like Helper Functions, Data Structures and Algorithms, Random Sequence Generators, Decorators, Cuthill-Mckee Ordering, Context Managers</p>

<p>NetworkX is great because it wowrs for graphs, digraphs, and multigraphs. It can write graph with multiple ways: Adjacency List, Multiline Adjacency List,
Edge List, GEXF, GML. It works with Pickle, GraphML, JSON, SparseGraph6 etc. </p>

<p>It has implimentation of various radimade algorithms including:
Approximation, Bipartite, Boundary, Centrality, Clique, Clustering,    Coloring, Components, Connectivity, Cycles,  Directed Acyclic Graphs,
Distance Measures,  Dominating Sets, Eulerian, Isomorphism,  Link Analysis,  Link Prediction, Matching, Minimum Spanning Tree, Rich Club, Shortest Paths, Traversal, Tree.</p>
",2639344.0,408.0,1
1171,28705,True,"<p>I would strongly advocate you look at <a href=""http://networkx.github.com/"" rel=""noreferrer"">NetworkX</a>. It's a battle-tested war horse and the first tool most 'research' types reach for when they need to do analysis of network based data. I have manipulated graphs with 100s of thousands of edges without problem on a notebook. Its feature rich and very easy to use. You will find yourself focusing more on the problem at hand rather than the details in the underlying implementation.</p>

<p><strong>Example of <a href=""http://en.wikipedia.org/wiki/Erd%C5%91s%E2%80%93R%C3%A9nyi_model"" rel=""noreferrer"">Erdős-Rényi</a> random graph generation and analysis</strong></p>

<pre><code>
""""""
Create an G{n,m} random graph with n nodes and m edges
and report some properties.

This graph is sometimes called the Erd##[m~Qs-Rényi graph
but is different from G{n,p} or binomial_graph which is also
sometimes called the Erd##[m~Qs-Rényi graph.
""""""
__author__ = """"""Aric Hagberg (hagberg@lanl.gov)""""""
__credits__ = """"""""""""
#    Copyright (C) 2004-2006 by 
#    Aric Hagberg 
#    Dan Schult 
#    Pieter Swart 
#    Distributed under the terms of the GNU Lesser General Public License
#    http://www.gnu.org/copyleft/lesser.html

from networkx import *
import sys

n=10 # 10 nodes
m=20 # 20 edges

G=gnm_random_graph(n,m)

# some properties
print ""node degree clustering""
for v in nodes(G):
    print v,degree(G,v),clustering(G,v)

# print the adjacency list to terminal 
write_adjlist(G,sys.stdout)
</code></pre>

<p>Visualizations are also straightforward:</p>

<p><img src=""https://i.stack.imgur.com/5biM9.jpg"" alt=""enter image description here""></p>

<p>More visualization: <a href=""http://jonschull.blogspot.com/2008/08/graph-visualization.html"" rel=""noreferrer"">http://jonschull.blogspot.com/2008/08/graph-visualization.html</a></p>
",620.0,4827.0,52
1171,4292022,False,"<p>Even though this question is now quite old, I think it is worthwhile to mention my own python module for graph manipulation called <a href=""http://graph-tool.skewed.de"" rel=""noreferrer"">graph-tool</a>. It is very efficient, since the data structures and algorithms are implemented in C++, with template metaprograming, using the Boost Graph Library. Therefore its performance (both in memory usage and runtime) is comparable to a pure C++ library, and can be orders of magnitude better than typical python code, without sacrificing ease of use. I use it myself constantly to work with very large graphs.</p>
",180962.0,4525.0,13
1171,29836,False,"<p>As already mentioned, NetworkX is very good, with another option being <a href=""http://cneurocvs.rmki.kfki.hu/igraph/"" rel=""noreferrer"">igraph</a>. Both modules will have most (if not all) the analysis tools you're likely to need, and both libraries are routinely used with large networks.</p>
",2963.0,4950.0,6
1171,3107,False,"<p>As I understand it, random access is in constant time for both Python's dicts and lists, the difference is that you can only do random access of integer indexes with lists.  I'm assuming that you need to lookup a node by its label, so you want a dict of dicts.</p>

<p>However, on the performance front, loading it into memory may not be a problem, but if you use too much you'll end up swapping to disk, which will kill the performance of even Python's highly efficient dicts.  Try to keep memory usage down as much as possible.  Also, RAM is amazingly cheap right now; if you do this kind of thing a lot, there's no reason not to have at least 4GB.</p>

<p>If you'd like advice on keeping memory usage down, give some more information about the kind of information you're tracking for each node.</p>
",101.0,42113.0,3
1171,1191,False,"<p>Making a class-based structure would probably have more overhead than the dict-based structure, since in python classes actually use dicts when they are implemented.</p>
",188.0,32164.0,2
1171,1174,False,"<p>A dictionary may also contain overhead, depending on the actual implementation. A hashtable usually contain some prime number of available nodes to begin with, even though you might only use a couple of the nodes.</p>

<p>Judging by your example, ""Property"", would you be better of with a class approach for the final level and real properties? Or is the names of the properties changing a lot from node to node?</p>

<p>I'd say that what ""efficient"" means depends on a lot of things, like:</p>

<ul>
<li>speed of updates (insert, update, delete)</li>
<li>speed of random access retrieval</li>
<li>speed of sequential retrieval</li>
<li>memory used</li>
</ul>

<p>I think that you'll find that a data structure that is speedy will generally consume more memory than one that is slow. This isn't always the case, but most data structures seems to follow this.</p>

<p>A dictionary might be easy to use, and give you relatively uniformly fast access, it will most likely use more memory than, as you suggest, lists. Lists, however, generally tend to contain more overhead when you insert data into it, unless they preallocate X nodes, in which they will again use more memory.</p>

<p>My suggestion, in general, would be to just use the method that seems the most natural to you, and then do a ""stress test"" of the system, adding a substantial amount of data to it and see if it becomes a problem.</p>

<p>You might also consider adding a layer of abstraction to your system, so that you don't have to change the programming interface if you later on need to change the internal data structure.</p>
",267.0,348196.0,4
1176,1703,False,"<p>The active projects on <a href=""http://rubyforge.org/top/mostactive.php?type=week"" rel=""nofollow noreferrer"">Rubyforge</a> are a great place to start.  What would be a good starter project is to pick one that is pretty popular but not a lot of developers.</p>

<p>If you are interested in Ruby on Rails, I'm working on <a href=""http://www.redmine.org"" rel=""nofollow noreferrer"">Redmine</a> right now.  It's been one of the most active projects and only has 5 developers.  <a href=""http://www.opensourcerails.com/"" rel=""nofollow noreferrer"">Open Source Rails</a> also has a good collection of projects.</p>

<p>I've found doing a <a href=""http://thinkrelevance.com/blog/2008/05/23/refactotum-overview"" rel=""nofollow noreferrer"">Refactotum</a> a great way to get started on a project.  Use the fact that you are new to your advantage, most people who have been on a project forget about simple things like gem dependencies and documentation</p>
",183.0,1837.0,11
1176,3531,False,"<p>Look around on <a href=""https://github.com"" rel=""nofollow noreferrer"">github</a> for some open source projects.  Some of the more popular projects are:</p>

<ul>
<li><a href=""https://github.com/rails/rails"" rel=""nofollow noreferrer"">Rails</a></li>
<li><a href=""https://github.com/wycats/merb"" rel=""nofollow noreferrer"">Merb</a></li>
<li><a href=""https://github.com/rubinius/rubinius"" rel=""nofollow noreferrer"">Rubinius</a></li>
</ul>

<p>Look on the <a href=""https://github.com/popular/forked"" rel=""nofollow noreferrer"">Popular Forked</a> list and you'll probably see something that interests you.</p>
",529.0,588.0,6
1176,1186,True,"<p>Well, you didn't specify Rails, so I'm going to throw <a href=""https://github.com/shoes/shoes"" rel=""noreferrer"">Shoes</a> out there. First, building shoes apps is probably the best way to learn Ruby (Rails is great, but I find mastering Ruby far more fun/useful). Secondly, while I certainly don't think building crossplatform UI components is trivial, shoes is relatively new, and relatively small. There are no doubt countless additions that could be made.</p>
",34.0,20440.0,19
1176,1184112,False,"<p>How about writing little games? Grab yourself a <a href=""http://rubygame.org/"" rel=""nofollow noreferrer"">RubyGame</a> and start by making some simple games. Make a tetris, a snake, something really simple. It is a lot of fun, and you will learn a lot of little basic things about the language.</p>
",141147.0,2073.0,2
1176,12296,False,"<p>Instead of joining an open source project, find an itch you want to scratch.</p>

<p>I find my first year with a language is almost always throw away code (or at least, it <em>should</em> be).</p>

<p>Find a problem you (personally) want to solve. Use ruby to do it. You'll learn a lot.</p>
",175.0,2701.0,8
1176,1430,False,"<p>I think if you are attempting to learn a new language do something fun in that language.</p>

<p>I learned python by writing lots of web spiders and little toys and for ruby I'd take exactly the same path.  Instead of finding a project that needs input do a couple of little personal projects to get a feel for the language.  You learn more by doing something then by reading lots of examples and other peoples code in those first few months.</p>

<p>A language like Ruby is structured in such a way you can do something productive straight out of the box without much support so jump right in and do something fun rather than think you have to do something for somebody else right at the beginning of your experimentation with a new language.</p>

<p>have fun with Ruby, it's on my short list of things to play with :)</p>
",269.0,18803.0,6
1180,1232,True,"<p>The way we do this is to have a 'catch all' for our domain name registered in DNS so that anything.ourdomain.com will point to our server.</p>

<p>With Apache you can set up a similar catch-all for your vhosts.  The ServerName must be a single static name but the ServerAlias directive can contain a pattern.</p>

<pre><code>Servername www.ourdomain.com
ServerAlias *.ourdomain.com
</code></pre>

<p>Now all of the domains will trigger the vhost for our project.  The final part is to decode the domain name actually used so that you can work out the username in your code, something like (PHP):</p>

<pre><code>list( $username ) = explode( ""."", $_SERVER[ ""HTTP_HOST"" ] );
</code></pre>

<p>or a RewriteRule as already suggested that silently maps user.ourdomain.com/foo/bar to www.ourdomain.com/foo/bar?user=user or whatever you prefer.</p>
",48.0,6386.0,14
1180,1555232,False,"<p>I was looking to do something similar (<code>www.mysite.com/SomeUser</code>).</p>

<p>What I did was I edited <code>404.shtml</code> to include this server side include (SSI) code:</p>

<pre><code>&lt;!--#include virtual=""404.php"" -- &gt;
</code></pre>

<p>Then I created the file <code>404.php</code>, where I parsed the URL to check for a user's name and showed their info from the database.</p>
",188511.0,1.0,0
1180,1187,False,"<p><strong>Don't worry about DNS and URL rewriting</strong></p>

<p>Your DNS record will be static, something like:</p>

<pre><code>*.YOURDOMAIN.COM A 123.123.123.123
</code></pre>

<p>Ask your DNS provider to do it for you (if it's not done already) or do it by yourself if you have control over your DNS records. This will automatically point all your subdomains (current and future ones) into the same HTTP server.</p>

<p>Once it's done, you will only need to parse HOST header on every single http request to detect what hostname was used to access your server-side scripts on your http server.</p>

<p>Assuming you're using ASP.NET, this is kind of silly example I came up with but works and demonstrates simplicity of this approach:</p>

<pre><code>&lt;%@ Language=""C#"" %&gt;
&lt;%
string subDomain = Request.Url.Host.Split('.')[0].ToUpper();
if (subDomain == ""CLIENTXXX"") Response.Write(""Hello CLIENTXXX, your secret number is 33"");
else if (subDomain == ""CLIENTYYY"") Response.Write(""Hello CLIENTYYY, your secret number is 44"");
else Response.Write(subDomain+"" doesn't exist"");
%&gt;
</code></pre>
",275.0,23844.0,8
1180,1185,False,"<p>The trick to that is to use URL rewriting so that <strong>name.domain.com</strong> transparently maps to something like <strong>domain.com/users/name</strong> on your server.  Once you start down that path, it's fairly trivial to implement.</p>
",60.0,56986.0,2
1189,1236,False,"<p>While I second the Channel 9 solution, also be aware that in some hosted environments Safari is not considered an up-level browser. You may need to add it to your application's browscap in order to make use of some ASP.Net features. </p>

<p>That was the root cause of some headaches we had for a client's site that used the ASP Menu control.</p>
",149.0,15905.0,5
1189,1202,False,"<p>My first port of call would be to go through the elements on the page and see which controls:</p>

<ol>
<li>Will still work when I switch ViewState off</li>
<li>Can be moved out of the page and into an AJAX call to be loaded when required</li>
</ol>

<p>Failing that, and here's the disclaimer - I've never used this solution on a web-facing site - but in the past where I've wanted to eliminate massive ViewStates in limited-audience applications I have stored the ViewState in the Session.</p>

<p>It has worked for me because the hit to memory isn't significant for the number of users, but if you're running a fairly popular site I wouldn't recommend this approach.  However, if the Session solution works for Safari you could always detect the user agent and fudge appropriately.</p>
",192.0,70350.0,3
1189,1190,True,"<p>I've been doing a little research into this and whilst I'm not entirely sure its the cause I believe it is because Safari is not returning the full result set (hence cropping it).</p>

<p>I have been in dicussion with another developer and found the following post on Channel 9 as well which recommends making use of the SQL State service to store the viewstate avoiding the postback issue and also page size.</p>

<p><a href=""http://channel9.msdn.com/forums/TechOff/250549-ASPNET-ViewState-flawed-architecture/?CommentID=270477#263702"" rel=""nofollow noreferrer"">http://channel9.msdn.com/forums/TechOff/250549-ASPNET-ViewState-flawed-architecture/?CommentID=270477#263702</a></p>

<p>Does this seem like the best solution?</p>
",258.0,5864.0,2
1237,1240,False,"<pre><code>\[start\](.*?)\[end\]
</code></pre>

<p>Zhich'll put the text in the middle within a capture.</p>
",34.0,20440.0,63
1237,1243,True,"<pre><code>\[start\]\s*(((?!\[start\]|\[end\]).)+)\s*\[end\]
</code></pre>

<p>This should hopefully drop the <code>[start]</code> and <code>[end]</code> markers as well.</p>
",264.0,76235.0,23
1237,25803893,False,"<p>Reading the text with in the square brackets [] i.e.[Start] and [End] and validate the array with a list of values. <b><em>jsfiddle</em></b> <a href=""http://jsfiddle.net/muralinarisetty/r4s4wxj4/1/"" rel=""nofollow"">http://jsfiddle.net/muralinarisetty/r4s4wxj4/1/</a></p>

<pre><code>var mergeFields = [""[sitename]"",
                   ""[daystoholdquote]"",
                   ""[expires]"",
                   ""[firstname]"",
                   ""[lastname]"",
                   ""[sitephonenumber]"",
                   ""[hoh_firstname]"",
                   ""[hoh_lastname]""];       

var str = ""fee [sitename] [firstname] \
sdfasd [lastname] "";
var res = validateMeargeFileds(str);
console.log(res);

function validateMeargeFileds(input) {
    var re = /\[\w+]/ig;
    var isValid;
    var myArray = input.match(re);

    try{
        if (myArray.length &gt; 0) {
            myArray.forEach(function (field) {

                isValid = isMergeField(field);

                if (!isValid){
                   throw e;                        
                }
            });
        }
    }
    catch(e) {        
    }

    return isValid;
}

function isMergeField(mergefield) {
    return mergeFields.indexOf(mergefield.toLowerCase()) &gt; -1;
}
</code></pre>
",4033971.0,1.0,0
1237,18498275,False,"<p>Refer to this question to pull out text between tags with space characters and dots (<code>.</code>)</p>

<p><code>[\S\s]</code> is the one I used </p>

<p><a href=""https://stackoverflow.com/questions/8303488/regex-to-match-any-character-including-new-lines"">Regex to match any character including new lines</a></p>
",1713298.0,541.0,0
1237,12761781,False,"<pre><code>$text =""Data Data Data start Data i want end Data"";
($content) = $text =~ m/ start (.*) end /;
print $content;
</code></pre>

<p>I had a similar problem for a while &amp; I can tell you this method works...</p>
",1725440.0,59.0,5
1237,849859,False,"<p>Well, if you guarantee that each start tag is followed by an end tag then the following would work.</p>

<pre><code>\[start\](.*?)\[end\]
</code></pre>

<p>However, If you have  complex text such as the follwoing:</p>

<pre><code>[start] sometext [start] sometext2 [end] sometext [end]
</code></pre>

<p>then you would run into problems with regex.</p>

<p>Now the following example will pull out all the hot links in a page:</p>

<pre><code>'/&lt;a(.*?)a&gt;/i'
</code></pre>

<p>In the above case we can guarantee that there would not be any nested cases of:</p>

<pre><code>'&lt;a&gt;&lt;/a&gt;'
</code></pre>

<p>So, this is a complex question and can't just be solved with a simple answer.</p>
",103734.0,15164.0,3
1237,1252,False,"<p>With Perl you can surround the data you want with ()'s and pull it out later, perhaps other languages have a similar feature.</p>

<pre><code>if ($s_output =~ /(data data data data START(data data data)END (data data)/) 
{
    $dataAllOfIt = $1;      # 1 full string
    $dataInMiddle = $2;     # 2 Middle Data
    $dataAtEnd = $3;        # 3 End Data
}
</code></pre>
",30.0,11407.0,1
1237,63313,False,"<p>While you can use a regular expression to parse the data between opening and closing tags, you need to think long and hard as to whether this is a path you want to go down.  The reason for it is the potential of tags to nest: if nesting tags could ever happen or may ever happen, the language is said to no longer be regular, and regular expressions cease to be the proper tool for parsing it.</p>

<p>Many regular expression implementations, such as PCRE or perl's regular expressions, support backtracking which can be used to achieve this rough effect.  But PCRE (unlike perl) doesn't support unlimited backtracking, and this can actually cause things to break in weird ways as soon as you have too many tags.  </p>

<p>There's a very commonly cited blog post that discusses this more, <a href=""http://kore-nordmann.de/blog/do_NOT_parse_using_regexp.html"" rel=""nofollow noreferrer"">http://kore-nordmann.de/blog/do_NOT_parse_using_regexp.html</a>  (google for it and check the cache currently, they seem to be having some downtime)</p>
",7548.0,15547.0,4
1237,18612,False,"<p>A more complete discussion of the pitfalls of using a regex to find matching tags can be found at: <a href=""http://faq.perl.org/perlfaq4.html#How_do_I_find_matchi"" rel=""noreferrer"">http://faq.perl.org/perlfaq4.html#How_do_I_find_matchi</a>.  In particular, be aware that nesting tags really need a full-fledged parser in order to be interpreted correctly.</p>

<p>Note that case sensitivity will need to be turned off in order to answer the question as stated.  In perl, that's the <strong>i</strong> modifier:</p>

<pre><code>$ echo ""Data Data Data [Start] Data i want [End] Data"" \
  | perl -ne '/\[start\](.*?)\[end\]/i; print ""$1\n""'
 Data i want 
</code></pre>

<p>The other trick is to use the <strong>*?</strong> quantifier which turns off the greediness of the captured match.  For instance, if you have a non-matching <strong>[end]</strong> tag:</p>

<pre><code>Data Data [Start] Data i want [End] Data [end]
</code></pre>

<p>you probably don't want to capture:</p>

<pre><code> Data i want [End] Data
</code></pre>
",1438.0,19444.0,4
1241,13639,False,"<p>Using asynchronous communication is totally possible in single thread! </p>

<p>There is a common design pattern in network software development called the reactor pattern (<a href=""http://www.amazon.fr/Pattern-Oriented-Software-Architecture-Concurrent-Networked/dp/0471606952/ref=sr_1_9?ie=UTF8&amp;s=english-books&amp;qid=1218980593&amp;sr=1-9"" rel=""noreferrer"">look at this book</a>). Some well known network library provides an implementation of this pattern (<a href=""http://www.cs.wustl.edu/~schmidt/ACE.html"" rel=""noreferrer"">look at ACE</a>).</p>

<p>Briefly, the reactor is an object, you register all your sockets inside, and you wait for something. If something happened (new data arrived, connection close...) the reactor will notify you. And of course, you can use only one socket to send and received data asynchronously.</p>
",1578.0,13558.0,7
1241,7650,False,"<p>Check out <a href=""http://tenermerx.com/Asio/"" rel=""nofollow noreferrer"">asio</a>. It is a cross compatable c++ library for asyncronous IO. I am not sure if this would be useful for the server ( I have never tried to link a standard c++ DLL to a c# project) but for the client it would be useful.</p>

<p>We use it with our application, and it solved most of our IO concurrency problems.</p>
",716.0,6421.0,3
1241,1934,False,"<p>I'm not clear on whether or not you're wanting to add the asynchronous bits to the server in C# or the client in C++.</p>

<p>If you're talking about doing this in C++, desktop Windows platforms can do socket I/O asynchronously through the API's that use overlapped I/O.  For sockets, WSASend, WSARecv both allow async I/O (read the documentation on their LPOVERLAPPED parameters, which you can populate with events that get set when the I/O completes).</p>

<p>I don't know if Windows Mobile platforms support these functions, so you might have to do some additional digging.</p>
",328.0,2394.0,3
1241,1275,True,"<p>When I needed to write an application with a client-server model where the clients could leave and enter whenever they want, (I assume that's also the case for your application as you use mobile devices) I made sure that the clients send an <em>online</em> message to the server, indicating they were connected and ready to do whatever they needed doing.</p>

<p>at that time the server could send messages back to the client trough the same open connection.</p>

<p>Also, but I don't know if that is applicable for you, I had some sort of <em>heartbeat</em> the clients sent to the server, letting it know it was still online. That way the server knows when a client was forcibly disconnected from the network and it could mark that client back as offline.</p>
",46.0,17306.0,8
1261,1272,True,"<p>CVS only tracks modification on a file-by-file basis, while SVN tracks a whole commit as a new revision, which means that it is easier to follow the history of your project. Add the fact that all modern source control software use the concept of revision so it is far easier to migrate from SVN than it is from CVS.</p>
<p>There is also the atomic commit problem. While I only encountered it once, it is possible that 2 people committing together in CVS can conflict each other, losing some data and putting your client in an inconsistent state. When detected early, these problems are not major because your data is still out there somewhere, but it can be a pain in a stressful environment.</p>
<p>And finally, not many tools are developed around CVS anymore. While the new and shiny-new tools like Git or Mercurial definitely lack tools yet, SVN has a pretty large application base on any system.</p>
<p><strong>EDIT 2020</strong>: Seriously, this answer is 12 years old now. Forget SVN, go use Git like everyone else!</p>
",268.0,33176.0,62
1261,51375418,False,"<p>CVS (Concurrent Versions System) and SVN (SubVersioN) are two version control file systems that are popularly used by teams who are collaborating on a single project. These systems allow the collaborators to keep track of the changes that are made and know who is developing which and whether a branch should be applied to the main trunk or not. CVS is the much older of the two and it has been the standard collaboration tool for a lot of people. SVN is much newer and it introduces a lot of improvements to address the demands of most people.</p>
",9993935.0,1152.0,1
1261,39558442,False,"<p>Well, a few things which i feel makes svn awesome.</p>

<ol>
<li>The SVN-Altassian crucible combination is a far superior method of reviews and quality checks</li>
<li>Better management of conflicts and merges</li>
<li>It's obviously faster for taking checkouts, performing commits, etc.</li>
<li>The atomic commit problem - It is possible that 2 people committing together in CVS can conflict each other, losing some data and putting your code base in an inconsistent state </li>
</ol>

<p>Migration can easily be done in a few hours using cvs2svn.</p>
",6845541.0,11.0,0
1261,183612,False,"<p>you might also choose to migrate only the latest code from CVS into SVN and freeze your current CVS repo. this will make migration easier and you might also build your legacy releases in the old CVS repo.</p>
",7229.0,1104.0,0
1261,44289,False,"<p>As someone who is in the middle of switching between CVS and SVN (initially we switched all of our projects with cvs2svn and then decided that we would transition by only using svn on new projects), here are some of the problems we have had.</p>

<ul>
<li>Merging and branching are very different, and if you branch and merge frequently, unless you have SVN 1.5 running on your server have to know when you branched (this isn't very clear in the Tortoise SVN dialogs).  Michael says the branching and merging is intuitive, I would argue that after using CVS for 10 years, it is not.</li>
<li>If your are running the SVN server on Linux, it may be hard to get your SA to move to svn 1.5, as the default install 1.4.x.</li>
<li>Merging conflicts is not nearly as easy or as clear (at least to me and my co-workers) in TortoiseSVN as it is in TortoiseCVS.  The three pane approach takes some getting used to and the WinMerge (my preferred merge tool) doesn't do a three pane merge.</li>
<li>Beware: many of the online tutorials and magazine articles I have read obviously don't branch and merge, you should set up your main repository as <a href=""https://svn.yoursvnserver.com/repos/YourProject/Trunk"" rel=""nofollow noreferrer"">https://svn.yoursvnserver.com/repos/YourProject/Trunk</a> and branches on <a href=""https://svn.yoursvnserver.com/repos/YourProject/Branches/BranchX"" rel=""nofollow noreferrer"">https://svn.yoursvnserver.com/repos/YourProject/Branches/BranchX</a> .  You can clean up if you start your repos in the wrong place, but it leads to confusion.</li>
</ul>
",3798.0,32335.0,2
1261,14952,False,"<p>One thing not to overlook is ecosystem. I was working at a CVSNT shop, and I was finding more and more open source tools supported SubVersion by default.</p>
",175.0,2701.0,4
1261,14919,False,"<p>I'll second Eridius' suggestion of Git, but I'd expand it to the other DRCS (Distributed Revision Control System) such as <a href=""http://www.selenic.com/mercurial/wiki/"" rel=""nofollow noreferrer"">Mercurial</a> and <a href=""http://bazaar-vcs.org/"" rel=""nofollow noreferrer"">bazaar</a>.</p>

<p>These products are fairly recent and the level of tooling and integration with them seems low at the moment (based on my initial research).  I'd say they were best suited to the power-developers out there (and on here ;-)).</p>

<p>On the other hand, what <strong>doesn't</strong> CVS currently do for you?  From your initial question, you don't really have any, ""CVS sucks at this, what could I use instead?""</p>

<p>You've gotta weigh up the costs of any potential migration against the benefits.  For an existing project, I think that it would be hard to justify.</p>
",1809.0,301.0,4
1261,14860,False,"<p>btw: CVSNT supports atomic commits</p>
",259.0,42994.0,2
1261,4102,False,"<p>You should take a look at <a href=""http://git-scm.com"" rel=""nofollow noreferrer"">Git</a> instead of SVN. It's a DVCS that's blazing-fast and very powerful. It's not as user-friendly as SVN, but it's improving in that regard, and it's not <em>that</em> hard to learn.</p>
",582.0,168655.0,1
1261,1278,False,"<p>SVN has 3 main advantages over CVS</p>

<ul>
<li>it's faster</li>
<li>supports versioning of binary files</li>
<li>and adds transactional commit (all or nothing)</li>
</ul>
",275.0,23844.0,15
1261,1269,False,"<p>The Subversion book has <a href=""http://svnbook.red-bean.com/en/1.4/svn.forcvs.html"" rel=""noreferrer"">an appendix</a> that details important differences from CVS, which may help you make your decision.  The two approaches are more or less the same idea but SVN was specifically designed to fix long standing flaws in CVS so, in theory at least, SVN will always be the better choice.</p>
",48.0,6386.0,7
1261,1264,False,"<p>One of the many comparisons:</p>

<p><a href=""http://wiki.scummvm.org/index.php/CVS_vs_SVN"" rel=""noreferrer"">http://wiki.scummvm.org/index.php/CVS_vs_SVN</a></p>

<p>Now this is very specific to that project, but a lot of stuff apllies in general.</p>

<p>Pro Subversion:</p>

<blockquote>
  <ul>
  <li>Support for versioned renames/moves (impossible with CVS): Fingolfin, Ender</li>
  <li>Supports directories natively: It's possible to remove them, and they are versioned: Fingolfin, Ender</li>
  <li>File properties are versioned; no more ""executable bit"" hell: Fingolfin</li>
  <li>Overall revision number makes build versioning and regression testing much easier: Ender, Fingolfin</li>
  <li>Atomic commits: Fingolfin</li>
  <li>Intuitive (directory-based) branching and tagging: Fingolfin</li>
  <li>Easier hook scripts (pre/post commit, etc): SumthinWicked (I use it for Doxygen after commits)</li>
  <li>Prevents accidental committing of conflicted files: Salty-horse, Fingolfin</li>
  <li>Support for custom 'diff' command: Fingolfin</li>
  <li>Offline diffs, and they're instant: sev </li>
  </ul>
</blockquote>
",91.0,166977.0,19
1276,44851042,False,"<p>I'm currently managing a MySQL database on Amazon's cloud infrastructure that has grown to 160 GB.  Query performance is fine.  What has become a nightmare is backups, restores, adding slaves, or anything else that deals with the whole dataset, or even DDL on large tables.  Getting a clean import of a dump file has become problematic.  In order to make the process stable enough to automate, various choices needed to be made to prioritize stability over performance.  If we ever had to recover from a disaster using a SQL backup, we'd be down for days.</p>
<p>Horizontally scaling SQL is also pretty painful, and in most cases leads to using it in ways you probably did not intend when you chose to put your data in SQL in the first place.  Shards, read slaves, multi-master, et al, they are all really shitty solutions that add complexity to everything you ever do with the DB, and not one of them solves the problem; only mitigates it in some ways.  I would strongly suggest looking at moving some of your data out of MySQL (or really any SQL) when you start approaching a dataset of a size where these types of things become an issue.</p>
<p>Update: a few years later, and our dataset has grown to about 800 GiB.  In addition, we have a single table which is 200+ GiB and a few others in the 50-100 GiB range.  Everything I said before holds.  It still performs just fine, but the problems of running full dataset operations have become worse.</p>
",3776288.0,1537.0,18
1276,62373670,False,"<p>Query performance mainly depends on the number of records it needs to scan, indexes plays a high role in it and index data size is proportional to number of rows and number of indexes.</p>

<p>Queries with indexed field conditions along with full value would be returned in 1ms generally, but starts_with, IN, Between, obviously contains conditions might take more time with more records to scan.  </p>

<p>Also you will face lot of maintenance issues with DDL, like ALTER, DROP will be slow and difficult with more live traffic even for adding a index or new columns.</p>

<p>Generally its advisable to cluster the Database into as many clusters as required (500GB would be a general benchmark, as said by others it depends on many factors and can vary based on use cases) that way it gives better isolation and gives independence to scale specific clusters (more suited in case of B2B)</p>
",13744323.0,9.0,0
1276,56303453,False,"<p>No it doesnt really matter. The MySQL speed is about 7 Million rows per second. So you can scale it quite a bit</p>
",11147992.0,57.0,0
1276,44366926,False,"<p>Database size DOES matter in terms of bytes and table's rows number. You will notice a huge performance difference between a light database and a blob filled one. Once my application got stuck because I put binary images inside fields instead of keeping images in files on the disk and putting only file names in database. Iterating a large number of rows on the other hand is not for free.</p>
",5645153.0,492.0,1
1276,1490,False,"<p>In general this is a very subtle issue and not trivial whatsoever. I encourage you to read <a href=""http://mysqlperformanceblog.com"" rel=""noreferrer"">mysqlperformanceblog.com</a> and <a href=""https://rads.stackoverflow.com/amzn/click/com/0596101716"" rel=""noreferrer"" rel=""nofollow noreferrer"">High Performance MySQL</a>. I really think there is no general answer for this.</p>

<p>I'm working on a project which has a MySQL database with almost 1TB of data. The most important scalability factor is RAM. If the indexes of your tables fit into memory and your queries are highly optimized, you can serve a reasonable amount of requests with a average machine. </p>

<p>The number of records do matter, depending of how your tables look like. It's a difference to have a lot of varchar fields or only a couple of ints or longs.</p>

<p>The physical size of the database matters as well: think of backups, for instance. Depending on your engine, your physical db files on grow, but don't shrink, for instance with innodb. So deleting a lot of rows, doesn't help to shrink your physical files.</p>

<p>There's a lot to this issues and as in a lot of cases the devil is in the details.</p>
",198.0,17111.0,99
1276,8110,False,"<blockquote>
  <p>I would focus first on your indexes, than have a server admin look at your OS, and if all that doesn't help it might be time for a master/slave configuration.</p>
</blockquote>

<p>That's true. Another thing that usually works is to just reduce the quantity of data that's repeatedly worked with. If you have ""old data"" and ""new data"" and 99% of your queries work with new data, just move all the old data to another table - and don't look at it ;)</p>

<p>-> Have a look at <a href=""http://dev.mysql.com/doc/refman/5.1/en/partitioning.html"" rel=""noreferrer"">partitioning</a>.</p>
",999.0,26641.0,23
1276,40865490,False,"<p><strong>It depends on your query and validation.</strong> </p>

<p>For example, i worked with a table of 100 000 drugs which has a column generic name where it has more than 15 characters for each drug in that table .I put a query to compare the generic name of drugs between two tables.The query takes more minutes to run.The Same,if you compare the drugs using the drug index,using an id column (as said above), it takes only few seconds. </p>
",4643764.0,623.0,4
1276,9016823,False,"<p>The database size <strong>does matter</strong>. If you have more than one table with more than a million records, then performance starts indeed to degrade. The number of records does of course affect the performance: <a href=""http://www.mysqlperformanceblog.com/2006/06/09/why-mysql-could-be-slow-with-large-tables/"">MySQL can be slow with large tables</a>. If you hit one million records you will get performance problems if the indices are not set right (for example no indices for fields in ""WHERE statements"" or ""ON conditions"" in joins). If you hit 10 million records, you will start to get performance problems even if you have all your indices right. Hardware upgrades - adding more memory and more processor power, especially memory - often help to reduce the most severe problems by increasing the performance again, at least to a certain degree.  For example <a href=""http://37signals.com/svn/posts/1185-the-need-for-speed-making-basecamp-faster"">37 signals went from 32 GB RAM to 128GB of RAM</a> for the Basecamp database server.</p>
",771581.0,24150.0,48
1276,18893356,False,"<p>Performance can degrade in a matter of few thousand rows if database is not designed properly. </p>

<p>If you have proper indexes, use proper engines (don't use MyISAM where multiple DMLs are expected), use partitioning, allocate correct memory depending on the use and of course have good server configuration, MySQL can handle data even in terabytes!</p>

<p>There are always ways to improve the database performance.</p>
",2645711.0,142.0,5
1276,1338,True,"<p>The physical database size doesn't matter.  The number of records don't matter.</p>

<p>In my experience the biggest problem that you are going to run in to is not size, but the number of queries you can handle at a time.  Most likely you are going to have to move to a master/slave configuration so that the read queries can run against the slaves and the write queries run against the master.  However if you are not ready for this yet, you can always tweak your indexes for the queries you are running to speed up the response times.  Also there is a lot of tweaking you can do to the network stack and kernel in Linux that will help.</p>

<p>I have had mine get up to 10GB, with only a moderate number of connections and it handled the requests just fine.</p>

<p>I would focus first on your indexes, then have a server admin look at your OS, and if all that doesn't help it might be time to implement a master/slave configuration.</p>
",17.0,52414.0,211
1276,13737357,False,"<p>A point to consider is also the purpose of the system and the data in the day to day.</p>

<p>For example, for a system with GPS monitoring of cars is not relevant query data from the positions of the car in previous months.</p>

<p>Therefore the data can be passed to other historical tables for possible consultation and reduce the execution times of the day to day queries.</p>
",1116802.0,3973.0,9
1276,3413193,False,"<p>2GB and about 15M records is a very small database - I've run much bigger ones on a pentium III(!) and everything has still run pretty fast.. If yours is slow it is a database/application design problem, not a mysql one. </p>
",411743.0,229.0,22
1276,3913,False,"<p>It's kind of pointless to talk about ""database performance"", ""query performance"" is a better term here. And the answer is: it depends on the query, data that it operates on, indexes, hardware, etc. You can get an idea of how many rows are going to be scanned and what indexes are going to be used with EXPLAIN syntax. </p>

<p>2GB does not really count as a ""large"" database - it's more of a medium size.</p>
",556.0,11052.0,20
1276,3079,False,"<p>I once was called upon to look at a mysql that had ""stopped working"".  I discovered that the DB files were residing on a Network Appliance filer mounted with NFS2 and with a maximum file size of 2GB.  And sure enough, the table that had stopped accepting transactions was exactly 2GB on disk.  But with regards to the performance curve I'm told that it was working like a champ right up until it didn't work at all!  This experience always serves for me as a nice reminder that there're always dimensions above and below the one you naturally suspect.</p>
",430.0,7014.0,10
1276,1504,False,"<p>Also watch out for complex joins.  Transaction complexity can be a big factor in addition to transaction volume.</p>

<p>Refactoring heavy queries sometimes offers a big performance boost.</p>
",59.0,5877.0,10
1292,62108498,False,"<p>You can use a <a href=""https://docs.microsoft.com/en-us/dotnet/api/system.collections.generic.linkedlist-1?view=netcore-3.1"" rel=""nofollow noreferrer""><code>LinkedList&lt;T&gt;</code></a> and add thread safety:</p>

<pre><code>public class Buffer&lt;T&gt; : LinkedList&lt;T&gt;
{
    private int capacity;

    public Buffer(int capacity)
    {
        this.capacity = capacity;   
    }

    public void Enqueue(T item)
    {
        // todo: add synchronization mechanism
        if (Count == capacity) RemoveLast();
        AddFirst(item);
    }

    public T Dequeue()
    {
        // todo: add synchronization mechanism
        var last = Last.Value;
        RemoveLast();
        return last;
    }
}
</code></pre>

<p>One thing to note is the default enumeration order will be LIFO in this example. But that can be overridden if necessary.</p>
",674237.0,1206.0,1
1292,50261664,False,"<h3>Concurrent Solution</h3>
<pre><code>public class LimitedConcurrentQueue&lt;ELEMENT&gt; : ConcurrentQueue&lt;ELEMENT&gt;
{
    public readonly int Limit;

    public LimitedConcurrentQueue(int limit)
    {
        Limit = limit;
    }

    public new void Enqueue(ELEMENT element)
    {
        base.Enqueue(element);
        if (Count &gt; Limit)
        {
            TryDequeue(out ELEMENT discard);
        }
    }
}
</code></pre>
<p>Note: Since <code>Enqueue</code> controls the addition of elements, and does so one at a time, there is no need to execute a <code>while</code> for <code>TryDequeue</code>.</p>
",218152.0,43172.0,4
1292,1305,True,"<p>I've knocked up a basic version of what I'm looking for, it's not perfect but it'll do the job until something better comes along.</p>

<pre><code>public class LimitedQueue&lt;T&gt; : Queue&lt;T&gt;
{
    public int Limit { get; set; }

    public LimitedQueue(int limit) : base(limit)
    {
        Limit = limit;
    }

    public new void Enqueue(T item)
    {
        while (Count &gt;= Limit)
        {
            Dequeue();
        }
        base.Enqueue(item);
    }
}
</code></pre>
",192.0,70350.0,42
1292,8136476,False,"<p>Well I hope this class will helps You:<br>
Internally the Circular FIFO Buffer use a Queue&lt;T&gt; with the specified size. 
Once the size of the buffer is reached, it will replaces older items with new ones.</p>

<p>NOTE: You can't remove items randomly. I set the method Remove(T item) to return false.
if You want You can modify to remove items randomly</p>

<pre><code>public class CircularFIFO&lt;T&gt; : ICollection&lt;T&gt; , IDisposable
{
    public Queue&lt;T&gt; CircularBuffer;

    /// &lt;summary&gt;
    /// The default initial capacity.
    /// &lt;/summary&gt;
    private int capacity = 32;

    /// &lt;summary&gt;
    /// Gets the actual capacity of the FIFO.
    /// &lt;/summary&gt;
    public int Capacity
    {
        get { return capacity; }          
    }

    /// &lt;summary&gt;
    ///  Initialize a new instance of FIFO class that is empty and has the default initial capacity.
    /// &lt;/summary&gt;
    public CircularFIFO()
    {            
        CircularBuffer = new Queue&lt;T&gt;();
    }

    /// &lt;summary&gt;
    /// Initialize a new instance of FIFO class that is empty and has the specified initial capacity.
    /// &lt;/summary&gt;
    /// &lt;param name=""size""&gt; Initial capacity of the FIFO. &lt;/param&gt;
    public CircularFIFO(int size)
    {
        capacity = size;
        CircularBuffer = new Queue&lt;T&gt;(capacity);
    }

    /// &lt;summary&gt;
    /// Adds an item to the end of the FIFO.
    /// &lt;/summary&gt;
    /// &lt;param name=""item""&gt; The item to add to the end of the FIFO. &lt;/param&gt;
    public void Add(T item)
    {
        if (this.Count &gt;= this.Capacity)
            Remove();

        CircularBuffer.Enqueue(item);
    }

    /// &lt;summary&gt;
    /// Adds array of items to the end of the FIFO.
    /// &lt;/summary&gt;
    /// &lt;param name=""item""&gt; The array of items to add to the end of the FIFO. &lt;/param&gt;
     public void Add(T[] item)
    { 
        int enqueuedSize = 0;
        int remainEnqueueSize = this.Capacity - this.Count;

        for (; (enqueuedSize &lt; item.Length &amp;&amp; enqueuedSize &lt; remainEnqueueSize); enqueuedSize++)
            CircularBuffer.Enqueue(item[enqueuedSize]);

        if ((item.Length - enqueuedSize) != 0)
        {
            Remove((item.Length - enqueuedSize));//remaining item size

            for (; enqueuedSize &lt; item.Length; enqueuedSize++)
                CircularBuffer.Enqueue(item[enqueuedSize]);
        }           
    }

    /// &lt;summary&gt;
    /// Removes and Returns an item from the FIFO.
    /// &lt;/summary&gt;
    /// &lt;returns&gt; Item removed. &lt;/returns&gt;
    public T Remove()
    {
        T removedItem = CircularBuffer.Peek();
        CircularBuffer.Dequeue();

        return removedItem;
    }

    /// &lt;summary&gt;
    /// Removes and Returns the array of items form the FIFO.
    /// &lt;/summary&gt;
    /// &lt;param name=""size""&gt; The size of item to be removed from the FIFO. &lt;/param&gt;
    /// &lt;returns&gt; Removed array of items &lt;/returns&gt;
    public T[] Remove(int size)
    {
        if (size &gt; CircularBuffer.Count)
            size = CircularBuffer.Count;

        T[] removedItems = new T[size];

        for (int i = 0; i &lt; size; i++)
        {
            removedItems[i] = CircularBuffer.Peek();
            CircularBuffer.Dequeue();
        }

        return removedItems;
    }

    /// &lt;summary&gt;
    /// Returns the item at the beginning of the FIFO with out removing it.
    /// &lt;/summary&gt;
    /// &lt;returns&gt; Item Peeked. &lt;/returns&gt;
    public T Peek()
    {
        return CircularBuffer.Peek();
    }

    /// &lt;summary&gt;
    /// Returns the array of item at the beginning of the FIFO with out removing it.
    /// &lt;/summary&gt;
    /// &lt;param name=""size""&gt; The size of the array items. &lt;/param&gt;
    /// &lt;returns&gt; Array of peeked items. &lt;/returns&gt;
    public T[] Peek(int size)
    {
        T[] arrayItems = new T[CircularBuffer.Count];
        CircularBuffer.CopyTo(arrayItems, 0);

        if (size &gt; CircularBuffer.Count)
            size = CircularBuffer.Count;

        T[] peekedItems = new T[size];

        Array.Copy(arrayItems, 0, peekedItems, 0, size);

        return peekedItems;
    }

    /// &lt;summary&gt;
    /// Gets the actual number of items presented in the FIFO.
    /// &lt;/summary&gt;
    public int Count
    {
        get
        {
            return CircularBuffer.Count;
        }
    }

    /// &lt;summary&gt;
    /// Removes all the contents of the FIFO.
    /// &lt;/summary&gt;
    public void Clear()
    {
        CircularBuffer.Clear();
    }

    /// &lt;summary&gt;
    /// Resets and Initialize the instance of FIFO class that is empty and has the default initial capacity.
    /// &lt;/summary&gt;
    public void Reset()
    {
        Dispose();
        CircularBuffer = new Queue&lt;T&gt;(capacity);
    }

    #region ICollection&lt;T&gt; Members

    /// &lt;summary&gt;
    /// Determines whether an element is in the FIFO.
    /// &lt;/summary&gt;
    /// &lt;param name=""item""&gt; The item to locate in the FIFO. &lt;/param&gt;
    /// &lt;returns&gt;&lt;/returns&gt;
    public bool Contains(T item)
    {
        return CircularBuffer.Contains(item);
    }

    /// &lt;summary&gt;
    /// Copies the FIFO elements to an existing one-dimensional array. 
    /// &lt;/summary&gt;
    /// &lt;param name=""array""&gt; The one-dimensional array that have at list a size of the FIFO &lt;/param&gt;
    /// &lt;param name=""arrayIndex""&gt;&lt;/param&gt;
    public void CopyTo(T[] array, int arrayIndex)
    {
        if (array.Length &gt;= CircularBuffer.Count)
            CircularBuffer.CopyTo(array, 0);           
    }

    public bool IsReadOnly
    {
        get { return false; }
    }

    public bool Remove(T item)
    {
        return false; 
    }

    #endregion

    #region IEnumerable&lt;T&gt; Members

    public IEnumerator&lt;T&gt; GetEnumerator()
    {
       return CircularBuffer.GetEnumerator();
    }

    #endregion

    #region IEnumerable Members

    IEnumerator IEnumerable.GetEnumerator()
    {
        return CircularBuffer.GetEnumerator();
    }

    #endregion

    #region IDisposable Members

    /// &lt;summary&gt;
    /// Releases all the resource used by the FIFO.
    /// &lt;/summary&gt;
    public void Dispose()
    {          
        CircularBuffer.Clear();
        CircularBuffer = null;
        GC.Collect();
    }

    #endregion
}
</code></pre>
",1047575.0,61.0,6
1292,1297,False,"<p>Why wouldn't you just use an array with a size of 2?  A Queue is supposed to be able to dynamically grow and shrink.</p>

<p>Or create a wrapper class around an instance of <code>Queue&lt;T&gt;</code> instance and each time one enqueues a <code>&lt;T&gt;</code> object, check the size of the queue.  If larger than 2, dequeue the first item.</p>
",25.0,33410.0,3
1292,8867737,False,"<p>If it's of any use to anyone, I made a <code>LimitedStack&lt;T&gt;</code>.</p>

<pre><code>public class LimitedStack&lt;T&gt;
{
    public readonly int Limit;
    private readonly List&lt;T&gt; _stack;

    public LimitedStack(int limit = 32)
    {
        Limit = limit;
        _stack = new List&lt;T&gt;(limit);
    }

    public void Push(T item)
    {
        if (_stack.Count == Limit) _stack.RemoveAt(0);
        _stack.Add(item);
    }

    public T Peek()
    {
        return _stack[_stack.Count - 1];
    }

    public void Pop()
    {
        _stack.RemoveAt(_stack.Count - 1);
    }

    public int Count
    {
        get { return _stack.Count; }
    }
}
</code></pre>

<p>It removes the oldest item (bottom of stack) when it gets too big.</p>

<p>(This question was the top Google result for ""C# limit stack size"")</p>
",65387.0,235837.0,1
1292,233606,False,"<p>I would recommend that you pull up the <a href=""http://www.itu.dk/research/c5"" rel=""noreferrer"">C5 Library</a>.  Unlike SCG (System.Collections.Generic), C5 is programmed to interface and designed to be subclassed.  Most public methods are virtual and none of the classes are sealed.  This way, you won't have to use that icky ""new"" keyword which wouldn't trigger if your <code>LimitedQueue&lt;T&gt;</code> were cast to a <code>SCG.Queue&lt;T&gt;</code>.  With C5 and using close to the same code as you had before, you would derive from the <code>CircularQueue&lt;T&gt;</code>.  The <code>CircularQueue&lt;T&gt;</code> actually implements both a stack and a queue, so you can get both options with a limit nearly for free.  I've rewritten it below with some 3.5 constructs:</p>

<pre><code>using C5;

public class LimitedQueue&lt;T&gt; : CircularQueue&lt;T&gt;
{
    public int Limit { get; set; }

    public LimitedQueue(int limit) : base(limit)
    {
        this.Limit = limit;
    }

    public override void Push(T item)
    {
        CheckLimit(false);
        base.Push(item);
    }

    public override void Enqueue(T item)
    {
        CheckLimit(true);
        base.Enqueue(item);
    }

    protected virtual void CheckLimit(bool enqueue)
    {
        while (this.Count &gt;= this.Limit)
        {
            if (enqueue)
            {
                this.Dequeue();
            }
            else
            {
                this.Pop();
            }
        }
    }
}
</code></pre>

<p>I think that this code should do exactly what you were looking for.</p>
",28645.0,7268.0,19
1292,1303,False,"<p>You should create your own class, a ringbuffer would probably fit your needs.</p>

<p>The data structures in .NET that allows you to specify capacity, except for array, uses this to build the internal data structure used to hold the internal data.</p>

<p>For instance, for a list, capacity is used to size an internal array. When you start adding elements to the list, it'll start filling this array from index 0 and up, and when it reaches your capacity, it increases the capacity to a new higher capacity, and continues filling it up.</p>
",267.0,348196.0,5
1300,148770,False,"<p>I find that you can also use a hybrid approach too, especially in larger projects.  A lot of our nant scripts are being converted to msbuild when new components are developed.  Both support the same major features and can call each other if you find a task that is natively supported in one but not the other.</p>

<p>For new .NET development starting with MSBuild can save you a lot of time since it can run the solution files directly.  Extending from the main compilation to perform other tasks (source control, deployment, etc) works quite well.</p>
",1145.0,2539.0,0
1300,44754,False,"<p>Like what so many people have already indicated, the answer here is ""it depends"". There are some things like <em>repeating operations</em> that are much simpler and cleaner in NAnt. See <a href=""http://forums.msdn.microsoft.com/en-US/msbuild/thread/417329cb-a6f6-45dd-9a56-98bb4aee74f9"" rel=""nofollow noreferrer"">the MSDN forums</a> for a discussion about this.</p>
",,,0
1300,33952,False,"<p>CC.NET is simply the build server technology, not the build script technology. We use CC.NET at work to very successfully call MSBuild build scripts with no problems.</p>

<p>NAnt is an older and more mature build scripting language, but they are both similar in how they work. There are very few things I could do in NAnt that I can't also do in MSBuild, so it really comes down to which one you are more comfortable with. As far as how active NAnt is, don't go by when the last release was...instead go by when the last nightly build was. NAnt tends to go a long time between releases, but the nightly builds are usually pretty stable.</p>
",1559.0,40259.0,1
1300,1673,True,"<p>If you are quite happy with MSBuild, then I would stick with MSBuild.  This may be one of those cases where the tool you learn first is the one you will prefer.  I started with NAnt and can't quite get used to MSBuild.  I'm sure they will both be around for quite some time.</p>

<p>There are some fundamental differences between the two, probably best highlighted by <a href=""http://forums.msdn.microsoft.com/en-US/msbuild/thread/994761a3-ea9d-40c7-8d4f-4c208b2023f6/"" rel=""noreferrer"">this conversation between some NAnt fans and a Microsoftie</a>.</p>

<p>Interestingly, <a href=""http://codebetter.com/blogs/jeremy.miller/default.aspx"" rel=""noreferrer"">Jeremy Miller</a> asked the exact opposite question <a href=""http://codebetter.com/blogs/jeremy.miller/archive/2007/09/20/is-there-a-good-reason-to-switch-to-msbuild.aspx"" rel=""noreferrer"">on his blog</a> last year.  </p>
",308.0,7397.0,15
1300,1364,False,"<p>If you've already got a bunch of custom tasks you use with nAnt, stick with it - you don't gain much with MSBuild.  That said, there doesn't seem to be anything that nAnt can do that MSBuild can't at its core.  Both can call external tools, both can run .Net-based custom tasks, and both have a bunch of community tasks out there.</p>

<p>We're using MSBuild here for the same reason you are - it's the default build system for VS now, and we didn't have any nAnt-specific stuff to worry about.</p>

<p>The <a href=""http://msbuildtasks.tigris.org/"" rel=""nofollow noreferrer"">MSBuildCommunityTasks</a> are a good third-party task base to start with, and covers most of the custom stuff I ever did in nAnt, including VSS and Subversion support.</p>
",35.0,17207.0,3
1300,1347,False,"<p>Honestly it depends on what fits in to your environment better.  If you are using a lot of Non-Microsoft tools, nunit, ccnet, ncover.  You will probably find better support with nant.  Alternatively if you are using MSTest, TFSBuild, you will probably find MSBuild a better environment.  I would learn both and use which every fits more smoothly with your environment.</p>
",17.0,52414.0,1
1300,1320,False,"<p>In my opinion it is more a question of personal preference.  nAnt is a great framework and MSBuild is almost as capable.  With the ability to easily develop custom tasks (in both frameworks) you can accomplish almost anything that you need to do.</p>

<p>I cannot answer the ""still supported"" portion of your questions, but I would say if you are already comfortable with nAnt then it's probably viable.  If you (or someone in your group) is familiar with MSBuild then that is a fine way to go as well.</p>
",312.0,22680.0,5
1304,18989377,False,"<p>Here's a variation of DixonD's code that adds number of seconds to wait for file to unlock, and try again:</p>

<pre><code>public bool IsFileLocked(string filePath, int secondsToWait)
{
    bool isLocked = true;
    int i = 0;

    while (isLocked &amp;&amp;  ((i &lt; secondsToWait) || (secondsToWait == 0)))
    {
        try
        {
            using (File.Open(filePath, FileMode.Open)) { }
            return false;
        }
        catch (IOException e)
        {
            var errorCode = Marshal.GetHRForException(e) &amp; ((1 &lt;&lt; 16) - 1);
            isLocked = errorCode == 32 || errorCode == 33;
            i++;

            if (secondsToWait !=0)
                new System.Threading.ManualResetEvent(false).WaitOne(1000);
        }
    }

    return isLocked;
}


if (!IsFileLocked(file, 10))
{
    ...
}
else
{
    throw new Exception(...);
}
</code></pre>
",436341.0,33544.0,9
1304,20619061,False,"<p>What I ended up doing is:</p>

<pre><code>internal void LoadExternalData() {
    FileStream file;

    if (TryOpenRead(""filepath/filename"", 5, out file)) {
        using (file)
        using (StreamReader reader = new StreamReader(file)) {
         // do something 
        }
    }
}


internal bool TryOpenRead(string path, int timeout, out FileStream file) {
    bool isLocked = true;
    bool condition = true;

    do {
        try {
            file = File.OpenRead(path);
            return true;
        }
        catch (IOException e) {
            var errorCode = Marshal.GetHRForException(e) &amp; ((1 &lt;&lt; 16) - 1);
            isLocked = errorCode == 32 || errorCode == 33;
            condition = (isLocked &amp;&amp; timeout &gt; 0);

            if (condition) {
                // we only wait if the file is locked. If the exception is of any other type, there's no point on keep trying. just return false and null;
                timeout--;
                new System.Threading.ManualResetEvent(false).WaitOne(1000);
            }
        }
    }
    while (condition);

    file = null;
    return false;
}
</code></pre>
",826568.0,17780.0,0
1304,34437734,False,"<p>Same thing but in Powershell</p>

<pre><code>function Test-FileOpen
{
    Param
    ([string]$FileToOpen)
    try
    {
        $openFile =([system.io.file]::Open($FileToOpen,[system.io.filemode]::Open))
        $open =$true
        $openFile.close()
    }
    catch
    {
        $open = $false
    }
    $open
}
</code></pre>
",4991132.0,1207.0,1
1304,14132721,False,"<p>A variation of DixonD's excellent answer (above).</p>

<pre><code>public static bool TryOpen(string path,
                           FileMode fileMode,
                           FileAccess fileAccess,
                           FileShare fileShare,
                           TimeSpan timeout,
                           out Stream stream)
{
    var endTime = DateTime.Now + timeout;

    while (DateTime.Now &lt; endTime)
    {
        if (TryOpen(path, fileMode, fileAccess, fileShare, out stream))
            return true;
    }

    stream = null;
    return false;
}

public static bool TryOpen(string path,
                           FileMode fileMode,
                           FileAccess fileAccess,
                           FileShare fileShare,
                           out Stream stream)
{
    try
    {
        stream = File.Open(path, fileMode, fileAccess, fileShare);
        return true;
    }
    catch (IOException e)
    {
        if (!FileIsLocked(e))
            throw;

        stream = null;
        return false;
    }
}

private const uint HRFileLocked = 0x80070020;
private const uint HRPortionOfFileLocked = 0x80070021;

private static bool FileIsLocked(IOException ioException)
{
    var errorCode = (uint)Marshal.GetHRForException(ioException);
    return errorCode == HRFileLocked || errorCode == HRPortionOfFileLocked;
}
</code></pre>

<p>Usage:</p>

<pre><code>private void Sample(string filePath)
{
    Stream stream = null;

    try
    {
        var timeOut = TimeSpan.FromSeconds(1);

        if (!TryOpen(filePath,
                     FileMode.Open,
                     FileAccess.ReadWrite,
                     FileShare.ReadWrite,
                     timeOut,
                     out stream))
            return;

        // Use stream...
    }
    finally
    {
        if (stream != null)
            stream.Close();
    }
}
</code></pre>
",642282.0,1398.0,8
1304,5512640,False,"<p>You can also check if any process is using this file and show a list of programs you must close to continue like an installer does.</p>

<pre><code>public static string GetFileProcessName(string filePath)
{
    Process[] procs = Process.GetProcesses();
    string fileName = Path.GetFileName(filePath);

    foreach (Process proc in procs)
    {
        if (proc.MainWindowHandle != new IntPtr(0) &amp;&amp; !proc.HasExited)
        {
            ProcessModule[] arr = new ProcessModule[proc.Modules.Count];

            foreach (ProcessModule pm in proc.Modules)
            {
                if (pm.ModuleName == fileName)
                    return proc.ProcessName;
            }
        }
    }

    return null;
}
</code></pre>
",687466.0,191.0,19
1304,20623302,False,"<p><strong>The other answers rely on old information.  This one provides a better solution.</strong></p>

<p>Long ago it was impossible to reliably get the list of processes locking a file because Windows simply did not track that information.  To support the <a href=""http://msdn.microsoft.com/en-us/library/windows/desktop/aa373656%28v=vs.85%29.aspx"" rel=""noreferrer"">Restart Manager API</a>, that information is now tracked.  The Restart Manager API is available beginning with Windows Vista and Windows Server 2008 (<a href=""https://msdn.microsoft.com/en-us/library/windows/desktop/cc948910(v=vs.85).aspx"" rel=""noreferrer"">Restart Manager: Run-time Requirements</a>).</p>

<p>I put together code that takes the path of a file and returns a <code>List&lt;Process&gt;</code> of all processes that are locking that file.</p>

<pre><code>static public class FileUtil
{
    [StructLayout(LayoutKind.Sequential)]
    struct RM_UNIQUE_PROCESS
    {
        public int dwProcessId;
        public System.Runtime.InteropServices.ComTypes.FILETIME ProcessStartTime;
    }

    const int RmRebootReasonNone = 0;
    const int CCH_RM_MAX_APP_NAME = 255;
    const int CCH_RM_MAX_SVC_NAME = 63;

    enum RM_APP_TYPE
    {
        RmUnknownApp = 0,
        RmMainWindow = 1,
        RmOtherWindow = 2,
        RmService = 3,
        RmExplorer = 4,
        RmConsole = 5,
        RmCritical = 1000
    }

    [StructLayout(LayoutKind.Sequential, CharSet = CharSet.Unicode)]
    struct RM_PROCESS_INFO
    {
        public RM_UNIQUE_PROCESS Process;

        [MarshalAs(UnmanagedType.ByValTStr, SizeConst = CCH_RM_MAX_APP_NAME + 1)]
        public string strAppName;

        [MarshalAs(UnmanagedType.ByValTStr, SizeConst = CCH_RM_MAX_SVC_NAME + 1)]
        public string strServiceShortName;

        public RM_APP_TYPE ApplicationType;
        public uint AppStatus;
        public uint TSSessionId;
        [MarshalAs(UnmanagedType.Bool)]
        public bool bRestartable;
    }

    [DllImport(""rstrtmgr.dll"", CharSet = CharSet.Unicode)]
    static extern int RmRegisterResources(uint pSessionHandle,
                                          UInt32 nFiles,
                                          string[] rgsFilenames,
                                          UInt32 nApplications,
                                          [In] RM_UNIQUE_PROCESS[] rgApplications,
                                          UInt32 nServices,
                                          string[] rgsServiceNames);

    [DllImport(""rstrtmgr.dll"", CharSet = CharSet.Auto)]
    static extern int RmStartSession(out uint pSessionHandle, int dwSessionFlags, string strSessionKey);

    [DllImport(""rstrtmgr.dll"")]
    static extern int RmEndSession(uint pSessionHandle);

    [DllImport(""rstrtmgr.dll"")]
    static extern int RmGetList(uint dwSessionHandle,
                                out uint pnProcInfoNeeded,
                                ref uint pnProcInfo,
                                [In, Out] RM_PROCESS_INFO[] rgAffectedApps,
                                ref uint lpdwRebootReasons);

    /// &lt;summary&gt;
    /// Find out what process(es) have a lock on the specified file.
    /// &lt;/summary&gt;
    /// &lt;param name=""path""&gt;Path of the file.&lt;/param&gt;
    /// &lt;returns&gt;Processes locking the file&lt;/returns&gt;
    /// &lt;remarks&gt;See also:
    /// http://msdn.microsoft.com/en-us/library/windows/desktop/aa373661(v=vs.85).aspx
    /// http://wyupdate.googlecode.com/svn-history/r401/trunk/frmFilesInUse.cs (no copyright in code at time of viewing)
    /// 
    /// &lt;/remarks&gt;
    static public List&lt;Process&gt; WhoIsLocking(string path)
    {
        uint handle;
        string key = Guid.NewGuid().ToString();
        List&lt;Process&gt; processes = new List&lt;Process&gt;();

        int res = RmStartSession(out handle, 0, key);

        if (res != 0)
            throw new Exception(""Could not begin restart session.  Unable to determine file locker."");

        try
        {
            const int ERROR_MORE_DATA = 234;
            uint pnProcInfoNeeded = 0,
                 pnProcInfo = 0,
                 lpdwRebootReasons = RmRebootReasonNone;

            string[] resources = new string[] { path }; // Just checking on one resource.

            res = RmRegisterResources(handle, (uint)resources.Length, resources, 0, null, 0, null);

            if (res != 0) 
                throw new Exception(""Could not register resource."");                                    

            //Note: there's a race condition here -- the first call to RmGetList() returns
            //      the total number of process. However, when we call RmGetList() again to get
            //      the actual processes this number may have increased.
            res = RmGetList(handle, out pnProcInfoNeeded, ref pnProcInfo, null, ref lpdwRebootReasons);

            if (res == ERROR_MORE_DATA)
            {
                // Create an array to store the process results
                RM_PROCESS_INFO[] processInfo = new RM_PROCESS_INFO[pnProcInfoNeeded];
                pnProcInfo = pnProcInfoNeeded;

                // Get the list
                res = RmGetList(handle, out pnProcInfoNeeded, ref pnProcInfo, processInfo, ref lpdwRebootReasons);

                if (res == 0)
                {
                    processes = new List&lt;Process&gt;((int)pnProcInfo);

                    // Enumerate all of the results and add them to the 
                    // list to be returned
                    for (int i = 0; i &lt; pnProcInfo; i++)
                    {
                        try
                        {
                            processes.Add(Process.GetProcessById(processInfo[i].Process.dwProcessId));
                        }
                        // catch the error -- in case the process is no longer running
                        catch (ArgumentException) { }
                    }
                }
                else
                    throw new Exception(""Could not list processes locking resource."");                    
            }
            else if (res != 0)
                throw new Exception(""Could not list processes locking resource. Failed to get size of result."");                    
        }
        finally
        {
            RmEndSession(handle);
        }

        return processes;
    }
}
</code></pre>

<p><strong>UPDATE</strong></p>

<p>Here is another <a href=""https://blogs.msdn.microsoft.com/oldnewthing/20120217-00/?p=8283"" rel=""noreferrer"">discussion with sample code</a> on how to use the Restart Manager API.</p>
",141172.0,139120.0,149
1304,3202085,False,"<p>When I faced with a similar problem, I finished with the following code:</p>

<pre><code>public bool IsFileLocked(string filePath)
{
    try
    {
        using (File.Open(filePath, FileMode.Open)){}
    }
    catch (IOException e)
    {
        var errorCode = Marshal.GetHRForException(e) &amp; ((1 &lt;&lt; 16) - 1);

        return errorCode == 32 || errorCode == 33;
    }

    return false;
}
</code></pre>
",213725.0,6064.0,184
1304,1309,True,"<p>No, unfortunately, and if you think about it, that information would be worthless anyway since the file could become locked the very next second (read: short timespan).</p>

<p>Why specifically do you need to know if the file is locked anyway? Knowing that might give us some other way of giving you good advice.</p>

<p>If your code would look like this:</p>

<pre><code>if not locked then
    open and update file
</code></pre>

<p>Then between the two lines, another process could easily lock the file, giving you the same problem you were trying to avoid to begin with: exceptions.</p>
",267.0,348196.0,134
1304,2403108,False,"<p>Instead of using interop you can use the .NET FileStream class methods Lock and Unlock:</p>

<p>FileStream.Lock
<a href=""http://msdn.microsoft.com/en-us/library/system.io.filestream.lock.aspx"" rel=""noreferrer"">http://msdn.microsoft.com/en-us/library/system.io.filestream.lock.aspx</a></p>

<p>FileStream.Unlock
<a href=""http://msdn.microsoft.com/en-us/library/system.io.filestream.unlock.aspx"" rel=""noreferrer"">http://msdn.microsoft.com/en-us/library/system.io.filestream.unlock.aspx</a></p>
",198152.0,934.0,16
1304,1176082,False,"<p>You could call <a href=""http://msdn.microsoft.com/en-us/library/aa365202%28VS.85%29.aspx"" rel=""noreferrer"">LockFile</a> via interop on the region of file you are interested in. This will not throw an exception, if it succeeds you will have a lock on that portion of the file (which is held by your process), that lock will be held until you call <a href=""http://msdn.microsoft.com/en-us/library/aa365715%28VS.85%29.aspx"" rel=""noreferrer"">UnlockFile</a> or your process dies. </p>
",17174.0,120598.0,7
1304,626095,False,"<p>You can see if the file is locked by trying to read or lock it yourself first. </p>

<p><a href=""https://stackoverflow.com/questions/203837/can-i-simply-read-a-file-that-is-in-use/203839#203839"">Please see my answer here for more information</a>.</p>
",3153.0,312311.0,6
1304,13789,False,"<blockquote>
  <p>Then between the two lines, another process could easily lock the file, giving you the same problem you were trying to avoid to begin with: exceptions.</p>
</blockquote>

<p>However, this way, you would know that the problem is temporary, and to retry later. (E.g., you could write a thread that, if encountering a lock while trying to write, keeps retrying until the lock is gone.)</p>

<p>The IOException, on the other hand, is not by itself specific enough that locking is the cause of the IO failure. There could be reasons that aren't temporary.</p>
",1600.0,18030.0,6
1306,1378,False,"<p>Personally I think curses is overkill in this case.  While the curses lib is nice (and I frequently use it myself) it's a PITA to relearn every time I haven't needed it for 12 months which has to be the sign of a bad interface design.</p>

<p>If for some reason you can't get on with <a href=""https://stackoverflow.com/questions/1306/#1318"">the progress bar lib Joey suggested</a> roll your own and release it under a pretty free licence for instant kudos :)</p>
",269.0,18803.0,4
1306,1375,False,"<p>On windows, curses works out of the box, ncurses doesn't, and for a progress bar curses should be sufficient. So, use curses instead of ncurses.</p>

<p>Also, both curses and ncurses are wafer-thin wrappers around the c library - that means you don't really need Ruby-specific tutorials.</p>

<p>However, on the <a href=""http://www.pragprog.com/titles/ruby/source_code"" rel=""nofollow noreferrer"">site for the PickAxe</a> you can download all the code examples for the book. The file ""ex1423.rb"" contains a curses demo which plays Pong - that should give you plenty of material to get you going.</p>
",136.0,40451.0,2
1306,4392562,False,"<p>Very late answer and sorry for self promotion, but I created <a href=""https://rubygems.org/gems/progress"" rel=""noreferrer"">library</a> to show progress in terminal.</p>
",96823.0,20852.0,4
1306,1318,True,"<p>You might be able to get some implementation ideas from the <a href=""http://0xcc.net/ruby-progressbar/"" rel=""noreferrer"" title=""Ruby/ProgressBar"">Ruby/ProgressBar library</a>, which generates text progress bars. I stumbled across it a couple of months back but haven't made any use of it.</p>
",216.0,8135.0,20
1313,19416874,False,"<p>as cmetric.htm link above failed for me, as well as many other implementations for color distance I found (after a very long jurney..) how to calculate the best color distance, and .. most scientifically accurate one: <strong>deltaE</strong> and from 2 RGB (!) values using OpenCV:</p>

<p>This required 3 color space conversions + some code conversion from javascript (<a href=""http://svn.int64.org/viewvc/int64/colors/colors.js"">http://svn.int64.org/viewvc/int64/colors/colors.js</a>) to C++</p>

<p>And finally the code (seems to work right out of the box, hope no one finds a serious bug there ... but it seems fine after a number of tests)</p>

<pre><code>#include &lt;opencv2/core/core.hpp&gt;
#include &lt;opencv2/imgproc/imgproc.hpp&gt;
#include &lt;opencv2/highgui/highgui.hpp&gt;
#include &lt;opencv2/photo/photo.hpp&gt;
#include &lt;math.h&gt;

using namespace cv;
using namespace std;

#define REF_X 95.047; // Observer= 2°, Illuminant= D65
#define REF_Y 100.000;
#define REF_Z 108.883;

void bgr2xyz( const Vec3b&amp; BGR, Vec3d&amp; XYZ );
void xyz2lab( const Vec3d&amp; XYZ, Vec3d&amp; Lab );
void lab2lch( const Vec3d&amp; Lab, Vec3d&amp; LCH );
double deltaE2000( const Vec3b&amp; bgr1, const Vec3b&amp; bgr2 );
double deltaE2000( const Vec3d&amp; lch1, const Vec3d&amp; lch2 );


void bgr2xyz( const Vec3b&amp; BGR, Vec3d&amp; XYZ )
{
    double r = (double)BGR[2] / 255.0;
    double g = (double)BGR[1] / 255.0;
    double b = (double)BGR[0] / 255.0;
    if( r &gt; 0.04045 )
        r = pow( ( r + 0.055 ) / 1.055, 2.4 );
    else
        r = r / 12.92;
    if( g &gt; 0.04045 )
        g = pow( ( g + 0.055 ) / 1.055, 2.4 );
    else
        g = g / 12.92;
    if( b &gt; 0.04045 )
        b = pow( ( b + 0.055 ) / 1.055, 2.4 );
    else
        b = b / 12.92;
    r *= 100.0;
    g *= 100.0;
    b *= 100.0;
    XYZ[0] = r * 0.4124 + g * 0.3576 + b * 0.1805;
    XYZ[1] = r * 0.2126 + g * 0.7152 + b * 0.0722;
    XYZ[2] = r * 0.0193 + g * 0.1192 + b * 0.9505;
}

void xyz2lab( const Vec3d&amp; XYZ, Vec3d&amp; Lab )
{
    double x = XYZ[0] / REF_X;
    double y = XYZ[1] / REF_X;
    double z = XYZ[2] / REF_X;
    if( x &gt; 0.008856 )
        x = pow( x , .3333333333 );
    else
        x = ( 7.787 * x ) + ( 16.0 / 116.0 );
    if( y &gt; 0.008856 )
        y = pow( y , .3333333333 );
    else
        y = ( 7.787 * y ) + ( 16.0 / 116.0 );
    if( z &gt; 0.008856 )
        z = pow( z , .3333333333 );
    else
        z = ( 7.787 * z ) + ( 16.0 / 116.0 );
    Lab[0] = ( 116.0 * y ) - 16.0;
    Lab[1] = 500.0 * ( x - y );
    Lab[2] = 200.0 * ( y - z );
}

void lab2lch( const Vec3d&amp; Lab, Vec3d&amp; LCH )
{
    LCH[0] = Lab[0];
    LCH[1] = sqrt( ( Lab[1] * Lab[1] ) + ( Lab[2] * Lab[2] ) );
    LCH[2] = atan2( Lab[2], Lab[1] );
}

double deltaE2000( const Vec3b&amp; bgr1, const Vec3b&amp; bgr2 )
{
    Vec3d xyz1, xyz2, lab1, lab2, lch1, lch2;
    bgr2xyz( bgr1, xyz1 );
    bgr2xyz( bgr2, xyz2 );
    xyz2lab( xyz1, lab1 );
    xyz2lab( xyz2, lab2 );
    lab2lch( lab1, lch1 );
    lab2lch( lab2, lch2 );
    return deltaE2000( lch1, lch2 );
}

double deltaE2000( const Vec3d&amp; lch1, const Vec3d&amp; lch2 )
{
    double avg_L = ( lch1[0] + lch2[0] ) * 0.5;
    double delta_L = lch2[0] - lch1[0];
    double avg_C = ( lch1[1] + lch2[1] ) * 0.5;
    double delta_C = lch1[1] - lch2[1];
    double avg_H = ( lch1[2] + lch2[2] ) * 0.5;
    if( fabs( lch1[2] - lch2[2] ) &gt; CV_PI )
        avg_H += CV_PI;
    double delta_H = lch2[2] - lch1[2];
    if( fabs( delta_H ) &gt; CV_PI )
    {
        if( lch2[2] &lt;= lch1[2] )
            delta_H += CV_PI * 2.0;
        else
            delta_H -= CV_PI * 2.0;
    }

    delta_H = sqrt( lch1[1] * lch2[1] ) * sin( delta_H ) * 2.0;
    double T = 1.0 -
            0.17 * cos( avg_H - CV_PI / 6.0 ) +
            0.24 * cos( avg_H * 2.0 ) +
            0.32 * cos( avg_H * 3.0 + CV_PI / 30.0 ) -
            0.20 * cos( avg_H * 4.0 - CV_PI * 7.0 / 20.0 );
    double SL = avg_L - 50.0;
    SL *= SL;
    SL = SL * 0.015 / sqrt( SL + 20.0 ) + 1.0;
    double SC = avg_C * 0.045 + 1.0;
    double SH = avg_C * T * 0.015 + 1.0;
    double delta_Theta = avg_H / 25.0 - CV_PI * 11.0 / 180.0;
    delta_Theta = exp( delta_Theta * -delta_Theta ) * ( CV_PI / 6.0 );
    double RT = pow( avg_C, 7.0 );
    RT = sqrt( RT / ( RT + 6103515625.0 ) ) * sin( delta_Theta ) * -2.0; // 6103515625 = 25^7
    delta_L /= SL;
    delta_C /= SC;
    delta_H /= SH;
    return sqrt( delta_L * delta_L + delta_C * delta_C + delta_H * delta_H + RT * delta_C * delta_H );
}
</code></pre>

<p>Hope it helps someone :)</p>
",,,8
1313,1325,False,"<p>HSL and HSV are better for human color perception. According to <a href=""http://en.wikipedia.org/wiki/HSL_and_HSV"" rel=""nofollow noreferrer"">Wikipedia</a>:</p>

<blockquote>
  <p>It is sometimes preferable in working with art materials, digitized images, or other media, to use the HSV or HSL color model over alternative models such as RGB or CMYK, because of differences in the ways the models emulate how humans perceive color. RGB and CMYK are additive and subtractive models, respectively, modelling the way that primary color lights or pigments (respectively) combine to form new colors when mixed.</p>
</blockquote>

<p><img src=""https://upload.wikimedia.org/wikipedia/commons/thumb/e/e0/HSV_cylinder.png/200px-HSV_cylinder.png"" alt=""Graphical depiction of HSV""></p>
",39.0,14412.0,4
1313,74033,True,"<p>Convert to La*b* (aka just plain ""Lab"", and you'll also see reference to ""CIELAB"").   A good quick measaure of color difference is   </p>

<blockquote>
  <p>(L1-L2)^2 + (a1-a2)^2 + (b1-b2)^2</p>
</blockquote>

<p>Color scientists have other more refined measures, which may not be worth the bother, depending on accuracy needed for what you're doing.</p>

<p>The <code>a</code> and <code>b</code> values represent opposing colors in a way similar to how cones work, and may be negative or positive.   Neutral colors - white, grays are <code>a=0</code>,<code>b=0</code>. The <code>L</code> is brightness defined in a particular way, from zero (pure darkness) up to whatever.  </p>

<p>Crude explanation :>> Given a color, our eyes distinguish between two broad ranges of wavelength - blue vs longer wavelengths. and then, thanks to a more recent genetic mutation, the longer wavelength cones bifurcated into two, distinguishing for us red vs. green.     </p>

<p>By the way, it'll be great for your career to rise above your color caveman collegues who know of only ""RGB"" or ""CMYK"" which are great for devices but suck for serious perception work.  I've worked for imaging scientists who didn't know a thing about this stuff!</p>

<p>For more fun reading on color difference theory, try:</p>

<ul>
<li><a href=""http://white.stanford.edu/~brian/scielab/introduction.html"" rel=""noreferrer"">http://white.stanford.edu/~brian/scielab/introduction.html</a> and info </li>
<li>and links on color theory in general, websurf starting with <a href=""http://www.efg2.com/Lab/Library/Color/"" rel=""noreferrer"">http://www.efg2.com/Lab/Library/Color/</a> and </li>
<li><a href=""http://www.poynton.com/Poynton-color.html"" rel=""noreferrer"">http://www.poynton.com/Poynton-color.html</a>  </li>
</ul>

<p>More detail on Lab at <a href=""http://en.kioskea.net/video/cie-lab.php3"" rel=""noreferrer"">http://en.kioskea.net/video/cie-lab.php3</a> I can't at this time find a non-ugly page that actually had the conversion formulas but I'm sure someone will edit this answer to include one.</p>
",10468.0,15669.0,43
1313,74396,False,"<p>As someone who is color blind I believe it is good to try to add more separation then normal vision.  The most common form of color blindness is red/green deficiency.  It doesn't mean that you can't see red or green, it means that it is more difficult to see and more difficult to see the differences.  So it takes a larger separation before a color blind person can tell the difference.</p>
",791.0,5058.0,2
1313,25118,False,"<p>The <a href=""http://en.wikipedia.org/wiki/Color_difference"" rel=""nofollow noreferrer"">Wikipedia article on color differences</a> lists a number of color spaces and distance metrics designed to agree with human perception of color distances.</p>
",2686.0,7389.0,3
1313,1348,False,"<p>Well, as a first point of call, I'd say of the common metrics HSV (Hue, Saturation and Value) or HSL are better representative of how humans perceive colour than say RGB or CYMK. See <a href=""http://en.wikipedia.org/wiki/HSL_and_HSV"" rel=""nofollow noreferrer"">HSL, HSV on Wikipedia</a>. </p>

<p>I suppose naively I would plot the points in the HSL space for the two colours and calculate the magnitude of the difference vector. However this would mean that bright yellow and bright green would be considered just as different as green to dark green. But then many consider red and pink two different colours.</p>

<p>Moreover, difference vectors in the same direction in this parameter space are not equal. For instance, the human eye picks up green much better than other colours. A shift in hue from green by the same amount as a shift from red may seem greater. Also a shift in saturation from a small amount to zero is the difference between grey and pink, elsewhere the shift would be the difference between two shades of red.</p>

<p>From a programmers point of view, you would need to plot the difference vectors but modified by a proportionality matrix that would adjust the lengths accordingly in various regions of the HSL space - this would be fairly arbitrary and would be based on various colour theory ideas but be tweaked fairly arbitrarily depending on what you wanted to apply this to.</p>

<p>Even better, you could see if anyone has already done such a thing online...</p>
",199.0,17071.0,2
1313,1322,False,"<p>The easiest <em>distance</em> would of course be to just consider the colors as 3d vectors originating from the same origin, and taking the distance between their end points.</p>

<p>If you need to consider such factors that green is more prominent in judging intensity, you can weigh the values.</p>

<p><a href=""http://www.imagemagick.org/Usage/color/#grayscale"" rel=""nofollow noreferrer"">ImageMagic</a> provides the following scales:  </p>

<ul>
<li>red: 0.3</li>
<li>green: 0.6</li>
<li>blue: 0.1</li>
</ul>

<p>Of course, values like this would only be meaningful in relation to other values for other colors, not as something that would be meaningful to humans, so all you could use the values for would be similiarity ordering.</p>
",267.0,348196.0,2
1314,1359,False,"<p>The CC.Net interface is generated via an XSL transform on your XML files put together as specified in the ccnet.config file for your projects.  The XSL is already written for things like FxCop - check your server's CC xsl directory for examples - shouldn't be too hard to write your own to add in the info - just remember to add the XML output from your tests into the main log.</p>
",35.0,17207.0,1
1314,1319,True,"<p>Not sure if that helps (i found the ccnet Documentation somewhat unhelpful at times):</p>

<p><a href=""http://confluence.public.thoughtworks.org/display/CCNET/Using+CruiseControl.NET+with+MSTest"" rel=""noreferrer"">Using CruiseControl.NET with MSTest</a></p>
",91.0,166977.0,5
1329,2118,False,"<p>I built myself a PC with 4GB RAM, dual core 1.8GHz 40GB PATA drive primary, and 250GB SATA drive secondary, and installed Windows Vista Business Edition. When I had to copy 120GB of data from my old PATA disk, Vista failed miserably and kept crashing. I definitely recommend Teracopy Free Edition.</p>
",389.0,1365.0,1
1329,4061599,False,"<pre><code>Xcopy [source] [destination] /e /c /h /o /d 
</code></pre>

<p>Copies eveverything that has not previously been copied. Essentially works as restartable since you can just press up and enter and it will commence where it was up to when you stoped it or it lost connection. Does not copy files that have already been copied and preserves onwership and attributes.</p>

<p>It also ignores errors so if ti can't copy something it just keeps going.</p>

<p>I remeber it because its xcopy echo(e)d</p>
",492537.0,1.0,0
1329,5280803,False,"<p>A GUI front-end for xcopy is available at:   <a href=""http://lorenstuff.weebly.com/"" rel=""nofollow"">http://lorenstuff.weebly.com/</a>    (free)
controls are:input, output, set switches &amp; run. Not a replacement or an improvement on xcopy, just a GUI to simplify operation.</p>
",656340.0,11.0,1
1329,4061622,False,"<p>Reboot into Linux, mount the drive, and use GNU <code>cp</code>.</p>
",92448.0,20137.0,-2
1329,2971779,False,"<p><a href=""http://www.conceptworld.com/Copywhiz"" rel=""nofollow noreferrer"">Copywhiz</a> program (commercial) seems to solve the exact problems you listed.</p>
",15065.0,6398.0,0
1329,571498,False,"<p>I've tried  <a href=""http://killprog.narod.ru/KCinst.exe"" rel=""nofollow noreferrer"">KillCopy 2.85</a> and I can say only one - this is a powerful copy software which can replace a windows file copy on 100%. May be the best from alternatives that i've tested for now. File transfer is very fast. KillCopy is the fastest software and can copy files with 40 MB/s.
Reasons for my choise is simple - KillCopy works fine on all Windows platforms without mean
whats is architecture - 32 or 64 bits.</p>
",,,1
1329,266099,False,"<p>I've tried out <a href=""http://www.copyhandler.com/"" rel=""nofollow noreferrer"">Copy Handler</a> and it works very well. It has some cool features where you can control buffering depending on the type of media and with file queuing support so you can setup your copy and move operations and forget about them and minimize disk fragmentation at the same time. So it won't copy multiple file simultaneously from a single CD or DVD as it would make the drive seek too much.</p>

<p>Best of all its Open Source.</p>
",28305.0,1221.0,2
1329,244990,False,"<p><a href=""http://www.ztree.com/html/ztreewin.htm"" rel=""nofollow noreferrer"">ZTreeWin</a> It's a 32 bit text-mode, tree-structured file/directory manager for Windows. Very easy to use, there is a menu but this also shows the keys for various commands. Easy to navigate around the file system and it has a has split pane mode so you can work with both source and target easily, with only ever a few keystrokes. It is far more effective for getting things done than Windows Explorer or Xcopy.</p>
",25093.0,9497.0,1
1329,244999,False,"<p>Besides XCOPY, RoboCopy and TeraCopy that have already been suggested, you may also try out Total Commander.</p>
",7053.0,894.0,3
1329,205483,False,"<p>Big thumbs up for robocopy.  I use it for doing the sort of things you mention.</p>

<p>For example I'm currently running 5 robocopy sessions on my server where I'm copying about 60GB of files between 3 remote servers, I'm connected to two via a CheckPoint VPN and the other is an Amazon S3 space mapped via JungleDisk.</p>

<p>I'm working with a colleague at the other end of the country.  He'll log in to the same servers later tonight and run a similar set of robocopy batch files to download all the changes I'm currently uploading.</p>

<p>The 'killer app' feature is that robocopy will retain file date/time stamps and, by default will ONLY copy files that are different.  So you can point it at a huge dir tree and only changed files will be copied.</p>

<p>Here's some useful tips for doing this sort of thing...</p>

<p><code>/MIR</code> mirrors a dir tree so will delete as well as add</p>

<p><code>/R:10</code> tells robocopy to try 10 times to copy the file before giving up.  The default is 1,000,000 times</p>

<p><code>/LOG+somefilename.log</code> will append the screen output to somefilename.log, creating it if necessary.</p>

<p><code>/XD dir1 dir2</code>  will ignore any dirs named dir1 or dir2 in the copy.  Wildcards can be used.</p>

<p><code>/FFT</code> will use FAT time stamps which are less accurate than NTFS (uses a 2 sec granularity in timestamps).  I also find this one useful when copying between Linux file systems and NTFS.</p>

<p>I typically use something like </p>

<pre><code>robocopy d:\workdir y:\workdir /TEE /LOG+:d:\update.log /MIR /R:5
</code></pre>

<p>which will mirror (/MIR) d:\workdir with y:\workdir, append a log of what it does to d:\update.log (/LOG+d:\update.log) writing output to both the console and the log file (/TEE), and try each file 5 times before moving on to the next one.</p>

<p>It also works with UNC paths.</p>

<p>If you've got a large collection of files that need syncing over a number of PCs then robocopy is your friend.</p>
",3099.0,1136.0,4
1329,3829,False,"<p>Powershell scripts might be useful too and surely more flexible than <em>xcopy</em> and other DOS commands. You can easily recurse through sub-directories, filter your files by name or extensions, treat especially some particular files based on the criteria of your choice, etc. The <a href=""http://www.powershellcommunity.org"" rel=""nofollow noreferrer"">Powershell community web site</a> is a good starting point.</p>
",563.0,3743.0,2
1329,3806,False,"<p>Besides the already mentioned Robocopy, <a href=""http://www.xxcopy.com"" rel=""nofollow noreferrer"">XXCOPY</a> has a free version. Its syntax is backwards compatible with XCOPY, but has tons of additional options (XXCOPY /HELP > x create a 42kb file with all the options available). For instance, you can delete files with it, include or exclude a list of directories for the copy, use it as a ""touch"" utility, etc.</p>

<p>I've been using it for years, it's 2 thumbs up.</p>
",394.0,22941.0,1
1329,2126,False,"<p>I would definitely prefer:  </p>

<p>1) <a href=""http://www.codesector.com/teracopy.asp"" rel=""noreferrer"">Teracopy</a> - GUI based, replaces the default Windows copy/move UI and adds itself to context menu. Basic version is free (for home use I guess).  </p>

<p>2) <a href=""http://en.wikipedia.org/wiki/Robocopy"" rel=""noreferrer"">Robocopy</a> - CLI based, useful when scripting. Free tool from MS and is included in Vista/Windows 2008. MS Technet has a GUI for robocopy as well - useful to create statements that you can later embed in scripts or on the command prompt.</p>

<p>PS: I know these have been already suggested here and I would have voted on them, if I could.</p>
",120.0,1197.0,12
1329,2114,False,"<p>I've been using Copy Handler. The nicest thing about it is that it queues up its jobs like a download manager. It has a shell extension so you can either rightclick drag, or just set copy with copyhandler as the default action.</p>
",369.0,92827.0,1
1329,1331,False,"<p>Use <a href=""http://en.wikipedia.org/wiki/Robocopy"" rel=""noreferrer"">Robocopy (Robust File Copy)</a>.</p>

<p>NOTE:</p>

<p>In Windows Vista and Server 2008 when you type:</p>

<pre><code>xcopy /?
</code></pre>

<p>you get:</p>

<blockquote>
  <p>NOTE: Xcopy is now deprecated, please use Robocopy.</p>
</blockquote>

<p>So start getting used to robocopy :)</p>
",39.0,14412.0,57
1329,1381,False,"<p>Use <a href=""http://en.wikipedia.org/wiki/Robocopy"" rel=""nofollow noreferrer"">Robocopy</a>, it has the ability to copy files in ""restartable mode"", plus it should respect the file attributes.  And it comes with Vista and Server 2008, and you can download it for older OS's.  Plus you can set it to retry on failed copies, to pick up files that are temporarily in use by another process.</p>
",206.0,4489.0,3
1329,1353,False,"<p>Xcopy keeps the Date Modified, only the Date Created and Date Accessed will change.</p>

<p>(tested on XP Pro, try it on a small folder to check if you're using Vista as I did not test it under Vista)</p>

<p>Edit: You MAY want to redirect the Output though:</p>

<pre><code>xcopy /K /R ....... s:\*.* t:\ &gt;c:\xcopy.log 2&gt;&amp;1
</code></pre>

<p>That way, if files fail to copy you can check the log (i.e. System Volume Information will generate an error, but that folder does not matter anyway for what you're trying to do)</p>
",91.0,166977.0,1
1329,1339,True,"<p>How about good old Command-Line Xcopy? With S: being the source and T: the target:</p>

<pre><code>xcopy /K /R /E /I /S /C /H /G /X /Y s:\*.* t:\
</code></pre>

<blockquote>
  <p>/K    Copies attributes. Normal Xcopy will reset read-only attributes.</p>
  
  <p>/R    Overwrites read-only files.</p>
  
  <p>/E    Copies directories and subdirectories, including empty ones.</p>
  
  <p>/I    If destination does not exist and copying more than one file, assumes that destination must be a directory.</p>
  
  <p>/S    Copies directories and subdirectories except empty ones.</p>
  
  <p>/C    Continues copying even if errors occur.</p>
  
  <p>/H    Copies hidden and system files also.</p>
  
  <p>/Y    Suppresses prompting to confirm you want to overwrite an existing destination file.</p>
  
  <p>/G    Allows the copying of encrypted files to destination that does not support encryption.</p>
  
  <p>/X    Copies file audit settings (implies /O).</p>
</blockquote>

<p>(Edit: Added /G and /X which are new since a few years)</p>
",91.0,166977.0,20
1329,1341,False,"<p>You can try <a href=""http://sourceforge.net/projects/supercopier/"" rel=""noreferrer"">SuperCopier</a>, it replaces the standard Windows copy mechanism while loaded.</p>

<p>It can retry failed files at the end, resume a canceled copy (even a copy canceled by Windows), accepts ""All"" for every answers. You can even answer the annoying questions (file already exists, error copying file) before they occur.</p>
",268.0,33176.0,6
1329,1337,False,"<p>You really need to use a file Sync tool, like <a href=""http://www.2brightsparks.com/syncback/syncback-hub.html"" rel=""noreferrer"">SyncBackSE</a>, <a href=""http://www.microsoft.com/downloads/details.aspx?familyid=C26EFA36-98E0-4EE9-A7C5-98D0592D8C52&amp;displaylang=en"" rel=""noreferrer"">MS SyncToy</a>, or even something like <a href=""http://winmerge.org/"" rel=""noreferrer"">WinMerge</a> will do the trick.
I prefer SyncBack as it allows you to set up very explicit rules for just about every possible case and conflict, at least more so than the other two.
With any of these you won't have to keep clicking all the pop-ups and you can verify, without a doubt, that the destination is exactly the same as the source.</p>
",194.0,29001.0,7
1329,1335,False,"<p>It sounds like a backup-style tool may be what you're looking for.</p>

<p>I've been using <a href=""http://www.2brightsparks.com/downloads.html"" rel=""nofollow noreferrer"">SyncBack</a> (one of the versions is free). You could also try out <a href=""http://en.wikipedia.org/wiki/SyncToy"" rel=""nofollow noreferrer"">MS SyncToy</a> which tries to make moving, copying, syncing, etc. easy.</p>

<p>If you really do copy just random files at random times, you could try <a href=""http://www.ranvik.net/totalcopy/"" rel=""nofollow noreferrer"">Total Copy</a> which has the added benefit of working well over a network (pause, resume, etc.).</p>
",29.0,96778.0,3
1329,1334,False,"<p>You can try <a href=""http://www.codesector.com/teracopy.php"" rel=""noreferrer"">TeraCopy</a> or <a href=""http://en.wikipedia.org/wiki/Robocopy"" rel=""noreferrer"">RoboCopy</a>.</p>
",267.0,348196.0,15
1383,43756257,False,"<p>Unit-testing and TDD in general enables you to have shorter feedback cycles about the software you are writing. Instead of having a large test phase at the very end of the implementation, you incrementally test everything you write. This increases code quality very much, as you immediately see, where you might have bugs.</p>
",1302116.0,55.0,0
1383,1398,False,"<p>I don't disagree with Dan (although a better choice may just be not to answer)...but...</p>

<p>Unit testing is the process of writing code to test the behavior and functionality of your system.</p>

<p>Obviously tests improve the quality of your code, but that's just a superficial benefit of unit testing. The real benefits are to:</p>

<ol>
<li>Make it easier to change the technical implementation while making sure you don't change the behavior (refactoring). Properly unit tested code can be aggressively refactored/cleaned up with little chance of breaking anything without noticing it.</li>
<li>Give developers confidence when adding behavior or making fixes.</li>
<li>Document your code</li>
<li>Indicate areas of your code that are tightly coupled. It's hard to unit test code that's tightly coupled</li>
<li>Provide a means to use your API and look for difficulties early on</li>
<li>Indicates methods and classes that aren't very cohesive</li>
</ol>

<p>You should unit test because its in your interest to deliver a maintainable and quality product to your client.</p>

<p>I'd suggest you use it for any system, or part of a system, which models real-world behavior. In other words, it's particularly well suited for enterprise development. I would not use it for throw-away/utility programs. I would not use it for parts of a system that are problematic to test (UI is a common example, but that isn't always the case)</p>

<p>The greatest pitfall is that developers test too large a unit, or they consider a method a unit. This is particularly true if you don't understand <a href=""https://en.wikipedia.org/wiki/Inversion_of_control"" rel=""noreferrer"">Inversion of Control</a> - in which case your unit tests will always turn into end-to-end integration testing. Unit test should test individual behaviors - and most methods have many behaviors.</p>

<p>The greatest misconception is that programmers shouldn't test. Only bad or lazy programmers believe that. Should the guy building your roof not test it? Should the doctor replacing a heart valve not test the new valve? Only a programmer can test that his code does what he intended it to do (QA can test edge cases - how code behaves when it's told to do things the programmer didn't intend, and the client can do acceptance test - does the code do what what the client paid for it to do)</p>
",34.0,20440.0,71
1383,31494287,False,"<p>This answers why you should be doing unit testing.</p>

<hr>

<p>The 3 videos below cover unit testing in javascript but the general principles apply across most languages.</p>

<p>Unit Testing: Minutes Now Will Save Hours Later - Eric Mann -  <a href=""https://www.youtube.com/watch?v=_UmmaPe8Bzc"" rel=""nofollow"">https://www.youtube.com/watch?v=_UmmaPe8Bzc</a></p>

<p>JS Unit Testing (very good) - <a href=""https://www.youtube.com/watch?v=-IYqgx8JxlU"" rel=""nofollow"">https://www.youtube.com/watch?v=-IYqgx8JxlU</a></p>

<p>Writing Testable JavaScript - <a href=""https://www.youtube.com/watch?v=OzjogCFO4Zo"" rel=""nofollow"">https://www.youtube.com/watch?v=OzjogCFO4Zo</a></p>

<hr>

<p>Now I'm just learning about the subject so I may not be 100% correct and there's more to it than what I'm describing here but my basic understanding of unit testing is that you write some test code (which is kept separate from your main code) that calls a function in your main code with input (arguments) that the function requires and the code then checks if it gets back a valid return value. If it does get back a valid value the unit testing framework that you're using to run the tests shows a green light (all good) if the value is invalid you get a red light and you then can fix the problem straight away before you release the new code to production, without testing you may actually not have caught the error.</p>

<p>So you write tests for you current code and create the code so that it passes the test. Months later you or someone else need to modify the function in your main code, because earlier you had already written test code for that function you now run again and the test may fail because the coder introduced a logic error in the function or return something completely different than what that function is supposed to return. Again without the test in place that error might be hard to track down as it can possibly affect other code as well and will go unnoticed.</p>

<hr>

<p>Also the fact that you have a computer program that runs through your code and tests it instead of you manually doing it in the browser page by page saves time (unit testing for javascript). Let's say that you modify a function that is used by some script on a web page and it works all well and good for its new intended purpose. But, let's also say for arguments sake that there is another function you have somewhere else in your code that depends on that newly modified function for it to operate properly. This dependent function may now stop working because of the changes that you've made to the first function, however without tests in place that are run automatically by your computer you will not notice that there's a problem with that function until it is actually executed and you'll have to manually navigate to a web page that includes the script which executes the dependent function, only then you notice that there's a bug because of the change that you made to the first function.</p>

<p>To reiterate, having tests that are run while developing your application will catch these kinds of problems as you're coding. Not having the tests in place you'd have to manually go through your whole application and even then it can be hard to spot the bug, naively you send it out into production and after a while a kind user sends you a bug report (which won't be as good as your error messages in a testing framework).</p>

<hr>

<p>It's quite confusing when you first hear of the subject and you think to yourself, am I not already testing my code? And the code that you've written is  working like it is supposed to already, ""why do I need another framework?""... Yes you are already testing your code but a computer is better at doing it. You just have to write good enough tests for a function/unit of code once and the rest is taken care of for you by the mighty cpu instead of you having to manually check that all of your code is still working when you make a change to your code.</p>

<p>Also, you don't have to unit test your code if you don't want to but it pays off as your project/code base starts to grow larger as the chances of introducing bugs increases.</p>
",5040151.0,74.0,1
1383,1393,True,"<p>Unit testing is, roughly speaking, testing bits of your code in isolation with test code. The immediate advantages that come to mind are:</p>

<ul>
<li>Running the tests becomes automate-able and repeatable</li>
<li>You can test at a much more granular level than point-and-click testing via a GUI</li>
</ul>

<p>Note that if your test code writes to a file, opens a database connection or does something over the network, it's more appropriately categorized as an integration test. Integration tests are a good thing, but should not be confused with unit tests. Unit test code should be short, sweet and quick to execute.</p>

<p>Another way to look at unit testing is that you write the tests first. This is known as Test-Driven Development (TDD for short). TDD brings additional advantages:</p>

<ul>
<li>You don't write speculative ""I might need this in the future"" code -- just enough to make the tests pass</li>
<li>The code you've written is always covered by tests</li>
<li>By writing the test first, you're forced into thinking about how you want to call the code, which usually improves the design of the code in the long run.</li>
</ul>

<p>If you're not doing unit testing now, I recommend you get started on it. Get a good book, practically any xUnit-book will do because the concepts are very much transferable between them. </p>

<p>Sometimes writing unit tests can be painful. When it gets that way, try to find someone to help you, and resist the temptation to ""just write the damn code"". Unit testing is a lot like washing the dishes. It's not always pleasant, but it keeps your metaphorical kitchen clean, and you really want it to be clean. :)</p>

<hr>

<p>Edit: One misconception comes to mind, although I'm not sure if it's so common. I've heard a project manager say that unit tests made the team write all the code twice. If it looks and feels that way, well, you're doing it wrong. Not only does writing the tests usually speed up development, but it also gives you a convenient ""now I'm done"" indicator that you wouldn't have otherwise.</p>
",266.0,29506.0,204
1383,25386,False,"<p>Chipping in on the philosophical pros of unit testing and TDD here are a few of they key ""lightbulb"" observations which struck me on my tentative first steps on the road to TDD enlightenment (none original or necessarily news)...</p>

<ol>
<li><p>TDD does NOT mean writing twice the amount of code. Test code is typically fairly quick and painless to write and is a key part of your design process and critically.</p></li>
<li><p>TDD helps you to realize when to stop coding! Your tests give you confidence that you've done enough for now and can stop tweaking and move on to the next thing.</p></li>
<li><p>The tests and the code work together to achieve better code. Your code could be bad / buggy. Your TEST could be bad / buggy. In TDD you are banking on the chances of BOTH being bad / buggy being fairly low. Often its the test that needs fixing but that's still a good outcome. </p></li>
<li><p>TDD helps with coding constipation. You know that feeling that you have so much to do you barely know where to start? It's Friday afternoon, if you just procrastinate for a couple more hours... TDD allows you to flesh out very quickly what you think you need to do, and gets your coding moving quickly. Also, like lab rats, I think we all respond to that big green light and work harder to see it again!</p></li>
<li><p>In a similar vein, these designer types can SEE what they're working on. They can wander off for a juice / cigarette / iphone break and return to a monitor that immediately gives them a visual cue as to where they got to. TDD gives us something similar. It's easier to see where we got to when life intervenes...</p></li>
<li><p>I think it was Fowler who said: ""Imperfect tests, run frequently, are much better than perfect tests that are never written at all"". I interprete this as giving me permission to write tests where I think they'll be most useful even if the rest of my code coverage is woefully incomplete.</p></li>
<li><p>TDD helps in all kinds of surprising ways down the line. Good unit tests can help document what something is supposed to do, they can help you migrate code from one project to another and give you an unwarranted feeling of superiority over your non-testing colleagues :)</p></li>
</ol>

<p><a href=""http://www.masukomi.org/talks/unit_testing_talk_2/index.xul?data=slide_data.txt#page1"" rel=""noreferrer"">This presentation</a> is an excellent introduction to all the yummy goodness testing entails.</p>
",2745.0,9342.0,14
1383,2443018,False,"<p>LibrarIES like <a href=""http://en.wikipedia.org/wiki/NUnit"" rel=""nofollow noreferrer"">NUnit</a>, <a href=""http://en.wikipedia.org/wiki/XUnit"" rel=""nofollow noreferrer"">xUnit</a> or <a href=""http://en.wikipedia.org/wiki/JUnit"" rel=""nofollow noreferrer"">JUnit</a> are just mandatory if you want to develop your projects using the <a href=""http://en.wikipedia.org/wiki/Test-driven_development"" rel=""nofollow noreferrer"">TDD</a> approach popularized by Kent Beck:</p>

<p>You can read <em><a href=""http://www.agiledata.org/essays/tdd.html"" rel=""nofollow noreferrer"">Introduction to Test Driven Development (TDD)</a></em> or Kent Beck's book <em><a href=""https://rads.stackoverflow.com/amzn/click/com/0321146530"" rel=""nofollow noreferrer"" rel=""nofollow noreferrer"">Test Driven Development: By Example</a></em>.</p>

<p>Then, if you want to be sure your tests cover a ""good"" part of your code, you can use software like <a href=""http://en.wikipedia.org/wiki/NCover"" rel=""nofollow noreferrer"">NCover</a>, <a href=""http://www.mmsindia.com/JCover.html"" rel=""nofollow noreferrer"">JCover</a>, <a href=""http://sourceforge.net/projects/partcover/"" rel=""nofollow noreferrer"">PartCover</a> or whatever. They'll tell you the coverage percentage of your code. Depending on how much you're adept at TDD, you'll know if you've practiced it well enough :)</p>
",83125.0,6985.0,4
1383,2443017,False,"<p>Unit testing is a practice to make sure that the function or module which you are going to implement is going to behave as expected (requirements) and also to make sure how it behaves in scenarios like boundary conditions, and invalid input.</p>

<p><a href=""http://en.wikipedia.org/wiki/XUnit"" rel=""nofollow noreferrer"">xUnit</a>, <a href=""http://en.wikipedia.org/wiki/NUnit"" rel=""nofollow noreferrer"">NUnit</a>, <a href=""http://mbunit.com/"" rel=""nofollow noreferrer"">mbUnit</a>, etc. are tools which help you in writing the tests.</p>
",51326.0,8807.0,3
1383,101545,False,"<p>I was never taught unit testing at university, and it took me a while to ""get"" it. I read about it, went ""ah, right, automated testing, that could be cool I guess"", and then I forgot about it.</p>

<p>It took quite a bit longer before I really figured out the point: Let's say you're working on a large system and you write a small module. It compiles, you put it through its paces, it works great, you move on to the next task. Nine months down the line and two versions later someone else makes a change to some <em>seemingly</em> unrelated part of the program, and it breaks the module. Worse, they test their changes, and their code works, but they don't test your module; hell, they may not even know your module <em>exists</em>.</p>

<p>And now you've got a problem: broken code is in the trunk and nobody even knows. The best case is an internal tester finds it before you ship, but fixing code that late in the game is expensive. And if no internal tester finds it...well, that can get very expensive indeed.</p>

<p>The solution is unit tests. They'll catch problems when you write code - which is fine - but you could have done that by hand. The real payoff is that they'll catch problems nine months down the line when you're now working on a completely different project, but a summer intern thinks it'll look tidier if those parameters were in alphabetical order - and then the unit test you wrote way back fails, and someone throws things at the intern until he changes the parameter order back. <strong>That's</strong> the ""why"" of unit tests. :-)</p>
",17086.0,8517.0,35
1383,78737,False,"<p>Use <a href=""http://www.artima.com/weblogs/viewpost.jsp?thread=203994"" rel=""nofollow noreferrer"">Testivus</a>. All you need to know is right there :)</p>
",8026.0,27487.0,3
1383,2443148,False,"<p>I would like to recommend the xUnit Testing Patterns book by Gerard Meszaros.   It's large but is a great resource on unit testing.  Here is a link to his web site where he discusses the basics of unit testing.  <a href=""http://xunitpatterns.com/XUnitBasics.html"" rel=""noreferrer"">http://xunitpatterns.com/XUnitBasics.html</a></p>
",99896.0,2577.0,7
1383,2443012,False,"<p>The main difference of unit testing, as opposed to ""just opening a new project and test this specific code"" is that it's <em>automated</em>, thus <em>repeatable</em>.</p>

<p>If you test your code manually, it may convince you that the code is working perfectly - <em>in its current state</em>. But what about a week later, when you made a slight modification in it? Are you willing to retest it again by hand whenever <em>anything</em> changes in your code? Most probably not :-(</p>

<p>But if you can <strong>run your tests anytime, with a single click, exactly the same way, within a few seconds</strong>, then they <em>will</em> show you immediately whenever something is broken. And if you also integrate the unit tests into your automated build process, they will alert you to bugs even in cases where a seemingly completely unrelated change broke something in a distant part of the codebase - when it would not even occur to you that there is a need to retest that particular functionality.</p>

<p>This is the main advantage of unit tests over hand testing. But wait, there is more:</p>

<ul>
<li>unit tests <strong>shorten the development feedback loop</strong> dramatically: with a separate testing department it may take weeks for you to know that there is a bug in your code, by which time you have already forgotten much of the context, thus it may take you hours to find and fix the bug; OTOH with unit tests, the feedback cycle is measured in seconds, and the bug fix process is typically along the lines of an ""oh sh*t, I forgot to check for that condition here"" :-)</li>
<li>unit tests effectively <strong>document</strong> (your understanding of) the behaviour of your code</li>
<li>unit testing forces you to reevaluate your design choices, which results in <strong>simpler, cleaner design</strong></li>
</ul>

<p>Unit testing frameworks, in turn,  make it easy for you to write and run your tests.</p>
",265143.0,109165.0,44
1383,2443027,False,"<p>I think the point that you don't understand is that unit testing frameworks like NUnit (and the like) will help you in <em>automating</em> small to medium-sized tests. Usually you can run the tests in a GUI (that's the case with <a href=""http://www.nunit.org/"" rel=""nofollow noreferrer"">NUnit</a>, for instance) by simply clicking a button and then - hopefully - see the progress bar stay green. If it turns red, the framework shows you which test failed and what exactly went wrong. In a normal unit test, you often use assertions, e.g. <code>Assert.AreEqual(expectedValue, actualValue, ""some description"")</code> - so if the two values are unequal you will see an error saying ""some description: expected &lt;expectedValue&gt; but was &lt;actualValue&gt;"".</p>

<p>So as a conclusion unit testing will make testing faster and a lot more comfortable for developers. You can run all the unit tests before committing new code so that you don't break the build process of other developers on the same project.</p>
",245706.0,61809.0,3
1383,2443019,False,"<p>First of all, whether speaking about Unit testing or any other kinds of automated testing (Integration, Load, UI testing etc.), the key difference from what you suggest is that it is automated, repeatable and it doesn't require any human resources to be consumed (= nobody has to perform the tests, they usually run at a press of a button).</p>
",199584.0,16387.0,2
1383,2443006,False,"<p>Unit testing is about writing code that tests your application code.</p>

<p>The <em>Unit</em> part of the name is about the intention to test small units of code (one method for example) at a time.</p>

<p>xUnit is there to help with this testing - they are frameworks that assist with this. Part of that is automated test runners that tell you what test fail and which ones pass.</p>

<p>They also have facilities to setup common code that you need in each test before hand and tear it down when all tests have finished.</p>

<p>You can have a test to check that an expected exception has been thrown, without having to write the whole try catch block yourself.</p>
",1583.0,461679.0,3
1383,78695,False,"<p>I use unit tests to save time.</p>

<p>When building business logic (or data access) testing functionality can often involve typing stuff into a lot of screens that may or may not be finished yet. Automating these tests saves time.</p>

<p>For me unit tests are a kind of modularised test harness. There is usually at least one test per public function. I write additional tests to cover various behaviours. </p>

<p><strong>All the special cases that you thought of when developing the code can be recorded in the code in the unit tests. The unit tests also become a source of examples on how to use the code.</strong></p>

<p>It is a lot faster for me to discover that my new code breaks something in my unit tests then to check in the code and have some front-end developer find a problem.</p>

<p>For data access testing I try to write tests that either have no change or clean up after themselves.</p>

<p>Unit tests aren’t going to be able to solve all the testing requirements. They will be able to save development time and test core parts of the application.</p>
",5506.0,3242.0,5
1383,25405,False,"<p>Test Driven Development has sort of taken over the term Unit Test.  As an old timer I will mention the more generic definition of it.</p>

<p>Unit Test also means testing a single component in a larger system. This single component could be a dll, exe, class library, etc.  It could even be a single system in a multi-system application.  So ultimately Unit Test ends up being the testing of whatever you want to call a single piece of a larger system. </p>

<p>You would then move up to integrated or system testing by testing how all the components work together. </p>
",791.0,5058.0,2
1383,23096,False,"<blockquote>
<p>What do you do if you are given a pile of crap and seem like you are stuck in a perpetual state of cleanup that you know with the addition of any new feature or code can break the current set because the current software is like a house of cards?</p>
<p>How can we do unit testing then?</p>
</blockquote>
<p>You start small. The project I just got into had no unit testing until a few months ago. When coverage was that low, we would simply pick a file that had no coverage and click &quot;add tests&quot;.</p>
<p>Right now we're up to over 40%, and we've managed to pick off most of the low-hanging fruit.</p>
<p>(The best part is that even at this low level of coverage, we've already run into many instances of the code doing the wrong thing, and the testing caught it. That's a huge motivator to push people to add more testing.)</p>
",517.0,5768.0,1
1383,23070,False,"<p>I went to a presentation on unit testing at FoxForward 2007 and was told never to unit test anything that works with data. After all, if you test on live data, the results are unpredictable, and if you don't test on live data, you're not actually testing the code you wrote. Unfortunately, that's most of the coding I do these days. :-)</p>

<p>I did take a shot at TDD recently when I was writing a routine to save and restore settings. First, I verified that I could create the storage object. Then, that it had the method I needed to call. Then, that I could call it. Then, that I could pass it parameters. Then, that I could pass it specific parameters. And so on, until I was finally verifying that it would save the specified setting, allow me to change it, and then restore it, for several different syntaxes.</p>

<p>I didn't get to the end, because I needed-the-routine-now-dammit, but it was a good exercise.</p>
",2531.0,1265.0,1
1383,12528,False,"<p>Unit-testing is the testing of a unit of code (e.g. a single function) without the need for the infrastructure that that unit of code relies on. i.e. test it in isolation.</p>

<p>If, for example, the function that you're testing connects to a database and does an update, in a unit test you might not want to do that update. You would if it were an integration test but in this case it's not.</p>

<p>So a unit test would exercise the functionality enclosed in the ""function"" you're testing without side effects of the database update.</p>

<p>Say your function retrieved some numbers from a database and then performed a standard deviation calculation. What are you trying to test here? That the standard deviation is calculated correctly or that the data is returned from the database?</p>

<p>In a unit test you just want to test that the standard deviation is calculated correctly. In an integration test you want to test the standard deviation calculation and the database retrieval.</p>
",1463.0,59177.0,3
1383,1718,False,"<p>This is my take on it. I would say unit testing is the practice of writing software tests to verify that your real software does what it is meant to. This started with <a href=""http://junit.org/"" rel=""noreferrer"">jUnit</a> in the Java world and has become a best practice in PHP as well with <a href=""http://simpletest.org/"" rel=""noreferrer"">SimpleTest</a> and <a href=""http://www.phpunit.de/"" rel=""noreferrer"">phpUnit</a>. It's a core practice of Extreme Programming and helps you to be sure that your software still works as intended after editing. If you have sufficient test coverage, you can do major refactoring, bug fixing or add features rapidly with much less fear of introducing other problems.</p>

<p>It's most effective when all unit tests can be run automatically.</p>

<p>Unit testing is generally associated with OO development. The basic idea is to create a script which sets up the environment for your code and then exercises it; you write assertions, specify the intended output that you should receive and then execute your test script using a framework such as those mentioned above.</p>

<p>The framework will run all the tests against your code and then report back success or failure of each test. phpUnit is run from the Linux command line by default, though there are HTTP interfaces available for it. SimpleTest is web-based by nature and is much easier to get up and running, IMO. In combination with xDebug, phpUnit can give you automated statistics for code coverage which some people find very useful.</p>

<p>Some teams write hooks from their subversion repository so that unit tests are run automatically whenever you commit changes.</p>

<p>It's good practice to keep your unit tests in the same repository as your application.</p>
",137.0,22414.0,4
1390,15209,False,"<p>No. For some things, you will need the <code>.net</code> Framework (like reporting services), and you can't install it (in a supported way) in a server core.</p>
",295.0,56.0,2
1390,18332025,False,"<p>Following are new features for Server 2008 R2 Server Core:</p>

<ul>
<li><p>.NET Framework – 2.0, 3.0, 3.5.1, 4.0 are now supported on Server Core installation</p></li>
<li><p>ASP.NET – as .NET is now supported on Server Core R2 ASP.NET can be enabled</p></li>
<li><p>PowerShell</p></li>
<li><p>AD CS – AD Certificate Services role can be installed on Server Core R2 system</p></li>
</ul>
",1230655.0,1922.0,1
1390,949347,False,"<p>Server Core 2008 R2 can run Sql Server, but this is unsupported (for now). Check <a href=""http://www.nullsession.com/2009/06/02/sql-server-2008-on-server-core-2008-r2/"" rel=""nofollow noreferrer"">http://www.nullsession.com/2009/06/02/sql-server-2008-on-server-core-2008-r2/</a> for an article + video on how it's done.</p>
",,,2
1390,331308,False,"<p>ASP.Net will be enabled on <a href=""http://blogs.technet.com/server_core/archive/2008/11/13/server-core-changes-in-windows-server-2008-r2.aspx"" rel=""nofollow noreferrer"">server core in R2</a>.</p>
",729.0,7611.0,3
1390,30065,False,"<p>Server Core won't be very useful (to me at least, and I think many others as well) until they get a version of .Net framework on it.  Maybe a specialized subset like they have in the Compact Framework on smart phones.</p>
",3043.0,360427.0,1
1390,1394,True,"<p>Not sure how credible <a href=""http://www.builderau.com.au/program/windows/soa/Getting-started-with-Windows-Server-2008-Core-edition/0,339024644,339288700,00.htm"" rel=""noreferrer"">this source is</a>, but:</p>

<blockquote>
  <p>The Windows Server 2008 Core edition can:</p>
  
  <ul>
  <li><p>Run the file server role.</p></li>
  <li><p>Run the Hyper-V virtualization server role.</p></li>
  <li><p>Run the Directory Services role.</p></li>
  <li><p>Run the DHCP server role.</p></li>
  <li><p>Run the IIS Web server role.</p></li>
  <li><p>Run the DNS server role.</p></li>
  <li><p>Run Active Directory Lightweight Directory Services.</p></li>
  <li><p>Run the print server role.</p></li>
  </ul>
  
  <p>The Windows Server 2008 Core edition cannot:</p>
  
  <ul>
  <li><p>Run a SQL Server.</p></li>
  <li><p>Run an Exchange Server.</p></li>
  <li><p>Run Internet Explorer.</p></li>
  <li><p>Run Windows Explorer.</p></li>
  <li><p>Host a remote desktop session.</p></li>
  <li><p>Run MMC snap-in consoles locally.</p></li>
  </ul>
</blockquote>
",91.0,166977.0,16
1401,1527,False,"<p>While I would still like an answer to why my javascript wasn't being recognized, the solution I found in the meantime (and should have done in the first place) is to use an <code>Asp:CompareValidator</code> instead of an <code>Asp:CustomValidator</code>.</p>
",149.0,15905.0,0
1401,1418,True,"<p>Try changing the argument names to <code>sender</code> and <code>args</code>.  And, after you have it working, switch the call over to <code>ScriptManager.RegisterClientScriptBlock</code>, regardless of AJAX use.</p>
",35.0,17207.0,19
1401,1405,False,"<p>When you're using .Net 2.0 and Ajax - you should use:</p>

<pre><code>ScriptManager.RegisterClientScriptBlock
</code></pre>

<p>It will work better in Ajax environments then the old Page.ClientScript version</p>
",225.0,27397.0,7
1401,991196,False,"<p>Also you could use:</p>

<pre><code>var amountDue = document.getElementById('&lt;%=YourControlName.ClientID%&gt;');
</code></pre>

<p>That will automatically resolve the client id for the element without you having to figure out that it's called <code>'ctl00_footerContentHolder_Fees1_FeeDue'</code>.</p>
",75314.0,339.0,0
1408,4824442,False,"<p>If you're trying to get XAMPP to use a network drive as your document root you have to use UNC paths in httpd.conf. XAMPP will not recognize your mapped network drives.</p>

<p>For example the following won't work,
DocumentRoot ""X:/webroot""</p>

<p>But this will,
DocumentRoot ""//192.168.10.100/webroot"" (note the forward slashes, not back slashes)</p>
",593201.0,111.0,11
1408,480089,False,"<p>Solution to allow Apache 2 to host websites outside of htdocs:</p>

<p>Underneath the ""DocumentRoot"" directive in httpd.conf, you should see a directory block. Replace this directory block with:</p>

<pre><code>&lt;Directory /&gt;
    Options FollowSymLinks
    AllowOverride All
    Allow from all
&lt;/Directory&gt; 
</code></pre>

<p><strong><em>REMEMBER NOT TO USE THIS CONFIGURATION IN A REAL ENVIRONMENT</em></strong></p>
",,,8
1408,1421,True,"<p>Ok, per <a href=""https://stackoverflow.com/questions/1408/#2471"">pix0r</a>'s, <a href=""https://stackoverflow.com/questions/1408/#1413"">Sparks</a>' and <a href=""https://stackoverflow.com/questions/1408/#1414"">Dave</a>'s answers it looks like there are three ways to do this:</p>

<hr>

<h2><a href=""https://stackoverflow.com/questions/1408/#2471"">Virtual Hosts</a></h2>

<ol>
<li>Open C:\xampp\apache\conf\extra\httpd-vhosts.conf.</li>
<li>Un-comment ~line 19 (<code>NameVirtualHost *:80</code>).</li>
<li><p>Add your virtual host (~line 36):</p>

<pre><code>&lt;VirtualHost *:80&gt;
    DocumentRoot C:\Projects\transitCalculator\trunk
    ServerName transitcalculator.localhost
    &lt;Directory C:\Projects\transitCalculator\trunk&gt;
        Order allow,deny
        Allow from all
    &lt;/Directory&gt;
&lt;/VirtualHost&gt;
</code></pre></li>
<li><p>Open your hosts file (C:\Windows\System32\drivers\etc\hosts).</p></li>
<li><p>Add</p>

<pre><code>127.0.0.1 transitcalculator.localhost #transitCalculator
</code></pre>

<p>to the end of the file (before the Spybot - Search &amp; Destroy stuff if you have that installed).</p></li>
<li>Save (You might have to save it to the desktop, change the permissions on the old hosts file (right click > properties), and copy the new one into the directory over the old one (or rename the old one) if you are using Vista and have trouble).</li>
<li>Restart Apache.</li>
</ol>

<p>Now you can access that directory by browsing to <a href=""http://transitcalculator.localhost/"" rel=""noreferrer"">http://transitcalculator.localhost/</a>.</p>

<hr>

<h2><a href=""https://stackoverflow.com/questions/1408/#1413"">Make an Alias</a></h2>

<ol>
<li><p>Starting ~line 200 of your <code>http.conf</code> file, copy everything between <code>&lt;Directory ""C:/xampp/htdocs""&gt;</code> and <code>&lt;/Directory&gt;</code> (~line 232) and paste it immediately below with <code>C:/xampp/htdocs</code> replaced with your desired directory (in this case <code>C:/Projects</code>) to give your server the correct permissions for the new directory.</p></li>
<li><p>Find the <code>&lt;IfModule alias_module&gt;&lt;/IfModule&gt;</code> section (~line 300) and add</p>

<pre><code>Alias /transitCalculator ""C:/Projects/transitCalculator/trunk""
</code></pre>

<p>(or whatever is relevant to your desires) below the <code>Alias</code> comment block, inside the module tags.</p></li>
</ol>

<hr>

<h2><a href=""https://stackoverflow.com/questions/1408/#1414"">Change your document root</a></h2>

<ol>
<li><p>Edit ~line 176 in C:\xampp\apache\conf\httpd.conf; change <code>DocumentRoot ""C:/xampp/htdocs""</code> to <code>#DocumentRoot ""C:/Projects""</code> (or whatever you want).</p></li>
<li><p>Edit ~line 203 to match your new location (in this case <code>C:/Projects</code>).</p></li>
</ol>

<hr>

<p><strong>Notes:</strong> </p>

<ul>
<li>You have to use forward slashes ""/"" instead of back slashes ""\"".</li>
<li>Don't include the trailing ""/"" at the end.</li>
<li><em>restart your server</em>.</li>
</ul>
",58.0,43521.0,370
1408,2471,False,"<p>A VirtualHost would also work for this and may work better for you as you can host several projects without the need for subdirectories.  Here's how you do it:</p>

<p>httpd.conf (or extra\httpd-vhosts.conf relative to httpd.conf. Trailing slashes ""\"" might cause it not to work):</p>

<pre><code>NameVirtualHost *:80
# ...
&lt;VirtualHost *:80&gt;  
    DocumentRoot C:\projects\transitCalculator\trunk\
    ServerName transitcalculator.localhost
    &lt;Directory C:\projects\transitCalculator\trunk\&gt;  
        Order allow,deny  
        Allow from all  
    &lt;/Directory&gt;
&lt;/VirtualHost&gt; 
</code></pre>

<p>HOSTS file (c:\windows\system32\drivers\etc\hosts usually):</p>

<pre><code># localhost entries
127.0.0.1 localhost transitcalculator.localhost
</code></pre>

<p>Now restart XAMPP and you should be able to access <a href=""http://transitcalculator.localhost/"" rel=""noreferrer"">http://transitcalculator.localhost/</a> and it will map straight to that directory.</p>

<p>This can be helpful if you're trying to replicate a production environment where you're developing a site that will sit on the root of a domain name.  You can, for example, point to files with absolute paths that will carry over to the server:</p>

<pre><code>&lt;img src=""/images/logo.png"" alt=""My Logo"" /&gt;
</code></pre>

<p>whereas in an environment using aliases or subdirectories, you'd need keep track of exactly where the ""images"" directory was relative to the current file.</p>
",72.0,30561.0,50
1408,1413,False,"<p>You can set Apache to serve pages from anywhere with any restrictions but it's normally distributed in a more secure form.</p>

<p>Editing your apache files (http.conf is one of the more common names) will allow you to set any folder so it appears in your webroot.</p>

<p>EDIT:</p>

<p>alias myapp c:\myapp\</p>

<p>I've edited my answer to include the format for creating an alias in the http.conf file which is sort of like a shortcut in windows or a symlink under un*x where Apache 'pretends' a folder is in the webroot.  This is probably going to be more useful to you in the long term.</p>
",269.0,18803.0,17
1408,1414,False,"<p>You can relocate it by editing the <strong>DocumentRoot</strong> setting in XAMPP\apache\conf\httpd.conf.</p>

<p>It should currently be:</p>

<blockquote>
  <p>C:/xampp/htdocs</p>
</blockquote>

<p>Change it to:</p>

<blockquote>
  <p>C:/projects/transitCalculator/trunk</p>
</blockquote>
",60.0,56986.0,99
1409,27335,True,"<p>My first thought is this. I don't know if it would work but it would only take a few minutes to try.</p>

<p>Create <strong>two</strong> IIS web sites on the same server. The first site is bound to the public IP, but the second site is bound to the private IP. Both point to the same folder on the file system.</p>

<p>Your VPN users will be accessing via the private IP, so you can setup a ""site-wide"" rule on that site that will only affect VPN users. This should work for almost any IIS6 setting, including bandwidth throttling.</p>

<p>Worth a try, at least.</p>

<p>-- 
Edit: Tried this and it worked flawlessly.</p>
",1690.0,30835.0,11
1417,1425,True,"<p>I think that you are after this</p>

<pre><code>$username = $_SERVER['PHP_AUTH_USER'];
$password = $_SERVER['PHP_AUTH_PW'];
</code></pre>
",1384652.0,97775.0,38
1451,4301,False,"<p>Honestly the ASP.NET Membership / Roles features would work perfectly for the scenario you described. Writing your own tables / procs / classes is a great exercise and you can get very nice control over minute details, but after doing this myself I've concluded it's better to just use the built in .NET stuff. A lot of existing code is designed to work around it which is nice at well. Writing from scratch took me about 2 weeks and it was no where near as robust as .NETs. You have to code so much crap (password recovery, auto lockout, encryption, roles, a permission interface, tons of procs, etc) and the time could be better spent elsewhere.</p>

<p>Sorry if I didn't answer your question, I'm like the guy who says to learn c# when someone asks a vb question.</p>
",26.0,18289.0,2
1451,1488,False,"<p>In addition to John Downey and jdecuyper's solutions, I've also added an ""Explicit Deny"" bit at the end/beginning of the bitfield, so that you can perform additive permissions by group, role membership, and then subtract permissions based upon explicit deny entries, much like NTFS works, permission-wise.</p>
",35.0,17207.0,2
1451,1477,True,"<p>I agree with John Downey.</p>

<p>Personally, I sometimes use a flagged enumeration of permissions. This way you can use AND, OR, NOT and XOR bitwise operations on the enumeration's items.</p>

<pre><code>""[Flags]
public enum Permission
{
    VIEWUSERS = 1, // 2^0 // 0000 0001
    EDITUSERS = 2, // 2^1 // 0000 0010
    VIEWPRODUCTS = 4, // 2^2 // 0000 0100
    EDITPRODUCTS = 8, // 2^3 // 0000 1000
    VIEWCLIENTS = 16, // 2^4 // 0001 0000
    EDITCLIENTS = 32, // 2^5 // 0010 0000
    DELETECLIENTS = 64, // 2^6 // 0100 0000
}""
</code></pre>

<p>Then, you can combine several permissions using the AND bitwise operator. <br /><br />
For example, if a user can view &amp; edit users, the binary result of the operation is 0000 0011 which converted to decimal is 3. <br />
You can then store the permission of one user into a single column of your DataBase (in our case it would be 3).<br /><br />
Inside your application, you just need another bitwise operation (OR) to verify if a user has a particular permission or not.</p>
",296.0,3866.0,14
1451,1466,False,"<p>An approach I've used in various applications is to have a generic PermissionToken class which has a changeable Value property.  Then you query the requested application, it tells you which PermissionTokens are needed in order to use it.</p>

<p>For example, the Shipping application might tell you it needs:</p>

<pre><code>new PermissionToken()
{
    Target = PermissionTokenTarget.Application,
    Action = PermissionTokenAction.View,
    Value = ""ShippingApp""
};
</code></pre>

<p>This can obviously be extended to Create, Edit, Delete etc and, because of the custom Value property, any application, module or widget can define its own required permissions.  YMMV, but this has always been an efficient method for me which I have found to scale well.</p>
",192.0,70350.0,0
1451,1459,False,"<p>The way I typically go about coding permission systems is having 6 tables.</p>

<ul>
<li>Users - this is pretty straight forward it is your typical users table</li>
<li>Groups - this would be synonymous to your departments</li>
<li>Roles - this is a table with all permissions generally also including a human readable name and a description</li>
<li>Users_have_Groups - this is a many-to-many table of what groups a user belongs to</li>
<li>Users_have_Roles - another many-to-many table of what roles are assigned to an individual user</li>
<li>Groups_have_Roles - the final many-to-many table of what roles each group has</li>
</ul>

<p>At the beginning of a users session you would run some logic that pulls out every role they have assigned, either directory or through a group. Then you code against those roles as your security permissions.</p>

<p>Like I said this is what I typically do but your millage may vary.</p>
",200.0,12856.0,10
1453,56441212,False,"<p>Improving upon Kevin's answer if you are using PHP 7 you may do:</p>

<pre><code>public function createShipment($startZip, $endZip, $weight=null){
    $weight = $weight ?: $this-&gt;getDefaultWeight();
}
</code></pre>
",800817.0,7214.0,0
1453,31495,False,"<p>You can use a static class member to hold the default:</p>

<pre><code>class Shipment
{
    public static $DefaultWeight = '0';
    public function createShipment($startZip,$endZip,$weight=Shipment::DefaultWeight) {
        // your function
    }
}
</code></pre>
",2976.0,6848.0,1
1453,31831,False,"<p>Neat trick with boolean OR operator:</p>

<pre><code>public function createShipment($startZip, $endZip, $weight = 0){
    $weight or $weight = $this-&gt;getDefaultWeight();
    ...
}
</code></pre>
",2169.0,12473.0,6
1453,2213,False,"<p>This will allow you to pass a weight of 0 and still work properly.  Notice the === operator, this checks to see if weight matches ""null"" in both value and type (as opposed to ==, which is just value, so 0 == null == false).</p>

<p>PHP:</p>

<pre><code>public function createShipment($startZip, $endZip, $weight=null){
    if ($weight === null)
        $weight = $this-&gt;getDefaultWeight();
}
</code></pre>
",72.0,30561.0,1
1453,1456,True,"<p>This isn't much better:</p>

<pre><code>public function createShipment($startZip, $endZip, $weight=null){
    $weight = !$weight ? $this-&gt;getDefaultWeight() : $weight;
}

// or...

public function createShipment($startZip, $endZip, $weight=null){
    if ( !$weight )
        $weight = $this-&gt;getDefaultWeight();
}
</code></pre>
",40.0,12742.0,15
1457,1468,True,"<p>The way to do this is to manipulate <code>location.hash</code> when AJAX updates result in a state change that you'd like to have a discrete URL.  For example, if your page's url is:</p>

<blockquote>
  <p><a href=""http://example.com/"" rel=""nofollow noreferrer"">http://example.com/</a></p>
</blockquote>

<p>If a client side function executed this code:</p>

<pre><code>// AJAX code to display the ""foo"" state goes here.

location.hash = 'foo';
</code></pre>

<p>Then, the URL displayed in the browser would be updated to:</p>

<blockquote>
  <p><a href=""http://example.com/#foo"" rel=""nofollow noreferrer"">http://example.com/#foo</a></p>
</blockquote>

<p>This allows users to bookmark the ""foo"" state of the page, and use the browser history to navigate between states.</p>

<p>With this mechanism in place, you'll then need to parse out the hash portion of the URL on the client side using JavaScript to create and display the appropriate initial state, as fragment identifiers (the part after the #) are not sent to the server.</p>

<p><a href=""http://benalman.com/projects/jquery-hashchange-plugin/"" rel=""nofollow noreferrer"">Ben Alman's hashchange plugin</a> makes the latter a breeze if you're using jQuery.</p>
",60.0,56986.0,116
1457,5801109,False,"<p>It is unlikely the writer wants to reload or redirect his visitor when using Ajax.
But why not use HTML5's <code>pushState</code>/<code>replaceState</code>?</p>

<p>You'll be able to modify the addressbar as much as you like. <a href=""https://www.w3.org/TR/2010/WD-html5-20100624/history.html#history"" rel=""nofollow noreferrer"">Get natural looking urls, with AJAX.</a></p>

<p>Check out the code on my latest project: 
<a href=""http://iesus.se/"" rel=""nofollow noreferrer"">http://iesus.se/</a></p>
",726784.0,171.0,17
1457,6451853,False,"<p>If OP or others are still looking for a way to do modify browser history to enable state, using pushState and replaceState, as suggested by IESUS, is the 'right' way to do it now. It's main advantage over location.hash seems to be that it creates actual urls, not just hashes. If browser history using hashes is saved, and then revisited with javascript disabled, the app won't work, since the hashes aren't sent to the server. However, if pushState has been used, the entire route will be sent to the server, which you can then build to respond appropriately to the routes. I saw an example where the same mustache templates were used on both the server and the client side. If the client had javascript enabled, he would get snappy responses by avoiding the roundtrip to the server, but the app would work perfectly fine without the javascript. Thus, the app can gracefully degrade in the absence of javascript.</p>

<p>Also, I believe there is some framework out there, with a name like history.js. For browsers that support HTML5, it uses pushState, but if the browser doesn't support that, it automatically falls back to using hashes.</p>
",181284.0,2830.0,3
1457,4986440,False,"<p>Look at sites like book.cakephp.org. This site changes the URL without using the hash and use AJAX. I'm not sure how it does it exactly but I've been trying to figure it out. If anyone knows, let me know.</p>

<p>Also github.com when looking at a navigating within a certain project.</p>
",439630.0,177.0,18
1457,3928831,False,"<p>Check if user is 'in' the page, when you click on the url bar, javascript says you are out of page.
If you change the url bar and press 'ENTER' with the symbol '#' within it then you go into the page again, without click on the page manually with mouse cursor, then a keyboad event command (document.onkeypress) from javascript will be able to check if it's enter and active the javascript for redirection.
You can check if user is IN the page with window.onfocus and check if he's out with window.onblur.</p>

<p>Yeah, it's possible.</p>

<p>;)</p>
",475145.0,43.0,2
1457,700173,False,"<p>The window.location.hash method is the preferred way of doing things. For an explanation of how to do it, 
<a href=""http://ajaxpatterns.org/Unique_URLs"" rel=""nofollow noreferrer"">Ajax Patterns - Unique URLs</a>.</p>

<p>YUI has an implementation of this pattern as a module, which includes IE specific work arounds for getting the back button working along with re-writing the address using the hash. <a href=""http://developer.yahoo.com/yui/history/"" rel=""nofollow noreferrer"">YUI Browser History Manager</a>.</p>

<p>Other frameworks have similar implementations as well. The important point is if you want the history to work along with the re-writing the address, the different browsers need different ways of handling it. (This is detailed in the first link article.) </p>

<p>IE needs an iframe based hack, where Firefox will produce double history using the same method.</p>
",,,3
1457,37966,False,"<p>SWFAddress works in Flash &amp; Javascript projects and lets you create bookmarkable URLs (using the hash method mentioned above) as well as giving you back-button support.</p>

<p><a href=""http://www.asual.com/swfaddress/"" rel=""nofollow noreferrer"">http://www.asual.com/swfaddress/</a></p>
",,,3
1457,1465,False,"<p>This is similar to what Kevin said.  You can have your client state as some javascript object, and when you want to save the state, you serialize the object (using JSON and base64 encoding).  You can then set the fragment of the href to this string.</p>

<pre><code>var encodedState = base64(json(state));
var newLocation = oldLocationWithoutFragment + ""#"" + encodedState;

document.location = newLocation; // adds new entry in browser history
document.location.replace(newLocation); // replaces current entry in browser history
</code></pre>

<p>The first way will treat the new state as a new location (so the back button will take them to the previous location).  The latter does not.</p>
",,,11
1476,65057066,False,"<p><strong>I've tried this in Python 3.6.9</strong></p>
<p><strong>Convert Binary to Decimal</strong></p>
<pre><code>&gt;&gt;&gt; 0b101111
47

&gt;&gt;&gt; int('101111',2)
47
</code></pre>
<p><strong>Convert Decimal to binary</strong></p>
<pre><code>&gt;&gt;&gt; bin(47)
'0b101111'
</code></pre>
<p><strong>Place a 0 as the second parameter python assumes it as decimal.</strong></p>
<pre><code>&gt;&gt;&gt; int('101111',0)
101111
</code></pre>
",12415637.0,21.0,0
1476,63297421,False,"<p>Another good method to get an integer representation from binary is to use eval()</p>
<p>Like so:</p>
<pre><code>def getInt(binNum = 0):
    return eval(eval('0b' + str(n)))
</code></pre>
<p>I guess this is a way to do it too.
I hope this is a satisfactory answer :D</p>
",14033284.0,111.0,1
1476,37226387,False,"<blockquote>
  <h1>How do you express binary literals in Python?</h1>
</blockquote>

<p>They're not ""binary"" literals, but rather, ""integer literals"". You can express integer literals with a binary format with a <code>0</code> followed by a <code>B</code> or <code>b</code> followed by a series of zeros and ones, for example:</p>

<pre><code>&gt;&gt;&gt; 0b0010101010
170
&gt;&gt;&gt; 0B010101
21
</code></pre>

<p>From the Python 3 <a href=""https://docs.python.org/3/reference/lexical_analysis.html#integer-literals"" rel=""noreferrer"">docs</a>, these are the ways of providing integer literals in Python:</p>

<blockquote>
  <p>Integer literals are described by the following lexical definitions:</p>

<pre><code>integer      ::=  decinteger | bininteger | octinteger | hexinteger
decinteger   ::=  nonzerodigit ([""_""] digit)* | ""0""+ ([""_""] ""0"")*
bininteger   ::=  ""0"" (""b"" | ""B"") ([""_""] bindigit)+
octinteger   ::=  ""0"" (""o"" | ""O"") ([""_""] octdigit)+
hexinteger   ::=  ""0"" (""x"" | ""X"") ([""_""] hexdigit)+
nonzerodigit ::=  ""1""...""9""
digit        ::=  ""0""...""9""
bindigit     ::=  ""0"" | ""1""
octdigit     ::=  ""0""...""7""
hexdigit     ::=  digit | ""a""...""f"" | ""A""...""F""
</code></pre>
  
  <p>There is no limit for the length of integer literals apart from what
  can be stored in available memory.</p>
  
  <p>Note that leading zeros in a non-zero decimal number are not allowed.
  This is for disambiguation with C-style octal literals, which Python
  used before version 3.0.</p>
  
  <p>Some examples of integer literals:</p>

<pre><code>7     2147483647                        0o177    0b100110111
3     79228162514264337593543950336     0o377    0xdeadbeef
      100_000_000_000                   0b_1110_0101
</code></pre>
  
  <p><em>Changed in version 3.6:</em> Underscores are now allowed for grouping purposes in literals.</p>
</blockquote>

<h2>Other ways of expressing binary:</h2>

<p>You can have the zeros and ones in a string object which can be manipulated (although you should probably just do bitwise operations on the integer in most cases) - just pass int the string of zeros and ones and the base you are converting from (2):</p>

<pre><code>&gt;&gt;&gt; int('010101', 2)
21
</code></pre>

<p>You can optionally have the <code>0b</code> or <code>0B</code> prefix:</p>

<pre><code>&gt;&gt;&gt; int('0b0010101010', 2)
170
</code></pre>

<p>If you pass it <code>0</code> as the base, it will assume base 10 if the string doesn't specify with a prefix:</p>

<pre><code>&gt;&gt;&gt; int('10101', 0)
10101
&gt;&gt;&gt; int('0b10101', 0)
21
</code></pre>

<h2>Converting from int back to human readable binary:</h2>

<p>You can pass an integer to bin to see the string representation of a binary literal:</p>

<pre><code>&gt;&gt;&gt; bin(21)
'0b10101'
</code></pre>

<p>And you can combine <code>bin</code> and <code>int</code> to go back and forth:</p>

<pre><code>&gt;&gt;&gt; bin(int('010101', 2))
'0b10101'
</code></pre>

<p>You can use a format specification as well, if you want to have minimum width with preceding zeros:</p>

<pre><code>&gt;&gt;&gt; format(int('010101', 2), '{fill}{width}b'.format(width=10, fill=0))
'0000010101'
&gt;&gt;&gt; format(int('010101', 2), '010b')
'0000010101'
</code></pre>
",541136.0,286899.0,33
1476,37955839,False,"<p>0 in the start here specifies that the base is 8 (not 10), which is pretty easy to see: </p>

<pre><code>&gt;&gt;&gt; int('010101', 0)
4161
</code></pre>

<p>If you don't start with a 0, then python assumes the number is base 10.</p>

<pre><code>&gt;&gt;&gt; int('10101', 0)
10101
</code></pre>
",6496481.0,23.0,2
1476,1484,False,"<pre><code>&gt;&gt;&gt; print int('01010101111',2)
687
&gt;&gt;&gt; print int('11111111',2)
255
</code></pre>

<p>Another way.</p>
",2089740.0,16086.0,75
1476,1479,False,"<p>I am pretty sure this is one of the things due to change in Python 3.0 with perhaps bin() to go with hex() and oct().</p>

<p>EDIT:
lbrandy's answer is correct in all cases.</p>
",269.0,18803.0,-3
1476,13107,True,"<p>For reference&mdash;<em>future</em> Python possibilities:<br>
Starting with Python 2.6 you can express binary literals using the prefix <strong>0b</strong> or <strong>0B</strong>:</p>

<pre><code>&gt;&gt;&gt; 0b101111
47
</code></pre>

<p>You can also use the new <strong>bin</strong> function to get the binary representation of a number:</p>

<pre><code>&gt;&gt;&gt; bin(173)
'0b10101101'
</code></pre>

<p>Development version of the documentation: <a href=""http://docs.python.org/dev/whatsnew/2.6.html#pep-3127-integer-literal-support-and-syntax"" rel=""noreferrer"">What's New in Python 2.6</a></p>
",1531.0,4020.0,317
1476,1478,False,"<p>As far as I can tell Python, up through 2.5, only supports hexadecimal &amp; octal literals.  I did find some discussions about adding binary to future versions but nothing definite.</p>
",305.0,134360.0,-1
1496,1517,True,"<p><strong>MacVim</strong> works well and certainly looks more mature than Vim-Cocoa, moreover there is a Cocoa plugin architecture in the pipeline for MacVim (and someone is already working on a TextMate style file browser tray plugin which is a huge ++ IMHO).</p>

<p>There was also a Carbon version of Vim, but this didn't offer a great deal over the Terminal version. i.e. only allowed one window open, not very OSX in appearance...</p>

<p><strong>Aquamacs</strong> is very usable and looks pretty good. Supports both traditional Mac OS style keyboard shortcuts (command-O, command-S) and the Control/Meta shortcuts for those raised on traditional Emacs. It is definitely more Mac-like than Carbon Emacs. It seems stable and fast, but I am not an Emacs guru so I don't stress it all that much when I use it. I can't speak to the extensiveness of the included elisp packages, either.</p>

<p>Someone syncs Carbon Emacs with the upstream tree quarterly I think. Aquamacs has a more irregular schedule, but it's seen some pretty major updates over the last year.</p>

<p><strong>GNU Emacs</strong> for OSX can be found at <a href=""http://emacsformacosx.com"" rel=""nofollow noreferrer"">emacsformacosx.com</a>. In addition to the latest stable release, there are also pre-release test builds and nightly builds, and Atom feeds are provided for tracking all three release types.</p>
",199.0,17071.0,21
1496,110346,False,"<p>Of the emacsen for Mac OS X, I have to say that after the console version of 22, CarbonEmacs is the most usable. <a href=""http://en.wikipedia.org/wiki/Aquamacs"" rel=""nofollow noreferrer"">Aquamacs</a> just does too many non-standard, read unexpected, things with configuration. Aquamacs questions generally aren't answered in any sort of timely manner in #emacs on freenode for whatever that is worth. It seem to be held in disdain simply because it does such a terrible job of handling standard configuration options in .emacs.</p>
",10738.0,24448.0,1
1496,175287,False,"<p>I prefer <a href=""http://en.wikipedia.org/wiki/Vim_%28text_editor%29"" rel=""nofollow noreferrer"">Vim</a> built from the Subversion repository. I run it in the console where I don't need to use the mouse while editing.</p>
",25007.0,739.0,0
1496,199136,False,"<p>I'm using <a href=""http://code.google.com/p/macvim/"" rel=""nofollow noreferrer"">MacVim</a> on Mac OS X. It's very, very nice.</p>
",,,2
1496,98677,False,"<p>Emacs 22 has worked pretty well for me.</p>
",18432.0,173.0,0
1496,86319,False,"<p>I love CarbonEmacs because it sticks very close to the standard GNU Emacs distribution, while still fitting in nicely with the Mac desktop.  To me, it ""felt"" like Emacs on my Ubuntu desktop even if it looked like a Mac application.</p>
",32538.0,27625.0,0
1496,69186,False,"<p>Personally, I've been using <a href=""http://www.finkproject.org/"" rel=""nofollow noreferrer"">fink</a> to install <a href=""http://www.xemacs.org"" rel=""nofollow noreferrer"">xemacs</a>.  It requires X but I've been
using xemacs for so long that I need what it has.</p>

<p>Additionally, I have installed <a href=""http://www.gnu.org/software/emacs"" rel=""nofollow noreferrer"">gnu emacs</a>.  It's nice because it is a completely
integrated mac os x application with a dock icon and everything.  I find it useful
when dragging a file on top of the gnu emacs icon to open it.</p>

<p>Last, I should mention that mac os x uses the emacs keystrokes all over the place.
stuff like ^A for beginning of text, ^E for end of text, ^N next line, ^P previous
line, etc...  These work in most text boxes throughout the OS.</p>
",9593.0,1527.0,2
1496,47577,False,"<p>I like the Nextstep-derived Emacs.app formerly at <a href=""http://emacs-app.sourceforge.net/"" rel=""nofollow noreferrer"">http://emacs-app.sourceforge.net/</a> now integrated in Emacs-23 CVS (as of August 2008). </p>

<p>Emacs.app feels more zippy than Aquamacs to me but its just bare CVS-Emacs and doesn't come with the same amount of stuff (you have to install your own AucTeX etc.).</p>
",4912.0,437.0,2
1496,34288,False,"<p>Some time ago, I was searching for a text editor for my new Mac. Since this was some months ago, some points might have been corrected in the meantime.<br>
I feel that Aquamacs is by far the best OSX-Emacs. However, it feels a bit too Mac-like in some areas. For example, it rather uses several windows instead of several buffers and the coloring schemes are not ""normal"" Emacs-style.<br>
If you look for a more basic set, Carbon Emacs might do it as well, though you might want to add some additional packages to add PHP support or AucTeX.<br>
Emacs.app feels broken in my oppinion. It not even opens files using drag and drop.</p>
",1034.0,14806.0,1
1496,29905,False,"<p>I use the CarbonEmacs version on the Macports progam. It installs all the dependencies with just one line:</p>

<pre><code>sudo port install emacs
</code></pre>

<p>For anyone intesrested in Macports (www.macports.org)</p>
",2937.0,7087.0,1
1496,23017,False,"<p>I get all my unixish/GNU support using <A href=""http://www.finkproject.org/"" rel=""nofollow noreferrer"">Fink</A> (which provides Debian-like package control) with the emacs22-carbon package which means I also get a clickable application. It does everything I expect it to do, and automagically starts using emacs extensions loaded with fink.</p>

<p>Good times.</p>
",2509.0,90091.0,1
1496,13126,False,"<p>I just download the Emacs source from the GNU site and build it myself.  I don't like too many Mac-specific features, because I want Emacs behavior to be consistent on all the platforms I use.</p>
",1175.0,74573.0,3
1496,1561,False,"<p>I've tried Aquamacs and it's very usable and looks pretty good.  Supports both traditional Mac OS style keyboard shortcuts (command-O, command-S) and the Control/Meta shortcuts for those raised on traditional Emacs.  It is definitely more Mac-like than Carbon Emacs.  It seems stable and fast, but I am not an Emacs guru so I don't stress it all that much when I use it.  I can't speak to the extensiveness of the included elisp packages, either.  </p>

<p>Someone syncs Carbon Emacs with the upstream tree quarterly I think.  Aquamacs has a more irregular schedule, but it's seen some pretty major updates over the last year.</p>
",153.0,1703.0,5
1503,1514,True,"<p>From some of the initial research it doesn't appear to be a super simple solution. </p>

<p>It appears that doing this involves having Visual Studio 2008 actually installed on the continuous integration server, which could be a deal breaker.</p>

<p>Then configure the MSTest.exe to run in the tasks list, but first you'll have to make a batch file to delete the results files from previous passes as this file's existence causes an error.</p>

<p>Then create a xslt to format the results and put it into the dashboard.config file.</p>

<p>The code project article I found has a lot more detail.</p>

<p><a href=""http://www.codeproject.com/KB/tips/VSTS2008_Tests_With_CCNET.aspx"" rel=""nofollow noreferrer"">Integrating Visual Studio Team System 2008 Unit Tests with CruiseControl.NET</a></p>
",27.0,1481.0,10
1505,65310987,False,"<p>I use <a href=""https://realfavicongenerator.net/"" rel=""nofollow noreferrer"">RealFaviconGenerator</a> to generate favicons and code for many browsers and platforms.</p>
",,,0
1505,3507075,True,"<p>See the <strong><a href=""https://developer.apple.com/library/archive/documentation/AppleApplications/Reference/SafariWebContent/ConfiguringWebApplications/ConfiguringWebApplications.html#//apple_ref/doc/uid/TP40002051-CH3-SW4"" rel=""nofollow noreferrer"">Specifying a Webpage Icon for Web Clip</a></strong> section of the <em>Configuring Web Applications</em> page of the <em>Safari Web Content Guide</em> in the <em>Safari Reference Library</em>.</p>

<blockquote>
  <h2>Specifying a Webpage Icon for Web Clip</h2>
  
  <p>You may want users to be able to add your web application or webpage link to the Home screen. These links, represented by an icon, are called Web Clips. Follow these simple steps to specify an icon to represent your web application or webpage on iOS.</p>
  
  <ul>
  <li><p>To specify an icon for the entire website (every page on the website), place an icon file in PNG format in the root document folder called <code>apple-touch-icon.png</code>.</p></li>
  <li><p>To specify an icon for a single webpage or replace the website icon with a webpage-specific icon, add a link element to the webpage, as in:<br>
  <code>&lt;link rel=""apple-touch-icon"" href=""/custom_icon.png""/&gt;</code><br>
  In the above example, replace <code>custom_icon.png</code> with your icon filename.</p></li>
  </ul>
  
  <hr>
  
  <p><strong>Note:</strong> Safari on iOS 7 doesn’t add effects to icons. Older versions of Safari will not add effects for icon files named with the <code>-precomposed.png</code> suffix. See First Steps: Identifying Your App in iTunes Connect for details.</p>
</blockquote>
",83.0,52898.0,4
1505,1506,False,"<p>From the Apple Developer Connection Safari Web Content Guide for iPhone page <a href=""https://developer.apple.com/library/archive/documentation/AppleApplications/Reference/SafariWebContent/ConfiguringWebApplications/ConfiguringWebApplications.html"" rel=""nofollow noreferrer"">Specifying a Webpage Icon for Web Clip</a>...</p>

<blockquote>
  <p>The user can add a web application or
  webpage link to the Home screen. These
  links, represented by an icon, are
  called web clips. Follow these simple
  steps to specify an icon to represent
  your web application or webpage on
  iPhone.</p>
  
  <p>To specify an icon for the entire
  website (every page on the website),
  place an icon file in PNG format in
  the root document folder called
  apple-touch-icon.png.</p>
  
  <p>To specify an icon for a single
  webpage, or replace the website icon
  with a webpage-specific icon, add a
  link element to the webpage as in:</p>
  
  <p><code>&lt;link rel=""apple-touch-icon"" href=""/custom_icon.png""/&gt;</code></p>
  
  <p>In the above example, replace
  custom_icon.png with your icon
  filename.</p>
  
  <p>See ""Create an Icon for Your Web
  Application or Webpage"" in iPhone
  Human Interface Guidelines in iPhone
  Human Interface Guidelines for webpage
  icon metrics.</p>
  
  <p>Note: The web clip feature is
  available in iPhone 1.1.3 and later.</p>
</blockquote>
",83.0,52898.0,5
1505,44412724,False,"<p>Add this in your head section:<code>&lt;link rel=""icon"" href=""/your-icon-url""/&gt;</code></p>
",7855854.0,278.0,2
1505,1509,False,"<p>And for the sake of completeness, a link to Scott Hanselman's posting, which contains some additional tips as well:</p>

<p><a href=""http://www.hanselman.com/blog/MakeYourWebsiteMobileAndIPhoneFriendlyAddHomeScreenIPhoneIconsAndAdjustTheViewPort.aspx"" rel=""noreferrer"">Add Home Screen iPhone Icons and Adjust the ViewPort</a></p>
",91.0,166977.0,8
1508,272695,False,"<p><a href=""http://hanselminutes.com/default.aspx?showID=126"" rel=""nofollow noreferrer"">This</a> episode of HanselMinutes covers exactly what I was hoping to hear. Apparently Git can be used locally then attached to external subversion/vss repositories as need. They talk about it 14 ~ 15 minutes in. </p>
",149.0,15905.0,0
1508,14488,False,"<p>some day i work in a company that use VSS (and in other companies that use other less unknow <a href=""http://en.wikipedia.org/wiki/Source_Code_Management"" rel=""nofollow noreferrer"">SCM</a>) but i prefer use SVN (someday i'll try GIT) for active development, for me and my group.</p>

<p>First of all, this situation it's only good idea, if commit to VSS are few over month, because working with other SCM (than VSS) give you more flexiblity, but commint to VSS from SVN is expensive in time.</p>

<p>My solution was:</p>

<p>VSS -> SVN: I have linux script (or ant script, or XXX script) that copy from currrent update directory work of VSS to current SVN, then refresh SVN client and update/merge/commit to SVN. With this, you are update from changes of the rest of company that use VSS.</p>

<p>SVN -> VSS: In this way, you need a checkout of all your modify files to VSS, then you can simply use the reverse script to copy from current update SVN directory (ignore .svn directories) and copy to current update VSS directory, update and commit.</p>

<p>But remember, in a few case does worth your time to do this.</p>
",1713.0,151.0,0
1508,1525,True,"<p>Well... KernelTrap has <a href=""http://kerneltrap.org/mailarchive/git/2008/5/27/1952124"" rel=""nofollow noreferrer"">something on this</a>.  Looks like you can use <a href=""http://www.pumacode.org/projects/vss2svn/wiki/RunningTheMigration"" rel=""nofollow noreferrer"">vss2svn</a> to pipe the Source Safe repo into a Subversion repository, then use the very nice git-svn to pull into a local git repo.</p>

<p>I would assume the commits back to VSS would not be a smooth, automatic process using this method.</p>
",59.0,5877.0,1
1508,1515,False,"<p>You should be able to check out the current version of the code and then create a git repository around it. Updating that and committing it to your local git repository should be painless. As should cloning it.</p>

<p>The only catch is that you need to have them both ignore each other (I've done something similar with SVN) by messing with the appropriate ignore files. I'm presuming SourceSafe let's you ignore things. And you'll need to do certain operations twice (like telling both that you are deleting a file).</p>
",2089740.0,16086.0,1
1528,58344418,False,"<p>While clearly stated above that it is not possible in C# to change the access modifiers on inherited methods and properties, I overcame this issue through a sort of ""fake inheritance"" using implicit casting.</p>

<p><strong>Example:</strong></p>

<pre><code>public class A
{
      int var1;
      int var2;

      public A(int var1, int var2)
      {
            this.var1 = var1;
            this.var2 = var2;
      }
      public void Method1(int i)
      {
            var1 = i;
      }
      public int Method2()
      {
            return var1+var2;
      }
}
</code></pre>

<p>Now lets say you want a <code>class B</code> to inherit from <code>class A</code>, but want to change some accessibility or even change Method1 entirely</p>

<pre><code>public class B
{
      private A parent;

      public B(int var1, int var2)
      {
            parent = new A(var1, var2);
      } 

      int var1 
      {
            get {return this.parent.var1;}
      }
      int var2 
      {
            get {return this.parent.var2;}
            set {this.parent.var2 = value;}
      }

      public Method1(int i)
      {
            this.parent.Method1(i*i);
      }
      private Method2()
      {
            this.parent.Method2();
      }


      public static implicit operator A(B b)
      {
            return b.parent;
      }
}
</code></pre>

<p>By including the implicit cast at the end, it allows us to treat <code>B</code> objects as <code>A</code>s when we need to. It can also be useful to define an implicit cast from <code>A-&gt;B</code>.</p>

<p>The biggest flaw to this approach is that you need to re-write every method/property that you intend to ""inherit"".
There's probably even more flaws to this approach, but I like to use it as a sort of ""fake inheritance"". </p>

<p><strong>Note:</strong></p>

<p>While this allows for changing the accessibility of <code>public</code> properties, it doesn't solve the issue of making <code>protected</code> properties public.</p>
",11903389.0,11.0,1
1528,47255529,False,"<p>You can use an interface</p>

<pre><code>    public static void Main()
    {
        NoRemoveList&lt;string&gt; testList = ListFactory&lt;string&gt;.NewList();

        testList.Add("" this is ok "");

        // not ok
        //testList.RemoveAt(0);
    }

    public interface NoRemoveList&lt;T&gt;
    {
        T this[int index] { get; }
        int Count { get; }
        void Add(T item);
    }

    public class ListFactory&lt;T&gt;
    {
        private class HiddenList: List&lt;T&gt;, NoRemoveList&lt;T&gt;
        {
            // no access outside
        }

        public static NoRemoveList&lt;T&gt; NewList()
        {
            return new HiddenList();
        }
    }
</code></pre>
",8930048.0,1.0,0
1528,17283870,False,"<p>To fully hide and mark not to use, including intellisense which I believe is what most readers expect ...</p>

<pre><code>[Obsolete(""Not applicable in this class."")] 
[DesignerSerializationVisibility(DesignerSerializationVisibility.Hidden)]
[Browsable(false), EditorBrowsable(EditorBrowsableState.Never)]
</code></pre>
",2164277.0,548.0,4
1528,10717931,False,"<p>I tested all of the proposed solutions and they do not really hide new members.</p>

<p>But this one DOES: </p>

<pre><code>[DesignerSerializationVisibility(DesignerSerializationVisibility.Hidden)]
public new string MyHiddenProperty
{ 
    get { return _myHiddenProperty; }
}
</code></pre>

<p>But in code-behide it's still accessible, so add as well Obsolete Attribute</p>

<pre><code>[Obsolete(""This property is not supported in this class"", true)]
[DesignerSerializationVisibility(DesignerSerializationVisibility.Hidden)]
public new string MyHiddenProperty
{ 
    get { return _myHiddenProperty; }
}
</code></pre>
",1271344.0,11.0,1
1528,4392227,False,"<p>I know there's been several answers to this, and it's quite old now, but the simplest method to do this is just declare them as <code>new private</code>.</p>

<p>Consider an example I am currently working on, where I have an API that makes available every method in a 3rd party DLL. I have to take their methods, but I want to use a .Net property, instead of a ""getThisValue"" and ""setThisValue"" method. So, I build a second class, inherit the first, make a property that uses the get and set methods, and then override the original get and set methods as private. They're still available to anyone wanting to build something different on them, but if they just want to use the engine I'm building, then they'll be able to use properties instead of methods.</p>

<p>Using the double class method gets rid of any restrictions on being unable to use the <code>new</code> declaration to hide the members. You simply can't use <code>override</code> if the members are marked as virtual.</p>

<pre><code>public class APIClass
{
    private static const string DllName = ""external.dll"";

    [DllImport(DllName)]
    public extern unsafe uint external_setSomething(int x, uint y);

    [DllImport(DllName)]
    public extern unsafe uint external_getSomething(int x, uint* y);

    public enum valueEnum
    {
        On = 0x01000000;
        Off = 0x00000000;
        OnWithOptions = 0x01010000;
        OffWithOptions = 0x00010000;
    }
}

public class APIUsageClass : APIClass
{
    public int Identifier;
    private APIClass m_internalInstance = new APIClass();

    public valueEnum Something
    {
        get
        {
            unsafe
            {
                valueEnum y;
                fixed (valueEnum* yPtr = &amp;y)
                {
                    m_internalInstance.external_getSomething(Identifier, yPtr);
                }
                return y;
            }
        }
        set
        {
            m_internalInstance.external_setSomething(Identifier, value);
        }
    }

    new private uint external_setSomething(int x, float y) { return 0; }
    new private unsafe uint external_getSomething(int x, float* y) { return 0; }
}
</code></pre>

<p>Now valueEnum is available to both classes, but only the property is visible in the APIUsageClass class. The APIClass class is still available for people who want to extend the original API or use it in a different way, and the APIUsageClass is available for those who want something more simple.</p>

<p>Ultimately, what I'll be doing is making the APIClass internal, and only expose my inherited class.</p>
",193939.0,5706.0,3
1528,1533,False,"<p>While you cannot prevent usage of those inherited members to my knowledge, you should be able to hide them from IntelliSense using the <a href=""http://msdn.microsoft.com/en-us/library/system.componentmodel.editorbrowsableattribute.aspx"" rel=""noreferrer"">EditorBrowsableAttribute</a>:</p>

<pre><code>Using System.ComponentModel;

[EditorBrowsable(EditorBrowsableState.Never)]
private string MyHiddenString = ""Muahahahahahahahaha"";
</code></pre>

<p><em>Edit:</em> Just saw this in the documentation comments, which makes it kinda useless for this purpose:</p>

<blockquote>
  <p>There is a prominent note that states that this attribute ""does not suppress members from a class in the same assembly"". That is true but not complete. Actually, the attribute does not suppress members from a class in the same solution.</p>
</blockquote>
",91.0,166977.0,19
1528,1556,True,"<p>Override them like Michael Suggests <a href=""https://stackoverflow.com/questions/1528/#1533"">above</a> and to prevent folks from using the overridden (sp?) methods, mark them as obsolete:</p>

<pre><code>[Obsolete(""These are not supported in this class."", true)]
public override  void dontcallmeanymore()
{
}
</code></pre>

<p>If the second parm is set to true, a compiler error will be generated if anyone tries to  call that method and the string in the first parm is the message.  If parm2 is false only a compiler warning will be generated.</p>
",313.0,7150.0,36
1528,1536,False,"<p>One potential thing you can do is contain the object rather than extend from the other class.  This will give you the most flexibility in terms of exposing what you want to expose, but if you absolutely need the object to be of that type it is not the ideal solution (however you could expose the object from a getter).</p>

<p>Thus:</p>

<pre><code>public class MyClass : BaseClass
{
    // Your stuff here
}
</code></pre>

<p>Becomes:</p>

<pre><code>public class MyClass
{
    private BaseClass baseClass;

    public void ExposeThisMethod()
    {
        baseClass.ExposeThisMethod();
    }
}
</code></pre>

<p>Or:</p>

<pre><code>public class MyClass
{
    private BaseClass baseClass;

    public BaseClass BaseClass
    {
        get
        {
            return baseClass;
        }
    }
}
</code></pre>
",122.0,42831.0,14
1528,1534,False,"<p>I think you're best least hackish way is to consider composition as opposed to inheritance.</p>

<p>Or, you could create an interface that has the members you want, have your derived class implement that interface, and program against the interface.</p>
",34.0,20440.0,8
1535,2047,True,"<p>This looks like an excellent opportunity to have a look at Aspect Oriented Programming. Here is a good article on <a href=""https://docs.microsoft.com/en-us/archive/blogs/simonince/aspect-oriented-interception"" rel=""nofollow noreferrer"">AOP in .NET</a>. The general idea is that you'd extract the cross-functional concern (i.e. Retry for x hours) into a separate class and then you'd annotate any methods that need to modify their behaviour in that way. Here's how it might look (with a nice extension method on Int32)</p>
<pre><code>[RetryFor( 10.Hours() )]
public void DeleteArchive()
{
  //.. code to just delete the archive
}
</code></pre>
",358.0,49442.0,14
1535,3697548,False,"<p>Here's what I did recently. It has probably been done elsewhere better, but it seems pretty clean and reusable.</p>

<p>I have a utility method that looks like this:</p>

<pre><code>    public delegate void WorkMethod();

    static public void DoAndRetry(WorkMethod wm, int maxRetries)
    {
        int curRetries = 0;
        do
        {
            try
            {
                wm.Invoke();
                return;
            }
            catch (Exception e)
            {
                curRetries++;
                if (curRetries &gt; maxRetries)
                {
                    throw new Exception(""Maximum retries reached"", e);
                }
            }
        } while (true);
    }
</code></pre>

<p>Then in my application, I use c#'s Lamda expression syntax to keep things tidy:</p>

<pre><code>Utility.DoAndRetry( () =&gt; ie.GoTo(url), 5);
</code></pre>

<p>This calls my method and retries up to 5 times. At the fifth attempt, the original exception is rethrown inside of a retry exception.</p>
",435024.0,726.0,2
1535,4601,False,"<p>You could also use a more OO approach:</p>

<ul>
<li>Create a base class that does the error handling and calls an abstract method to perform the concrete work. (Template Method pattern)</li>
<li>Create concrete classes for each operation.</li>
</ul>

<p>This has the advantage of naming each type of operation you perform and gives you a Command pattern - operations have been represented as objects.</p>
",608.0,10469.0,2
1535,1554,False,"<p>Just wondering, what do you feel your method leaves to be desired?  You could replace the anonymous delegate with a.. named? delegate, something like</p>

<pre><code>    public delegate void IoOperation(params string[] parameters);

    public void FileDeleteOperation(params string[] fileName)
    {
        File.Delete(fileName[0]);
    }

    public void FileCopyOperation(params string[] fileNames)
    {
        File.Copy(fileNames[0], fileNames[1]);
    }

    public void RetryFileIO(IoOperation operation, params string[] parameters)
    {
        RetryTimer fileIORetryTimer = new RetryTimer(TimeSpan.FromHours(10));
        bool success = false;
        while (!success)
        {
            try
            {
                operation(parameters);
                success = true;
            }
            catch (IOException e)
            {
                if (fileIORetryTimer.HasExceededRetryTimeout)
                {
                    throw;
                }
                fileIORetryTimer.SleepUntilNextRetry();
            }
        }
    }

    public void Foo()
    {
        this.RetryFileIO(FileDeleteOperation, ""L:\file.to.delete"" );
        this.RetryFileIO(FileCopyOperation, ""L:\file.to.copy.source"", ""L:\file.to.copy.destination"" );
    }
</code></pre>
",96.0,32474.0,4

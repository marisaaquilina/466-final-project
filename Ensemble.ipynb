{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import mstats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10162\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"datasets/features_with_politeness.csv\", lineterminator='\\n', encoding=\"ISO-8859-1\").dropna()\n",
    "df['q_score'] = df['answer_score'] - df['a_score_rel_q_score']\n",
    "df.head()\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [\n",
    "       'entities_matches', 'reputation', 'reply_by_author', 'len_answer_text',\n",
    "       'is_accepted', 'code_snippet_count', 'link_count', 'Hedges',\n",
    "       'Positive.Emotion', 'Negative.Emotion', 'Impersonal.Pronoun',\n",
    "       'Swearing', 'Negation', 'Filler.Pause', 'Informal.Title',\n",
    "       'Formal.Title', 'Could.You', 'Can.You', 'By.The.Way', 'Let.Me.Know',\n",
    "       'Goodbye', 'For.Me', 'For.You', 'Reasoning', 'Reassurance',\n",
    "       'Ask.Agency', 'Give.Agency', 'Hello', 'Please', 'First.Person.Plural',\n",
    "       'First.Person.Single', 'Second.Person', 'Agreement', 'Acknowledgement',\n",
    "       'Subjectivity', 'Bare.Command', 'WH.Questions', 'YesNo.Questions',\n",
    "       'Gratitude', 'Apology', 'Truth.Intensifier', 'Affirmation',\n",
    "       'Adverb.Just', 'Conjunction.Start', 'q_score']\n",
    "\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(df[features])\n",
    "X = scaler.transform(df[features])\n",
    "X = pd.DataFrame(X,columns=features)\n",
    "y = df['answer_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entities_matches</th>\n",
       "      <th>reputation</th>\n",
       "      <th>reply_by_author</th>\n",
       "      <th>len_answer_text</th>\n",
       "      <th>is_accepted</th>\n",
       "      <th>code_snippet_count</th>\n",
       "      <th>link_count</th>\n",
       "      <th>Hedges</th>\n",
       "      <th>Positive.Emotion</th>\n",
       "      <th>Negative.Emotion</th>\n",
       "      <th>...</th>\n",
       "      <th>Bare.Command</th>\n",
       "      <th>WH.Questions</th>\n",
       "      <th>YesNo.Questions</th>\n",
       "      <th>Gratitude</th>\n",
       "      <th>Apology</th>\n",
       "      <th>Truth.Intensifier</th>\n",
       "      <th>Affirmation</th>\n",
       "      <th>Adverb.Just</th>\n",
       "      <th>Conjunction.Start</th>\n",
       "      <th>q_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.708131</td>\n",
       "      <td>-0.316037</td>\n",
       "      <td>-0.185487</td>\n",
       "      <td>0.402484</td>\n",
       "      <td>-0.544218</td>\n",
       "      <td>-0.535847</td>\n",
       "      <td>-0.462886</td>\n",
       "      <td>0.00201</td>\n",
       "      <td>-0.388082</td>\n",
       "      <td>1.185952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.414020</td>\n",
       "      <td>-0.194408</td>\n",
       "      <td>-0.276662</td>\n",
       "      <td>-0.114404</td>\n",
       "      <td>-0.083912</td>\n",
       "      <td>-0.325376</td>\n",
       "      <td>-0.169873</td>\n",
       "      <td>-0.396733</td>\n",
       "      <td>-0.407037</td>\n",
       "      <td>-0.170743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.425816</td>\n",
       "      <td>-0.314292</td>\n",
       "      <td>-0.185487</td>\n",
       "      <td>0.548692</td>\n",
       "      <td>1.837498</td>\n",
       "      <td>-0.535847</td>\n",
       "      <td>0.286970</td>\n",
       "      <td>-0.63629</td>\n",
       "      <td>0.551563</td>\n",
       "      <td>-0.228104</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.414020</td>\n",
       "      <td>-0.194408</td>\n",
       "      <td>-0.276662</td>\n",
       "      <td>-0.114404</td>\n",
       "      <td>-0.083912</td>\n",
       "      <td>1.706875</td>\n",
       "      <td>-0.169873</td>\n",
       "      <td>-0.396733</td>\n",
       "      <td>1.119841</td>\n",
       "      <td>-0.170743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.708131</td>\n",
       "      <td>-0.293650</td>\n",
       "      <td>-0.185487</td>\n",
       "      <td>-0.194703</td>\n",
       "      <td>-0.544218</td>\n",
       "      <td>0.540934</td>\n",
       "      <td>-0.462886</td>\n",
       "      <td>1.91691</td>\n",
       "      <td>0.864778</td>\n",
       "      <td>0.125410</td>\n",
       "      <td>...</td>\n",
       "      <td>2.417250</td>\n",
       "      <td>-0.194408</td>\n",
       "      <td>-0.276662</td>\n",
       "      <td>-0.114404</td>\n",
       "      <td>-0.083912</td>\n",
       "      <td>-0.325376</td>\n",
       "      <td>-0.169873</td>\n",
       "      <td>1.412784</td>\n",
       "      <td>-0.407037</td>\n",
       "      <td>-0.170743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.842078</td>\n",
       "      <td>2.469529</td>\n",
       "      <td>-0.185487</td>\n",
       "      <td>-0.021724</td>\n",
       "      <td>-0.544218</td>\n",
       "      <td>-0.535847</td>\n",
       "      <td>-0.462886</td>\n",
       "      <td>0.00201</td>\n",
       "      <td>0.551563</td>\n",
       "      <td>-0.581618</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.414020</td>\n",
       "      <td>-0.194408</td>\n",
       "      <td>-0.276662</td>\n",
       "      <td>-0.114404</td>\n",
       "      <td>-0.083912</td>\n",
       "      <td>-0.325376</td>\n",
       "      <td>-0.169873</td>\n",
       "      <td>-0.396733</td>\n",
       "      <td>-0.407037</td>\n",
       "      <td>-0.170743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.425816</td>\n",
       "      <td>-0.357657</td>\n",
       "      <td>-0.185487</td>\n",
       "      <td>-0.235888</td>\n",
       "      <td>-0.544218</td>\n",
       "      <td>-0.535847</td>\n",
       "      <td>-0.462886</td>\n",
       "      <td>-0.63629</td>\n",
       "      <td>-0.701297</td>\n",
       "      <td>-0.581618</td>\n",
       "      <td>...</td>\n",
       "      <td>1.001615</td>\n",
       "      <td>3.265442</td>\n",
       "      <td>1.337252</td>\n",
       "      <td>-0.114404</td>\n",
       "      <td>-0.083912</td>\n",
       "      <td>-0.325376</td>\n",
       "      <td>-0.169873</td>\n",
       "      <td>-0.396733</td>\n",
       "      <td>-0.407037</td>\n",
       "      <td>-0.170743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10157</th>\n",
       "      <td>-0.425816</td>\n",
       "      <td>0.002162</td>\n",
       "      <td>-0.185487</td>\n",
       "      <td>-0.328555</td>\n",
       "      <td>-0.544218</td>\n",
       "      <td>-0.535847</td>\n",
       "      <td>-0.462886</td>\n",
       "      <td>-0.63629</td>\n",
       "      <td>-0.701297</td>\n",
       "      <td>-0.228104</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.414020</td>\n",
       "      <td>-0.194408</td>\n",
       "      <td>-0.276662</td>\n",
       "      <td>-0.114404</td>\n",
       "      <td>-0.083912</td>\n",
       "      <td>1.706875</td>\n",
       "      <td>-0.169873</td>\n",
       "      <td>-0.396733</td>\n",
       "      <td>-0.407037</td>\n",
       "      <td>0.369809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10158</th>\n",
       "      <td>0.708131</td>\n",
       "      <td>0.240396</td>\n",
       "      <td>-0.185487</td>\n",
       "      <td>1.065568</td>\n",
       "      <td>1.837498</td>\n",
       "      <td>-0.535847</td>\n",
       "      <td>0.286970</td>\n",
       "      <td>0.64031</td>\n",
       "      <td>1.491207</td>\n",
       "      <td>0.478924</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.414020</td>\n",
       "      <td>-0.194408</td>\n",
       "      <td>1.337252</td>\n",
       "      <td>-0.114404</td>\n",
       "      <td>-0.083912</td>\n",
       "      <td>5.771376</td>\n",
       "      <td>-0.169873</td>\n",
       "      <td>-0.396733</td>\n",
       "      <td>2.646720</td>\n",
       "      <td>-0.189600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10159</th>\n",
       "      <td>0.708131</td>\n",
       "      <td>7.138310</td>\n",
       "      <td>-0.185487</td>\n",
       "      <td>-0.202940</td>\n",
       "      <td>-0.544218</td>\n",
       "      <td>-0.535847</td>\n",
       "      <td>-0.462886</td>\n",
       "      <td>0.64031</td>\n",
       "      <td>-0.701297</td>\n",
       "      <td>0.832438</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.414020</td>\n",
       "      <td>-0.194408</td>\n",
       "      <td>-0.276662</td>\n",
       "      <td>-0.114404</td>\n",
       "      <td>-0.083912</td>\n",
       "      <td>-0.325376</td>\n",
       "      <td>-0.169873</td>\n",
       "      <td>-0.396733</td>\n",
       "      <td>-0.407037</td>\n",
       "      <td>-0.189600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10160</th>\n",
       "      <td>-0.425816</td>\n",
       "      <td>-0.071838</td>\n",
       "      <td>-0.185487</td>\n",
       "      <td>-0.182347</td>\n",
       "      <td>1.837498</td>\n",
       "      <td>0.540934</td>\n",
       "      <td>0.286970</td>\n",
       "      <td>-0.63629</td>\n",
       "      <td>-0.388082</td>\n",
       "      <td>-0.581618</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.414020</td>\n",
       "      <td>-0.194408</td>\n",
       "      <td>-0.276662</td>\n",
       "      <td>-0.114404</td>\n",
       "      <td>-0.083912</td>\n",
       "      <td>-0.325376</td>\n",
       "      <td>-0.169873</td>\n",
       "      <td>-0.396733</td>\n",
       "      <td>1.119841</td>\n",
       "      <td>-0.168648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10161</th>\n",
       "      <td>-0.425816</td>\n",
       "      <td>1.920488</td>\n",
       "      <td>-0.185487</td>\n",
       "      <td>-0.577726</td>\n",
       "      <td>-0.544218</td>\n",
       "      <td>-0.535847</td>\n",
       "      <td>-0.462886</td>\n",
       "      <td>-0.63629</td>\n",
       "      <td>-0.701297</td>\n",
       "      <td>-0.581618</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.414020</td>\n",
       "      <td>-0.194408</td>\n",
       "      <td>-0.276662</td>\n",
       "      <td>-0.114404</td>\n",
       "      <td>-0.083912</td>\n",
       "      <td>-0.325376</td>\n",
       "      <td>5.416690</td>\n",
       "      <td>-0.396733</td>\n",
       "      <td>-0.407037</td>\n",
       "      <td>-0.168648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10162 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       entities_matches  reputation  reply_by_author  len_answer_text  \\\n",
       "0              0.708131   -0.316037        -0.185487         0.402484   \n",
       "1             -0.425816   -0.314292        -0.185487         0.548692   \n",
       "2              0.708131   -0.293650        -0.185487        -0.194703   \n",
       "3              1.842078    2.469529        -0.185487        -0.021724   \n",
       "4             -0.425816   -0.357657        -0.185487        -0.235888   \n",
       "...                 ...         ...              ...              ...   \n",
       "10157         -0.425816    0.002162        -0.185487        -0.328555   \n",
       "10158          0.708131    0.240396        -0.185487         1.065568   \n",
       "10159          0.708131    7.138310        -0.185487        -0.202940   \n",
       "10160         -0.425816   -0.071838        -0.185487        -0.182347   \n",
       "10161         -0.425816    1.920488        -0.185487        -0.577726   \n",
       "\n",
       "       is_accepted  code_snippet_count  link_count   Hedges  Positive.Emotion  \\\n",
       "0        -0.544218           -0.535847   -0.462886  0.00201         -0.388082   \n",
       "1         1.837498           -0.535847    0.286970 -0.63629          0.551563   \n",
       "2        -0.544218            0.540934   -0.462886  1.91691          0.864778   \n",
       "3        -0.544218           -0.535847   -0.462886  0.00201          0.551563   \n",
       "4        -0.544218           -0.535847   -0.462886 -0.63629         -0.701297   \n",
       "...            ...                 ...         ...      ...               ...   \n",
       "10157    -0.544218           -0.535847   -0.462886 -0.63629         -0.701297   \n",
       "10158     1.837498           -0.535847    0.286970  0.64031          1.491207   \n",
       "10159    -0.544218           -0.535847   -0.462886  0.64031         -0.701297   \n",
       "10160     1.837498            0.540934    0.286970 -0.63629         -0.388082   \n",
       "10161    -0.544218           -0.535847   -0.462886 -0.63629         -0.701297   \n",
       "\n",
       "       Negative.Emotion  ...  Bare.Command  WH.Questions  YesNo.Questions  \\\n",
       "0              1.185952  ...     -0.414020     -0.194408        -0.276662   \n",
       "1             -0.228104  ...     -0.414020     -0.194408        -0.276662   \n",
       "2              0.125410  ...      2.417250     -0.194408        -0.276662   \n",
       "3             -0.581618  ...     -0.414020     -0.194408        -0.276662   \n",
       "4             -0.581618  ...      1.001615      3.265442         1.337252   \n",
       "...                 ...  ...           ...           ...              ...   \n",
       "10157         -0.228104  ...     -0.414020     -0.194408        -0.276662   \n",
       "10158          0.478924  ...     -0.414020     -0.194408         1.337252   \n",
       "10159          0.832438  ...     -0.414020     -0.194408        -0.276662   \n",
       "10160         -0.581618  ...     -0.414020     -0.194408        -0.276662   \n",
       "10161         -0.581618  ...     -0.414020     -0.194408        -0.276662   \n",
       "\n",
       "       Gratitude   Apology  Truth.Intensifier  Affirmation  Adverb.Just  \\\n",
       "0      -0.114404 -0.083912          -0.325376    -0.169873    -0.396733   \n",
       "1      -0.114404 -0.083912           1.706875    -0.169873    -0.396733   \n",
       "2      -0.114404 -0.083912          -0.325376    -0.169873     1.412784   \n",
       "3      -0.114404 -0.083912          -0.325376    -0.169873    -0.396733   \n",
       "4      -0.114404 -0.083912          -0.325376    -0.169873    -0.396733   \n",
       "...          ...       ...                ...          ...          ...   \n",
       "10157  -0.114404 -0.083912           1.706875    -0.169873    -0.396733   \n",
       "10158  -0.114404 -0.083912           5.771376    -0.169873    -0.396733   \n",
       "10159  -0.114404 -0.083912          -0.325376    -0.169873    -0.396733   \n",
       "10160  -0.114404 -0.083912          -0.325376    -0.169873    -0.396733   \n",
       "10161  -0.114404 -0.083912          -0.325376     5.416690    -0.396733   \n",
       "\n",
       "       Conjunction.Start   q_score  \n",
       "0              -0.407037 -0.170743  \n",
       "1               1.119841 -0.170743  \n",
       "2              -0.407037 -0.170743  \n",
       "3              -0.407037 -0.170743  \n",
       "4              -0.407037 -0.170743  \n",
       "...                  ...       ...  \n",
       "10157          -0.407037  0.369809  \n",
       "10158           2.646720 -0.189600  \n",
       "10159          -0.407037 -0.189600  \n",
       "10160           1.119841 -0.168648  \n",
       "10161          -0.407037 -0.168648  \n",
       "\n",
       "[10162 rows x 45 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         5\n",
       "1        13\n",
       "2         0\n",
       "3         1\n",
       "4         0\n",
       "         ..\n",
       "10482    20\n",
       "10483     2\n",
       "10484     1\n",
       "10485     8\n",
       "10486     1\n",
       "Name: answer_score, Length: 10162, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gss = GroupShuffleSplit(n_splits=2, train_size=0.8, random_state=0)\n",
    "train_ix, val_ix = next(gss.split(X, y, groups=df['question_id']))\n",
    "    \n",
    "X_train = X.iloc[train_ix]\n",
    "y_train = y.iloc[train_ix]\n",
    "\n",
    "X_val = X.iloc[val_ix]\n",
    "y_val = y.iloc[val_ix]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.25798782 1.38968789 3.08437483 ... 0.27590428 0.79686186 4.60247526]\n"
     ]
    }
   ],
   "source": [
    "svr = SVR(kernel='linear')\n",
    "svr.fit(X_train, y_train)\n",
    "\n",
    "filename = 'models/svm_model_' + str(len(X_train)) + '.sav'\n",
    "joblib.dump(svr, filename)\n",
    "\n",
    "svm_pred = svr.predict(X_val)\n",
    "print(svm_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 (Linear Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.52242113  1.69725951 11.05846245 ... -7.05887171 -9.51974177\n",
      " 23.90525346]\n"
     ]
    }
   ],
   "source": [
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "filename = 'models/reg_model_' + str(len(X_train)) + '.sav'\n",
    "joblib.dump(reg, filename)\n",
    "\n",
    "reg_pred = reg.predict(X_val)\n",
    "print(reg_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3 (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 ... 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=0, n_estimators=1000)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "filename = 'models/rf_model_' + str(len(X_train)) + '.sav'\n",
    "joblib.dump(rf, filename)\n",
    "\n",
    "rf_pred = rf.predict(X_val)\n",
    "print(rf_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Model 1\n",
    "# r = permutation_importance(svr, X_val, y_val, n_repeats=20, random_state=0)\n",
    "\n",
    "# for i in r.importances_mean.argsort()[::-1]:\n",
    "#     print(f\"{features[i]:<8}\"\n",
    "#     f\"{r.importances_mean[i]:.3f}\")\n",
    "    \n",
    "# # Model 2\n",
    "# r = permutation_importance(reg, X_val, y_val, n_repeats=20, random_state=0)\n",
    "\n",
    "# for i in r.importances_mean.argsort()[::-1]:\n",
    "#     print(f\"{features[i]:<8}\"\n",
    "#     f\"{r.importances_mean[i]:.3f}\")\n",
    "   \n",
    "# # Model 3\n",
    "# r = permutation_importance(reg, X_val, y_val, n_repeats=20, random_state=0)\n",
    "\n",
    "# for i in r.importances_mean.argsort()[::-1]:\n",
    "#     print(f\"{features[i]:<8}\"\n",
    "#     f\"{r.importances_mean[i]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to pred_df\n",
    "pred_df = df.iloc[val_ix][['question_id', 'answer_id', 'answer_score']]\n",
    "pred_df['svm_pred_answer_score'] = svm_pred\n",
    "pred_df['reg_pred_answer_score'] = reg_pred\n",
    "pred_df['rf_pred_answer_score'] = rf_pred\n",
    "\n",
    "# Convert predicted answer_score to predicted rankings\n",
    "pred_df['answer_rank'] = pred_df.groupby('question_id')['answer_score'].rank(ascending=False)\n",
    "pred_df['svm_pred_rank'] = pred_df.groupby('question_id')['svm_pred_answer_score'].rank(ascending=False)\n",
    "pred_df['reg_pred_rank'] = pred_df.groupby('question_id')['reg_pred_answer_score'].rank(ascending=False)\n",
    "pred_df['rf_pred_rank'] = pred_df.groupby('question_id')['rf_pred_answer_score'].rank(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm_pred_answer_score Avg Correlation Per Question: 0.4913708143219172\n",
      "reg_pred_answer_score Avg Correlation Per Question: 0.4315530314889336\n",
      "rf_pred_answer_score Avg Correlation Per Question: 0.4499857383469573\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stdout\n",
    "\n",
    "def get_metric(pred_answer_score, answer_score):\n",
    "    return mstats.spearmanr(pred_answer_score, answer_score, use_ties=True).correlation\n",
    "\n",
    "models = {'svm_pred_answer_score': [], 'reg_pred_answer_score': [], 'rf_pred_answer_score': []}\n",
    "for model_answer_score in models.keys():\n",
    "    for question_id in pred_df['question_id'].unique():\n",
    "        mask = (pred_df['question_id'] == question_id)\n",
    "        if len(pred_df[mask]) > 1:\n",
    "            corr = mstats.spearmanr(pred_df[mask][model_answer_score].to_list(), pred_df[mask]['answer_score'].to_list(), use_ties=True).correlation\n",
    "            models[model_answer_score].append(corr)\n",
    "            \n",
    "for key, val in models.items():\n",
    "    print(key, \"Avg Correlation Per Question:\", sum(val) / len(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Of all questions, what proportion of best answers did we predict correctly?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm_pred_rank_exact 0.6484149855907781\n",
      "reg_pred_rank_exact 0.6051873198847262\n",
      "rf_pred_rank_exact 0.590778097982709\n"
     ]
    }
   ],
   "source": [
    "answer_rank = pred_df[pred_df['answer_rank'] == 1]\n",
    "svm_pred_rank_exact = pred_df[pred_df['svm_pred_rank'] == 1]\n",
    "reg_pred_rank_exact = pred_df[pred_df['reg_pred_rank'] == 1]\n",
    "rf_pred_rank_exact = pred_df[pred_df['rf_pred_rank'] == 1]\n",
    "print('svm_pred_rank_exact', len(answer_rank.merge(svm_pred_rank_exact, how='inner', on='answer_id')) / len(pred_df['question_id'].unique()))\n",
    "print('reg_pred_rank_exact', len(answer_rank.merge(reg_pred_rank_exact, how='inner', on='answer_id')) / len(pred_df['question_id'].unique()))\n",
    "print('rf_pred_rank_exact', len(answer_rank.merge(rf_pred_rank_exact, how='inner', on='answer_id')) / len(pred_df['question_id'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Of all questions, what proportion of best answers did we predict within top 3?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm_pred_rank_exact 0.8357348703170029\n",
      "reg_pred_rank_exact 0.8357348703170029\n",
      "rf_pred_rank_exact 0.8155619596541787\n"
     ]
    }
   ],
   "source": [
    "pred_df['svm_top_3'] = pred_df['svm_pred_rank'].apply(lambda row: int(row < 4))\n",
    "pred_df['reg_top_3'] = pred_df['reg_pred_rank'].apply(lambda row: int(row < 4))\n",
    "pred_df['rf_top_3'] = pred_df['rf_pred_rank'].apply(lambda row: int(row < 4))\n",
    "\n",
    "print('svm_pred_rank_exact', len(answer_rank.merge(pred_df[pred_df['svm_top_3'] == 1], how='inner', on='answer_id')) / len(pred_df['question_id'].unique()))\n",
    "print('reg_pred_rank_exact', len(answer_rank.merge(pred_df[pred_df['reg_top_3'] == 1], how='inner', on='answer_id')) / len(pred_df['question_id'].unique()))\n",
    "print('rf_pred_rank_exact', len(answer_rank.merge(pred_df[pred_df['rf_top_3'] == 1], how='inner', on='answer_id')) / len(pred_df['question_id'].unique()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
